/**
 * AUTO-GENERATED FILE - DO NOT EDIT
 *
 * Generated from: server/models/tribrid_config_model.py
 * Generated by: scripts/generate_types.py
 *
 * To regenerate: uv run scripts/generate_types.py
 *
 * ALL TypeScript types for API data MUST be imported from this file.
 * Hand-writing interfaces that should come from Pydantic is FORBIDDEN.
 *
 * This file contains:
 * - Configuration interfaces (TriBridConfig and sub-configs)
 * - Domain model interfaces (ChunkMatch, SearchRequest, Entity, etc.)
 */

/** What the user has checked in the data sources dropdown.  This is what the frontend sends. The backend passes corpus_ids straight into fusion. */
export interface ActiveSources {
  /** Checked corpus IDs (include recall_default when Recall is checked). Empty = no retrieval. */
  corpus_ids?: string[];
}

/** Split-screen model comparison + pipeline profiling. */
export interface BenchmarkConfig {
  enabled?: boolean; // default: True
  max_concurrent_models?: number; // default: 4
  save_results?: boolean; // default: True
  results_path?: string; // default: "data/benchmarks/"
  include_cost_tracking?: boolean; // default: True
  include_timing_breakdown?: boolean; // default: True
}

/** Top-level chat configuration. Lives at TriBridConfig.chat.  KEY CONCEPT: There are no modes. The user checks/unchecks data sources. Recall is always available and ON by default. Corpora are available when indexed. Everything composes freely. */
export interface ChatConfig {
  /** Default checked corpus IDs for new conversations (Recall ON by default). */
  default_corpus_ids?: string[]; // default: ["recall_default"]
  system_prompt_base?: string; // default: "You are a helpful assistant."
  system_prompt_recall_suffix?: string; // default: " You have access to conversation history. Refer..."
  system_prompt_rag_suffix?: string; // default: " Answer questions using the provided code conte..."
  /** State 1: No context. Nothing checked or retrieval returned empty. */
  system_prompt_direct?: string; // default: "You are a code assistant powered by TriBridRAG...."
  /** State 2: RAG only. Code corpora returned results; Recall did not. */
  system_prompt_rag?: string; // default: "You are a code assistant powered by TriBridRAG,..."
  /** State 3: Recall only. Recall returned results; no RAG corpora active. */
  system_prompt_recall?: string; // default: "You are a code assistant powered by TriBridRAG...."
  /** State 4: Both. RAG and Recall both returned results. */
  system_prompt_rag_and_recall?: string; // default: "You are a code assistant powered by TriBridRAG,..."
  reranker?: ChatRerankerConfig;
  recall?: RecallConfig;
  recall_gate?: RecallGateConfig;
  multimodal?: ChatMultimodalConfig;
  image_gen?: ImageGenConfig;
  local_models?: LocalModelConfig;
  openrouter?: OpenRouterConfig;
  benchmark?: BenchmarkConfig;
  temperature?: number; // default: 0.3
  /** Temperature when nothing is checked (direct chat = more creative) */
  temperature_no_retrieval?: number; // default: 0.7
  max_tokens?: number; // default: 4096
  show_source_dropdown?: boolean; // default: True
  send_shortcut?: string; // default: "ctrl+enter"
}

/** Developer-facing debug metadata for a single chat answer. */
export interface ChatDebugInfo {
  /** Heuristic confidence score for this answer (0-1). */
  confidence?: number | null; // default: None
  /** Recall gate decision for this message (Recall only; RAG corpora are always queried when checked). */
  recall_plan?: RecallPlan | null; // default: None
  /** Vector leg requested for this message */
  include_vector?: boolean; // default: True
  /** Sparse/BM25 leg requested for this message */
  include_sparse?: boolean; // default: True
  /** Graph leg requested for this message */
  include_graph?: boolean; // default: True
  /** Vector leg enabled in config */
  vector_enabled?: boolean | null; // default: None
  /** Sparse leg enabled in config */
  sparse_enabled?: boolean | null; // default: None
  /** Graph leg enabled in config */
  graph_enabled?: boolean | null; // default: None
  /** Fusion method used for retrieval results */
  fusion_method?: "rrf" | "weighted" | null; // default: None
  /** RRF k (if fusion_method is rrf) */
  rrf_k?: number | null; // default: None
  /** Vector weight (if fusion_method is weighted) */
  vector_weight?: number | null; // default: None
  /** Sparse weight (if fusion_method is weighted) */
  sparse_weight?: number | null; // default: None
  /** Graph weight (if fusion_method is weighted) */
  graph_weight?: number | null; // default: None
  /** Whether leg score normalization was enabled */
  normalize_scores?: boolean | null; // default: None
  /** Final K used for retrieval context */
  final_k_used?: number | null; // default: None
  /** Vector leg results returned */
  vector_results?: number | null; // default: None
  /** Sparse leg results returned */
  sparse_results?: number | null; // default: None
  /** Graph entity hits (pre-hydration) */
  graph_entity_hits?: number | null; // default: None
  /** Graph hydrated chunks returned */
  graph_hydrated_chunks?: number | null; // default: None
  /** Final fused results returned */
  final_results?: number | null; // default: None
  /** Top-1 fused score (raw) */
  top1_score?: number | null; // default: None
  /** Average fused score for top-5 (raw) */
  avg5_score?: number | null; // default: None
  /** Configured top-1 confidence threshold */
  conf_top1_thresh?: number | null; // default: None
  /** Configured avg-5 confidence threshold */
  conf_avg5_thresh?: number | null; // default: None
  /** Raw fusion debug payload (for developers). */
  fusion_debug?: Record<string, unknown>;
}

/** Single chat model option resolved from providers. */
export interface ChatModelInfo {
  /** Model identifier */
  id: string;
  /** Provider display name (e.g., OpenRouter, Ollama) */
  provider: string;
  /** Model source group for UI grouping. */
  source: "cloud_direct" | "openrouter" | "local";
  /** Provider type (ollama, llamacpp, openrouter, etc) */
  provider_type?: string | null; // default: None
  /** Provider base URL (local/openrouter) */
  base_url?: string | null; // default: None
  /** Whether this model is expected to support vision inputs */
  supports_vision?: boolean; // default: False
}

/** Image upload + vision model configuration. */
export interface ChatMultimodalConfig {
  vision_enabled?: boolean; // default: True
  max_image_size_mb?: number; // default: 20
  max_images_per_message?: number; // default: 5
  supported_formats?: string[]; // default: ["png", "jpg", "jpeg", "gif", "webp"]
  /** OpenAI vision detail level. */
  image_detail?: string; // default: "auto"
  /** Force model for vision. Empty=use chat model if it supports vision. */
  vision_model_override?: string; // default: ""
}

/** Chat-specific reranker.  Separate from RAG reranker because: - Shorter passages (conversation turns, not code blocks) - Recency bias (recent messages matter more) - Lower latency tolerance (chat feels slow >500ms) */
export interface ChatRerankerConfig {
  /** Chat reranker mode. */
  mode?: string; // default: "local"
  /** Local cross-encoder. L-6 not L-12 — faster for chat. */
  local_model?: string; // default: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  cloud_provider?: string; // default: "cohere"
  cloud_model?: string; // default: "rerank-v3.5"
  top_n?: number; // default: 20
  /** Blend weight for recency. 0=pure relevance, 1=pure recency. */
  recency_weight?: number; // default: 0.3
  /** Only retrieve messages from last N hours. 0=no limit. */
  max_age_hours?: number; // default: 0
}

/** Unified result shape for vector/sparse/graph retrieval. */
export interface ChunkMatch {
  /** Unique identifier for matched chunk */
  chunk_id: string;
  /** The matched code/text content */
  content: string;
  /** Path to the source file */
  file_path: string;
  /** Starting line number */
  start_line: number;
  /** Ending line number */
  end_line: number;
  /** Programming language */
  language?: string | null; // default: None
  /** Relevance score from retrieval */
  score: number;
  /** Which retrieval leg found this */
  source: "vector" | "sparse" | "graph";
  /** Additional match metadata */
  metadata?: Record<string, unknown>;
}

/** Metadata about the most recent chunk_summaries build. */
export interface ChunkSummariesLastBuild {
  /** Corpus identifier */
  corpus_id: string;
  /** When the build completed */
  timestamp?: string;
  /** Number of chunk_summaries generated */
  total: number;
  /** Number of chunk_summaries enriched (if enabled) */
  enriched?: number; // default: 0
}

/** A short summary of an indexed chunk (chunk_summary). */
export interface ChunkSummary {
  /** Unique identifier of the source chunk */
  chunk_id: string;
  /** Path to the source file */
  file_path: string;
  /** Starting line number */
  start_line?: number | null; // default: None
  /** Ending line number */
  end_line?: number | null; // default: None
  /** High-level purpose summary */
  purpose?: string | null; // default: None
  /** Symbols mentioned in this chunk */
  symbols?: string[];
  /** Technical details summary */
  technical_details?: string | null; // default: None
  /** Domain concepts mentioned in this chunk */
  domain_concepts?: string[];
}

/** Chunk summary builder filtering configuration. */
export interface ChunkSummaryConfig {
  /** Directories to skip when building chunk_summaries */
  exclude_dirs?: string[];
  /** File patterns/extensions to skip */
  exclude_patterns?: string[];
  /** Keywords that, when present in code, skip the chunk */
  exclude_keywords?: string[];
  /** Max code snippet length in semantic chunk_summaries */
  code_snippet_length?: number; // default: 2000
  /** Max symbols to include per chunk_summary */
  max_symbols?: number; // default: 5
  /** Max API routes to include per chunk_summary */
  max_routes?: number; // default: 5
  /** Max length for purpose field in chunk_summaries */
  purpose_max_length?: number; // default: 240
  /** Quick tips shown in chunk_summaries builder UI */
  quick_tips?: string[];
}

/** Code chunking configuration. */
export interface ChunkingConfig {
  /** Target chunk size (non-whitespace chars) */
  chunk_size?: number; // default: 1000
  /** Overlap between chunks */
  chunk_overlap?: number; // default: 200
  /** Overlap lines for AST chunking */
  ast_overlap_lines?: number; // default: 20
  /** Max file size to index (bytes) - files larger than this are skipped */
  max_indexable_file_size?: number; // default: 2000000
  /** Maximum tokens per chunk - chunks exceeding this are split recursively */
  max_chunk_tokens?: number; // default: 8000
  /** Minimum chunk size */
  min_chunk_chars?: number; // default: 50
  /** Target size for greedy chunking */
  greedy_fallback_target?: number; // default: 800
  /** Chunking strategy */
  chunking_strategy?: string; // default: "ast"
  /** Include imports in chunks */
  preserve_imports?: number; // default: 1
}

export interface CorpusEvalProfile {
  /** Corpus identifier */
  corpus_id: string;
  /** Label structure for relevance data */
  label_kind?: "pairwise" | "binary" | "graded" | "unknown"; // default: "unknown"
  avg_relevant_per_query?: number; // default: 0.0
  p95_relevant_per_query?: number; // default: 0.0
  /** Auto-selected headline metric for this corpus */
  recommended_metric: "mrr" | "ndcg" | "map";
  /** Recommended k for @k metrics */
  recommended_k?: number; // default: 10
  /** Short UI-safe explanation for metric choice */
  rationale?: string; // default: ""
}

/** Embedding configuration summary for dashboard display. */
export interface DashboardEmbeddingConfigSummary {
  /** Embedding provider (embedding.embedding_type). */
  provider?: string | null; // default: None
  /** Effective embedding model name. */
  model?: string | null; // default: None
  /** Embedding vector dimensions. */
  dimensions?: number | null; // default: None
  /** Storage precision label (e.g., float32). */
  precision?: string | null; // default: None
}

/** Indexing cost summary for dashboard display. */
export interface DashboardIndexCosts {
  /** Total tokens processed during indexing. */
  total_tokens?: number; // default: 0
  /** Estimated embedding cost (USD) when pricing data is available. */
  embedding_cost?: number | null; // default: None
}

/** Metadata payload for the dashboard index status panel. */
export interface DashboardIndexStatusMetadata {
  /** Corpus identifier */
  corpus_id: string;
  /** Display name for the active corpus. */
  current_repo: string;
  /** Current git branch for the corpus (if available). */
  current_branch?: string | null; // default: None
  /** Timestamp for this status snapshot (UTC). */
  timestamp: string;
  /** Embedding configuration summary. */
  embedding_config?: DashboardEmbeddingConfigSummary | null; // default: None
  /** Indexing cost summary. */
  costs?: DashboardIndexCosts | null; // default: None
  /** Storage breakdown (bytes) for major components. */
  storage_breakdown?: DashboardIndexStorageBreakdown;
  /** Number of keywords for this corpus (if generated). */
  keywords_count?: number; // default: 0
  /** Total storage bytes (Postgres + Neo4j). */
  total_storage?: number; // default: 0
}

/** Storage breakdown for the Dashboard index summary (bytes).  NOTE: - Values are best-effort and may be allocated/estimated when a storage   component cannot be attributed to a single corpus directly (e.g., shared   Postgres indexes). */
export interface DashboardIndexStorageBreakdown {
  /** Bytes used by chunk content + metadata in Postgres (corpus-scoped). */
  chunks_bytes?: number; // default: 0
  /** Bytes used by stored embeddings in Postgres (corpus-scoped). */
  embeddings_bytes?: number; // default: 0
  /** Bytes used by pgvector index structures (0 if not created; may be allocated/estimated). */
  pgvector_index_bytes?: number; // default: 0
  /** Allocated bytes for Postgres full-text (BM25/FTS) index (may be allocated/estimated). */
  bm25_index_bytes?: number; // default: 0
  /** Bytes used by chunk_summaries in Postgres (corpus-scoped). */
  chunk_summaries_bytes?: number; // default: 0
  /** Total Neo4j store size for the resolved database (bytes). */
  neo4j_store_bytes?: number; // default: 0
  /** Total Postgres bytes (sum of Postgres components, including allocations). */
  postgres_total_bytes?: number; // default: 0
  /** Total storage bytes across Postgres + Neo4j. */
  total_storage_bytes?: number; // default: 0
}

/** Docker infrastructure configuration. */
export interface DockerConfig {
  /** Docker socket URL (e.g., unix:///var/run/docker.sock). Leave empty for auto-detection. */
  docker_host?: string; // default: ""
  /** Timeout for Docker status check (seconds) */
  docker_status_timeout?: number; // default: 5
  /** Timeout for Docker container list (seconds) */
  docker_container_list_timeout?: number; // default: 10
  /** Timeout for Docker container actions (start/stop/restart) */
  docker_container_action_timeout?: number; // default: 30
  /** Timeout for Docker infrastructure up command (seconds) */
  docker_infra_up_timeout?: number; // default: 60
  /** Timeout for Docker infrastructure down command (seconds) */
  docker_infra_down_timeout?: number; // default: 30
  /** Default number of log lines to tail from containers */
  docker_logs_tail?: number; // default: 100
  /** Include timestamps in Docker logs (1=yes, 0=no) */
  docker_logs_timestamps?: number; // default: 1
  /** Port for dev frontend (Vite) */
  dev_frontend_port?: number; // default: 5173
  /** Port for dev backend (Uvicorn) */
  dev_backend_port?: number; // default: 8012
  /** Timeout for dev stack restart operations (seconds) */
  dev_stack_restart_timeout?: number; // default: 30
}

/** Normalized Docker container entry used by the Docker tab + dashboard. */
export interface DockerContainer {
  /** Full container ID. */
  id: string;
  /** Short container ID (first 12 chars). */
  short_id: string;
  /** Container name. */
  name: string;
  /** Container image reference. */
  image: string;
  /** Container state (lowercase, best-effort). */
  state: string;
  /** Human-readable docker status string. */
  status: string;
  /** Port mapping summary string (may be empty). */
  ports?: string | null; // default: None
  /** Docker Compose project label (if present). */
  compose_project?: string | null; // default: None
  /** Docker Compose service label (if present). */
  compose_service?: string | null; // default: None
  /** Whether this container belongs to the TriBrid dev stack. */
  tribrid_managed?: boolean; // default: False
}

/** Embedding generation and caching configuration. */
export interface EmbeddingConfig {
  /** Embedding provider (dynamic - validated against models.json at runtime) */
  embedding_type?: string; // default: "openai"
  /** OpenAI embedding model */
  embedding_model?: string; // default: "text-embedding-3-large"
  /** Embedding dimensions */
  embedding_dim?: number; // default: 3072
  /** Voyage embedding model */
  voyage_model?: string; // default: "voyage-code-3"
  /** Local SentenceTransformer model */
  embedding_model_local?: string; // default: "all-MiniLM-L6-v2"
  /** Batch size for embedding generation */
  embedding_batch_size?: number; // default: 64
  /** Max tokens per embedding chunk */
  embedding_max_tokens?: number; // default: 8000
  /** Enable embedding cache */
  embedding_cache_enabled?: number; // default: 1
  /** Embedding API timeout (seconds) */
  embedding_timeout?: number; // default: 30
  /** Max retries for embedding API */
  embedding_retry_max?: number; // default: 3
}

/** Code enrichment and chunk_summary generation configuration. */
export interface EnrichmentConfig {
  /** Enable chunk_summary enrichment by default */
  chunk_summaries_enrich_default?: number; // default: 1
  /** Max chunk_summaries to generate */
  chunk_summaries_max?: number; // default: 100
  /** Enable chunk enrichment */
  enrich_code_chunks?: number; // default: 1
  /** Min chars for enrichment */
  enrich_min_chars?: number; // default: 50
  /** Max chars for enrichment prompt */
  enrich_max_chars?: number; // default: 1000
  /** Enrichment timeout (seconds) */
  enrich_timeout?: number; // default: 30
}

/** Knowledge graph node representing a code entity. */
export interface Entity {
  /** Unique identifier */
  entity_id: string;
  /** Entity name (function name, class name, etc) */
  name: string;
  /** Type of entity */
  entity_type: "function" | "class" | "module" | "variable" | "concept";
  /** File where entity is defined */
  file_path?: string | null; // default: None
  /** AI-generated description */
  description?: string | null; // default: None
  /** Additional properties */
  properties?: Record<string, unknown>;
}

/** Lightweight scored retrieval doc for eval drill-down. */
export interface EvalDoc {
  /** Retrieved file path */
  file_path: string;
  /** Optional start line for the retrieved span */
  start_line?: number | null; // default: None
  /** Retrieval score (post-fusion) */
  score: number;
  /** Retrieval source (vector/sparse/graph) */
  source?: string | null; // default: None
}

/** Aggregated retrieval metrics from an evaluation run. */
export interface EvalMetrics {
  /** Mean Reciprocal Rank */
  mrr: number;
  /** Recall at top 5 */
  recall_at_5: number;
  /** Recall at top 10 */
  recall_at_10: number;
  /** Recall at top 20 */
  recall_at_20: number;
  /** Precision at top 5 */
  precision_at_5: number;
  /** NDCG at top 10 */
  ndcg_at_10: number;
  /** 50th percentile latency in ms */
  latency_p50_ms: number;
  /** 95th percentile latency in ms */
  latency_p95_ms: number;
}

/** Per-entry evaluation result. */
export interface EvalResult {
  /** Dataset entry ID */
  entry_id: string;
  /** The test question */
  question: string;
  /** File paths that were actually retrieved (ranked) */
  retrieved_paths: string[];
  /** File paths that should have been retrieved */
  expected_paths: string[];
  /** Top retrieved file paths (ranked, truncated for UI) */
  top_paths?: string[];
  /** Top-1 retrieved file path (0 or 1 items) */
  top1_path?: string[];
  /** Whether top-1 contained any expected path */
  top1_hit?: boolean; // default: False
  /** Whether top-k contained any expected path */
  topk_hit?: boolean; // default: False
  /** Reciprocal rank for this entry */
  reciprocal_rank: number;
  /** Recall for this entry */
  recall: number;
  /** Latency for this query */
  latency_ms: number;
  /** Duration for this query (seconds) */
  duration_secs?: number; // default: 0.0
  /** Top docs with scores for drill-down */
  docs?: EvalDoc[];
}

/** Summary metadata for listing eval runs. */
export interface EvalRunMeta {
  /** Eval run ID */
  run_id: string;
  /** Top-1 accuracy */
  top1_accuracy: number;
  /** Top-k accuracy */
  topk_accuracy: number;
  /** Mean reciprocal rank */
  mrr?: number | null; // default: None
  /** Total questions evaluated */
  total: number;
  /** Total run duration (seconds) */
  duration_secs: number;
  /** Whether config snapshot is present */
  has_config?: boolean; // default: True
}

/** Evaluation dataset configuration. */
export interface EvaluationConfig {
  /** Evaluation dataset path */
  eval_dataset_path?: string; // default: "data/evaluation_dataset.json"
  /** Baseline results path */
  baseline_path?: string; // default: "data/evals/eval_baseline.json"
  /** K used for recall_at_5 metric (default 5). */
  recall_at_5_k?: number; // default: 5
  /** K used for recall_at_10 metric (default 10). */
  recall_at_10_k?: number; // default: 10
  /** K used for recall_at_20 metric (default 20). */
  recall_at_20_k?: number; // default: 20
  /** K used for precision_at_5 metric (default 5). */
  precision_at_5_k?: number; // default: 5
  /** K used for ndcg_at_10 metric (default 10). */
  ndcg_at_10_k?: number; // default: 10
  /** Multi-query variants for evaluation */
  eval_multi_m?: number; // default: 10
}

/** Configuration for tri-brid fusion of vector + sparse + graph results. */
export interface FusionConfig {
  /** Fusion method: 'rrf' (Reciprocal Rank Fusion) or 'weighted' (score-based) */
  method?: "rrf" | "weighted"; // default: "rrf"
  /** Weight for vector search results (pgvector) */
  vector_weight?: number; // default: 0.4
  /** Weight for sparse BM25/FTS search results */
  sparse_weight?: number; // default: 0.3
  /** Weight for graph search results (Neo4j) */
  graph_weight?: number; // default: 0.3
  /** RRF smoothing constant (higher = more weight to top ranks) */
  rrf_k?: number; // default: 60
  /** Normalize scores to [0,1] before fusion */
  normalize_scores?: boolean; // default: True
}

/** LLM generation configuration. */
export interface GenerationConfig {
  /** Primary generation model */
  gen_model?: string; // default: "gpt-4o-mini"
  /** Generation temperature */
  gen_temperature?: number; // default: 0.0
  /** Max tokens for generation */
  gen_max_tokens?: number; // default: 2048
  /** Nucleus sampling threshold */
  gen_top_p?: number; // default: 1.0
  /** Generation timeout (seconds) */
  gen_timeout?: number; // default: 60
  /** Max retries for generation */
  gen_retry_max?: number; // default: 2
  /** Model for code enrichment */
  enrich_model?: string; // default: "gpt-4o-mini"
  /** Enrichment backend */
  enrich_backend?: string; // default: "openai"
  /** Disable code enrichment */
  enrich_disabled?: number; // default: 0
  /** Context window for Ollama */
  ollama_num_ctx?: number; // default: 8192
  /** CLI generation model */
  gen_model_cli?: string; // default: "qwen3-coder:14b"
  /** Ollama generation model */
  gen_model_ollama?: string; // default: "qwen3-coder:30b"
  /** HTTP transport generation model override */
  gen_model_http?: string; // default: ""
  /** MCP transport generation model override */
  gen_model_mcp?: string; // default: ""
  /** Ollama enrichment model */
  enrich_model_ollama?: string; // default: ""
  /** Ollama API URL */
  ollama_url?: string; // default: "http://127.0.0.1:11434/api"
  /** OpenAI API base URL override (for proxies) */
  openai_base_url?: string; // default: ""
  /** Maximum total time to wait for a local (Ollama) generation request to complete (seconds) */
  ollama_request_timeout?: number; // default: 300
  /** Maximum idle time allowed between streamed chunks from local (Ollama) during generation (seconds) */
  ollama_stream_idle_timeout?: number; // default: 60
}

/** Configuration for building/persisting graph data during indexing. */
export interface GraphIndexingConfig {
  /** Enable graph building during indexing (Neo4j) */
  enabled?: boolean; // default: True
  /** Build lexical graph (Document/Chunk nodes + NEXT_CHUNK relationships) */
  build_lexical_graph?: boolean; // default: True
  /** Store chunk embeddings on Chunk nodes for Neo4j vector search (requires dense embeddings) */
  store_chunk_embeddings?: boolean; // default: True
  /** Build semantic knowledge graph (concept entities + relations) linked to chunks during indexing */
  semantic_kg_enabled?: boolean; // default: False
  /** Edge weight for AST containment relationships (module->class/function, class->method). */
  ast_contains_weight?: number; // default: 1.0
  /** Edge weight for AST inheritance relationships (class->base). */
  ast_inherits_weight?: number; // default: 1.0
  /** Edge weight for AST import relationships (module->imported_module). */
  ast_imports_weight?: number; // default: 1.0
  /** Edge weight for AST call relationships (function->callee). */
  ast_calls_weight?: number; // default: 1.0
  /** Semantic KG extraction mode. 'heuristic' is deterministic and test-friendly; 'llm' uses an LLM to extract entities + relations. */
  semantic_kg_mode?: "heuristic" | "llm"; // default: "heuristic"
  /** Edge weight for semantic concept relations in LLM mode. */
  semantic_kg_relation_weight_llm?: number; // default: 0.7
  /** Edge weight for semantic concept relations in heuristic fallback mode. */
  semantic_kg_relation_weight_heuristic?: number; // default: 0.5
  /** Maximum semantic concepts to extract per chunk */
  semantic_kg_max_concepts_per_chunk?: number; // default: 8
  /** Minimum length for semantic concept tokens */
  semantic_kg_min_concept_len?: number; // default: 4
  /** Maximum semantic relations to create per chunk (heuristic mode) */
  semantic_kg_max_relations_per_chunk?: number; // default: 12
  /** Maximum chunks to process for semantic KG extraction per indexing run (0 = disabled) */
  semantic_kg_max_chunks?: number; // default: 200
  /** LLM model name for semantic KG extraction when semantic_kg_mode='llm' (empty = use generation.enrich_model) */
  semantic_kg_llm_model?: string; // default: ""
  /** Timeout (seconds) for semantic KG LLM extraction per chunk */
  semantic_kg_llm_timeout_s?: number; // default: 30
  /** Neo4j vector index name for Chunk embeddings (mode='chunk') */
  chunk_vector_index_name?: string; // default: "tribrid_chunk_embeddings"
  /** Chunk node property that stores the embedding vector */
  chunk_embedding_property?: string; // default: "embedding"
  /** Neo4j vector similarity function */
  vector_similarity_function?: "cosine" | "euclidean"; // default: "cosine"
  /** Wait for the Neo4j vector index to come ONLINE after (re)creating it */
  wait_vector_index_online?: boolean; // default: True
  /** Timeout waiting for Neo4j vector index ONLINE (seconds) */
  vector_index_online_timeout_s?: number; // default: 60.0
}

/** Configuration for graph-based search using Neo4j. */
export interface GraphSearchConfig {
  /** Graph retrieval mode. 'chunk' uses lexical chunk nodes + Neo4j vector index; 'entity' uses the legacy code-entity graph. */
  mode?: "chunk" | "entity"; // default: "chunk"
  /** Enable graph search in tri-brid retrieval */
  enabled?: boolean; // default: True
  /** When mode='chunk', include up to N adjacent chunks (NEXT_CHUNK) around each seed hit */
  chunk_neighbor_window?: number; // default: 1
  /** When mode='chunk' and Neo4j uses a shared database, overfetch seed hits before filtering by corpus_id */
  chunk_seed_overfetch_multiplier?: number; // default: 10
  /** When mode='chunk', expand from seed chunks via Entity graph (IN_CHUNK links) to find related chunks */
  chunk_entity_expansion_enabled?: boolean; // default: True
  /** Blend weight for entity-expansion scores relative to seed chunk scores (mode='chunk') */
  chunk_entity_expansion_weight?: number; // default: 0.8
  /** Maximum graph traversal hops */
  max_hops?: number; // default: 2
  /** Include community-based expansion in graph search */
  include_communities?: boolean; // default: True
  /** Number of results to retrieve from graph search */
  top_k?: number; // default: 30
}

/** Statistics about a repository's knowledge graph. */
export interface GraphStats {
  /** Corpus identifier */
  corpus_id: string;
  /** Number of entities in graph */
  total_entities: number;
  /** Number of relationships */
  total_relationships: number;
  /** Number of detected communities */
  total_communities: number;
  /** Count by entity type */
  entity_breakdown?: Record<string, number>;
  /** Count by relation type */
  relationship_breakdown?: Record<string, number>;
}

/** Configuration for Neo4j graph storage and traversal. */
export interface GraphStorageConfig {
  /** Neo4j connection URI (bolt:// or neo4j://) */
  neo4j_uri?: string; // default: "bolt://localhost:7687"
  /** Neo4j username */
  neo4j_user?: string; // default: "neo4j"
  /** Neo4j password (recommend using environment variable) */
  neo4j_password?: string; // default: ""
  /** Neo4j database name */
  neo4j_database?: string; // default: "neo4j"
  /** Database isolation mode: 'shared' uses a single Neo4j database (Community-compatible), 'per_corpus' uses a separate Neo4j database per corpus (Enterprise multi-database). */
  neo4j_database_mode?: "shared" | "per_corpus"; // default: "shared"
  /** Prefix for per-corpus Neo4j database names when neo4j_database_mode='per_corpus'. */
  neo4j_database_prefix?: string; // default: "tribrid_"
  /** Automatically create per-corpus Neo4j databases when missing (Enterprise). */
  neo4j_auto_create_databases?: boolean; // default: True
  /** Maximum traversal hops for graph search */
  max_hops?: number; // default: 2
  /** Include community detection in graph analysis */
  include_communities?: boolean; // default: True
  /** Community detection algorithm */
  community_algorithm?: "louvain" | "label_propagation"; // default: "louvain"
  /** Entity types to extract and store in graph */
  entity_types?: string[]; // default: ["function", "class", "module", "variable", "im...
  /** Relationship types to extract */
  relationship_types?: string[]; // default: ["calls", "imports", "inherits", "contains", "r...
  /** Number of results from graph traversal */
  graph_search_top_k?: number; // default: 30
}

/** Per-service status entry for /api/health. */
export interface HealthServiceStatus {
  /** Service health status label (e.g., up/unknown/down). */
  status: string;
  /** Optional error message if unhealthy/unreachable. */
  error?: string | null; // default: None
}

/** Context hydration configuration. */
export interface HydrationConfig {
  /** Context hydration mode */
  hydration_mode?: string; // default: "lazy"
  /** Max characters to hydrate */
  hydration_max_chars?: number; // default: 2000
}

/** Single image attached to a chat message.  Exactly ONE of `url` or `base64` must be provided. */
export interface ImageAttachment {
  /** Remote URL */
  url?: string | null; // default: None
  /** Base64 data URI (no data: prefix required) */
  base64?: string | null; // default: None
  /** MIME type (e.g., image/png) */
  mime_type?: string; // default: "image/png"
}

/** Two tiers: - LOCAL: Direct CLI/subprocess (free, self-hosted) - CLOUD: Paid APIs (ComfyUI API, Replicate, DALL-E)  ComfyUI is typically self-hosted. We do NOT use ComfyUI as the local P0 path; local P0 is direct CLI/subprocess. `comfyui_api` is a remote endpoint (self-hosted or paid). */
export interface ImageGenConfig {
  enabled?: boolean; // default: False
  provider?: string; // default: "local"
  /** CLI command. Receives --prompt, --output, --steps, --width, --height. */
  local_command?: string; // default: "python -m qwen_image.generate"
  local_model_path?: string; // default: ""
  use_lightning_lora?: boolean; // default: True
  comfyui_api_endpoint?: string; // default: ""
  replicate_model?: string; // default: ""
  default_steps?: number; // default: 8
  default_resolution?: string; // default: "1024x1024"
}

/** Statistics about an indexed repository. */
export interface IndexStats {
  /** Corpus identifier */
  corpus_id: string;
  /** Number of files indexed */
  total_files: number;
  /** Number of chunks created */
  total_chunks: number;
  /** Total token count across all chunks */
  total_tokens: number;
  /** Model used for embeddings */
  embedding_model: string;
  /** Dimension of embedding vectors */
  embedding_dimensions: number;
  /** When last indexed */
  last_indexed?: string | null; // default: None
  /** Count by file extension */
  file_breakdown?: Record<string, number>;
}

/** Indexing and vector storage configuration. */
export interface IndexingConfig {
  /** PostgreSQL connection string (DSN) for pgvector + FTS storage */
  postgres_url?: string; // default: "postgresql://postgres:postgres@localhost:5432/t..."
  /** pgvector table name template */
  table_name?: string; // default: "code_chunks_{repo}"
  /** Collection suffix for multi-index scenarios */
  collection_suffix?: string; // default: "default"
  /** Fallback repository path if not found in repos.json */
  repo_path?: string; // default: ""
  /** Batch size for indexing */
  indexing_batch_size?: number; // default: 100
  /** Parallel workers for indexing */
  indexing_workers?: number; // default: 4
  /** BM25 tokenizer type */
  bm25_tokenizer?: string; // default: "stemmer"
  /** Stemmer language */
  bm25_stemmer_lang?: string; // default: "english"
  /** Stopwords language code */
  bm25_stopwords_lang?: string; // default: "en"
  /** Excluded file extensions (comma-separated) */
  index_excluded_exts?: string; // default: ".png,.jpg,.gif,.ico,.svg,.woff,.ttf"
  /** Max file size to index (MB) */
  index_max_file_size_mb?: number; // default: 10
  /** Skip dense vector indexing */
  skip_dense?: number; // default: 0
  /** Base output directory */
  out_dir_base?: string; // default: "./out"
  /** Override for OUT_DIR_BASE if specified */
  rag_out_base?: string; // default: ""
  /** Repository configuration file */
  repos_file?: string; // default: "./repos.json"
}

/** Discriminative keywords configuration. */
export interface KeywordsConfig {
  /** Max discriminative keywords per repo */
  keywords_max_per_repo?: number; // default: 50
  /** Min frequency for keyword */
  keywords_min_freq?: number; // default: 3
  /** Score boost for keyword matches */
  keywords_boost?: number; // default: 1.3
  /** Auto-generate keywords */
  keywords_auto_generate?: number; // default: 1
  /** Hours between keyword refresh */
  keywords_refresh_hours?: number; // default: 24
}

/** Layer-specific scoring bonuses with intent-aware matrix.  The base bonuses are additive percentages (e.g., 0.15 = +15%). They are converted downstream to multiplicative factors. */
export interface LayerBonusConfig {
  /** Bonus for GUI/front-end layers */
  gui?: number; // default: 0.15
  /** Bonus for retrieval/API layers */
  retrieval?: number; // default: 0.15
  /** Bonus for indexing/ingestion layers */
  indexer?: number; // default: 0.15
  /** Penalty for vendor/third-party code (negative values apply a penalty) */
  vendor_penalty?: number; // default: -0.1
  /** Bonus for recently modified files */
  freshness_bonus?: number; // default: 0.05
  /** Intent-to-layer bonus matrix. Keys are query intents, values are layer->multiplier maps. */
  intent_matrix?: Record<string, Record<string, number>>;
}

/** Supports MULTIPLE simultaneous local providers.  P0: Ollama + llama.cpp. All use OpenAI-compatible API. */
export interface LocalModelConfig {
  providers?: LocalProviderEntry[]; // default: [{"name": "Ollama", "provider_type": "ollama", ...
  auto_detect?: boolean; // default: True
  health_check_interval?: number; // default: 30
  fallback_to_cloud?: boolean; // default: True
  gpu_memory_limit_gb?: number; // default: 0
  default_chat_model?: string; // default: "qwen3:8b"
  default_vision_model?: string; // default: "qwen3-vl:8b"
  default_embedding_model?: string; // default: "nomic-embed-text"
}

/** A single local inference provider endpoint. */
export interface LocalProviderEntry {
  /** Display name */
  name: string;
  provider_type: string;
  /** Provider API endpoint */
  base_url: string;
  enabled?: boolean; // default: True
  /** Lower = higher priority when multiple have same model. */
  priority?: number; // default: 0
}

/** Inbound MCP (Model Context Protocol) server configuration.  This config controls TriBridRAG's embedded MCP Streamable HTTP endpoint. */
export interface MCPConfig {
  /** Enable the embedded MCP Streamable HTTP server. */
  enabled?: boolean; // default: True
  /** Mount path for the MCP Streamable HTTP endpoint (e.g. /mcp). */
  mount_path?: string; // default: "/mcp"
  /** Run MCP Streamable HTTP in stateless mode (recommended). */
  stateless_http?: boolean; // default: True
  /** Prefer JSON responses for MCP Streamable HTTP (recommended). */
  json_response?: boolean; // default: True
  /** Enable DNS rebinding protection for MCP HTTP (recommended). */
  enable_dns_rebinding_protection?: boolean; // default: True
  /** Allowed Host header values for MCP HTTP (supports wildcard ':*'). */
  allowed_hosts?: string[];
  /** Allowed Origin header values for MCP HTTP (supports wildcard ':*'). */
  allowed_origins?: string[];
  /** Require `Authorization: Bearer $MCP_API_KEY` for MCP HTTP access. */
  require_api_key?: boolean; // default: False
  /** Default top_k for MCP search/answer tools when not provided. */
  default_top_k?: number; // default: 20
  /** Default retrieval mode for MCP search/answer tools when not provided. */
  default_mode?: "tribrid" | "dense_only" | "sparse_only" | "graph_only"; // default: "tribrid"
}

/** Status of an MCP HTTP transport (Python/Node) when enabled. */
export interface MCPHTTPTransportStatus {
  /** Host for the MCP HTTP transport. */
  host: string;
  /** Port for the MCP HTTP transport. */
  port: number;
  /** HTTP path prefix (if applicable). */
  path?: string | null; // default: None
  /** Whether the transport is reachable/responding. */
  running: boolean;
}

/** Compact result shape for legacy /api/mcp/rag_search (debug UI). */
export interface MCPRagSearchResult {
  /** Matched file path. */
  file_path: string;
  /** Start line for the matched span. */
  start_line: number;
  /** End line for the matched span. */
  end_line: number;
  /** Legacy field: score for the match (post-fusion). */
  rerank_score: number;
}

/** Chat message in a conversation. */
export interface Message {
  /** Message role */
  role: "user" | "assistant" | "system";
  /** Message content */
  content: string;
  /** When message was created */
  timestamp?: string;
}

/** Unified gateway to 400+ cloud models. OpenAI-compatible.  MANDATORY P0 provider. */
export interface OpenRouterConfig {
  enabled?: boolean; // default: False
  api_key?: string; // default: ""
  base_url?: string; // default: "https://openrouter.ai/api/v1"
  default_model?: string; // default: "anthropic/claude-sonnet-4-20250514"
  site_name?: string; // default: "TriBridRAG"
  fallback_models?: string[]; // default: ["openai/gpt-4o", "google/gemini-2.0-flash"]
}

/** Health status for a configured provider endpoint. */
export interface ProviderHealth {
  /** Provider display name */
  provider: string;
  /** Provider kind */
  kind: "openrouter" | "local";
  /** Provider base URL */
  base_url: string;
  /** Whether the provider endpoint is reachable */
  reachable: boolean;
  /** Optional detail/error message */
  detail?: string | null; // default: None
}

/** Persistent chat memory. ON by default.  Indexes every conversation into a lightweight pgvector corpus. Self-hosted, local, zero privacy risk, negligible storage. */
export interface RecallConfig {
  /** Enable Recall. ON by default. */
  enabled?: boolean; // default: True
  /** pgvector recommended (already running). */
  vector_backend?: string; // default: "pgvector"
  auto_index?: boolean; // default: True
  index_delay_seconds?: number; // default: 5
  /** 'turn'=one chunk per message, 'sentence'=split by sentence. */
  chunking_strategy?: string; // default: "sentence"
  /** Chat chunks should be smaller than code chunks. */
  chunk_max_tokens?: number; // default: 256
  /** Override embedding model. Empty=use global config. */
  embedding_model?: string; // default: ""
  max_history_tokens?: number; // default: 4096
  /** Auto-created at first launch. Users never touch this. */
  default_corpus_id?: string; // default: "recall_default"
  /** Enable Recall graph indexing + retrieval (experimental). */
  graph_enabled?: boolean; // default: False
}

/** Per-message overrides applied when querying Recall.  The gate generates these. They do not permanently change config. They are applied only for this single Recall query. */
export interface RecallFusionOverrides {
  /** Override vector leg. None=use request/default. */
  include_vector?: boolean | null; // default: None
  /** Override sparse leg. None=use request/default. */
  include_sparse?: boolean | null; // default: None
  /** Override final_k for the Recall query. Lower than RAG since chat chunks are smaller. */
  top_k?: number | null; // default: None
  /** Override reranker for Recall. None=use config default. */
  enable_rerank?: boolean | null; // default: None
  /** How much to weight recent messages over relevance (0=relevance, 1=recency). */
  recency_weight?: number | null; // default: None
}

/** Configuration for the Recall gate. Lives at ChatConfig.recall_gate.  Controls the heuristic that decides per-message Recall behavior. NOTE: This only affects Recall (chat memory). RAG corpora are always queried when checked. */
export interface RecallGateConfig {
  /** Enable smart gating. False=always query Recall when checked. */
  enabled?: boolean; // default: True
  /** Fallback when classifier is uncertain. */
  default_intensity?: RecallIntensity; // default: "standard"
  /** Skip Recall for greetings, farewells, acknowledgments. */
  skip_greetings?: boolean; // default: True
  /** Skip Recall for questions that don't reference past context. 'How does auth work?' doesn't need chat history. */
  skip_standalone_questions?: boolean; // default: True
  /** Skip Recall when RAG corpora are checked. Assumes user wants code context, not chat history. Default False — let both contribute. */
  skip_when_rag_active?: boolean; // default: False
  /** Messages with ≤ this many tokens are skip candidates (only if they match a skip pattern). */
  skip_max_tokens?: number; // default: 4
  /** Use sparse-only for short questions (< 10 tokens) without explicit recall triggers. */
  light_for_short_questions?: boolean; // default: True
  /** top_k when intensity=light. */
  light_top_k?: number; // default: 3
  /** top_k for standard Recall queries. */
  standard_top_k?: number; // default: 5
  /** Default recency weight for Recall (recent messages often more relevant). */
  standard_recency_weight?: number; // default: 0.3
  /** Trigger deep when message explicitly references past conversation. */
  deep_on_explicit_reference?: boolean; // default: True
  /** top_k when intensity=deep. */
  deep_top_k?: number; // default: 10
  /** recency_weight for deep (higher when user explicitly asks about the past). */
  deep_recency_weight?: number; // default: 0.5
  /** Show gate decision (intensity, reason) in status bar. */
  show_gate_decision?: boolean; // default: True
  /** Show raw RecallSignals in debug footer (dev mode). */
  show_signals?: boolean; // default: False
}

/** How aggressively to query Recall (chat memory) for a single message.  NOTE: - This is an optimization hint decided per-message (or overridden by the user). - It only applies to the Recall corpus. Non-Recall RAG corpora are always queried when checked. */
export type RecallIntensity = "skip" | "light" | "standard" | "deep";

/** The gate's decision for whether/how to query Recall for a single message. */
export interface RecallPlan {
  /** How aggressively to query Recall. */
  intensity: RecallIntensity;
  /** Per-message parameter patches for Recall query. */
  fusion_overrides?: RecallFusionOverrides;
  /** Signals that drove this decision. */
  signals: RecallSignals;
  /** Human-readable explanation for the decision. E.g., 'Greeting — skipping Recall' or 'Past reference — querying Recall' */
  reason: string;
  /** True if the user manually overrode intensity for this message. */
  user_override?: boolean; // default: False
}

/** Signals extracted from the user's message + conversation context.  Used by the Recall gate to decide Recall intensity. Exposed in debug metadata. All fields are cheap to compute (no LLM calls, no embeddings). */
export interface RecallSignals {
  /** Approximate token count of message */
  token_count: number;
  /** Contains ? or interrogative pattern */
  is_question: boolean;
  /** Matches greeting/farewell patterns */
  is_greeting: boolean;
  /** 'ok', 'thanks', 'got it', etc. */
  is_acknowledgment: boolean;
  /** Continuation of prior topic — short message after retrieval-backed reply */
  is_follow_up: boolean;
  /** Explicit past reference: 'we discussed', 'you mentioned', 'last time', 'remember when', 'as I said before' */
  is_recall_trigger: boolean;
  /** 'the function', 'the bug', 'the config' — assumes shared context */
  has_definite_article: boolean;
  /** Question that makes sense without conversation history (code/concept questions vs 'what did we decide?') */
  is_standalone_question: boolean;
  /** 0-indexed user turn number in current conversation */
  conversation_turn: number;
  /** Did the previous message's Recall query return >0 chunks? */
  last_recall_had_results?: boolean; // default: True
  /** Are any non-Recall corpora checked? */
  rag_corpora_active: boolean;
}

/** Knowledge graph edge connecting two entities. */
export interface Relationship {
  /** Source entity ID */
  source_id: string;
  /** Target entity ID */
  target_id: string;
  /** Type of relationship */
  relation_type: "calls" | "imports" | "inherits" | "contains" | "references" | "related_to";
  /** Relationship strength */
  weight?: number; // default: 1.0
  /** Additional properties */
  properties?: Record<string, unknown>;
}

export interface RerankerTrainMetricEvent {
  type: "log" | "progress" | "metrics" | "state" | "error" | "complete";
  /** UTC timestamp */
  ts: string;
  run_id: string;
  step?: number | null; // default: None
  epoch?: number | null; // default: None
  message?: string | null; // default: None
  percent?: number | null; // default: None
  metrics?: Record<string, number> | null; // default: None
  status?: "queued" | "running" | "completed" | "failed" | "cancelled" | null; // default: None
}

export interface RerankerTrainRun {
  /** Unique identifier for this training run */
  run_id: string;
  /** Corpus identifier */
  corpus_id: string;
  status?: "queued" | "running" | "completed" | "failed" | "cancelled"; // default: "queued"
  /** UTC start time */
  started_at: string;
  /** UTC completion time */
  completed_at?: string | null; // default: None
  /** Nested TriBridConfig snapshot (mode='json') */
  config_snapshot: Record<string, unknown>;
  /** Flat env-style config snapshot */
  config?: Record<string, unknown>;
  /** Run-locked headline metric */
  primary_metric: "mrr" | "ndcg" | "map";
  /** Run-locked k for @k metrics */
  primary_k: number;
  /** e.g. ['mrr@10','ndcg@10','map'] */
  metrics_available?: string[];
  /** Profile snapshot used to choose primary_metric/primary_k */
  metric_profile: CorpusEvalProfile;
  epochs: number;
  batch_size: number;
  lr: number;
  warmup_ratio: number;
  max_length: number;
  summary?: RerankerTrainRunSummary;
}

export interface RerankerTrainRunMeta {
  run_id: string;
  corpus_id: string;
  status: "queued" | "running" | "completed" | "failed" | "cancelled";
  started_at: string;
  completed_at?: string | null; // default: None
  primary_metric: "mrr" | "ndcg" | "map";
  primary_k: number;
  primary_metric_best?: number | null; // default: None
  primary_metric_final?: number | null; // default: None
}

export interface RerankerTrainRunSummary {
  primary_metric_best?: number | null; // default: None
  primary_metric_final?: number | null; // default: None
  best_step?: number | null; // default: None
  time_to_best_secs?: number | null; // default: None
  /** Late-training stddev of primary metric */
  stability_stddev?: number | null; // default: None
}

/** Reranking configuration for result refinement. */
export interface RerankingConfig {
  /** Reranker mode: 'cloud' (Cohere/Voyage API), 'local' (HuggingFace cross-encoder), 'learning' (TRIBRID cross-encoder-tribrid), 'none' (disabled) */
  reranker_mode?: string; // default: "none"
  /** Cloud reranker provider when mode=cloud (cohere, voyage, jina) */
  reranker_cloud_provider?: string; // default: "cohere"
  /** Cloud reranker model name when mode=cloud (Cohere: rerank-v3.5) */
  reranker_cloud_model?: string; // default: "rerank-v3.5"
  /** Local HuggingFace cross-encoder model when mode=local */
  reranker_local_model?: string; // default: "cross-encoder/ms-marco-MiniLM-L-12-v2"
  /** Blend weight for reranker scores */
  tribrid_reranker_alpha?: number; // default: 0.7
  /** Number of candidates to rerank (local/learning mode) */
  tribrid_reranker_topn?: number; // default: 50
  /** Number of candidates to rerank (cloud mode) */
  reranker_cloud_top_n?: number; // default: 50
  /** Reranker batch size */
  tribrid_reranker_batch?: number; // default: 16
  /** Max token length for reranker */
  tribrid_reranker_maxlen?: number; // default: 512
  /** Hot-reload on model change */
  tribrid_reranker_reload_on_change?: number; // default: 0
  /** Reload check period (seconds) */
  tribrid_reranker_reload_period_sec?: number; // default: 60
  /** Reranker API timeout (seconds) */
  reranker_timeout?: number; // default: 10
  /** Snippet chars for reranking input */
  rerank_input_snippet_chars?: number; // default: 700
  /** Allow transformers remote code for HF rerankers that require it */
  transformers_trust_remote_code?: number; // default: 1
}

/** Configuration for retrieval and search parameters. */
export interface RetrievalConfig {
  /** RRF rank smoothing constant (higher = more weight to top ranks) */
  rrf_k_div?: number; // default: 60
  /** Number of final results to return in LangGraph pipeline */
  langgraph_final_k?: number; // default: 20
  /** Maximum number of query rewrites for multi-query expansion */
  max_query_rewrites?: number; // default: 2
  /** Maximum number of query rewrites for LangGraph pipeline */
  langgraph_max_query_rewrites?: number; // default: 2
  /** Confidence threshold for fallback retrieval strategies */
  fallback_confidence?: number; // default: 0.55
  /** Default top-k for search results */
  final_k?: number; // default: 10
  /** Top-k for evaluation runs */
  eval_final_k?: number; // default: 5
  /** Confidence threshold for top-1 */
  conf_top1?: number; // default: 0.62
  /** Confidence threshold for avg top-5 */
  conf_avg5?: number; // default: 0.55
  /** Minimum confidence threshold */
  conf_any?: number; // default: 0.55
  /** Enable multi-query in eval */
  eval_multi?: number; // default: 1
  /** Enable synonym expansion */
  query_expansion_enabled?: number; // default: 1
  /** Weight for BM25 in hybrid search */
  bm25_weight?: number; // default: 0.3
  /** BM25 term frequency saturation parameter (higher = more weight to term frequency) */
  bm25_k1?: number; // default: 1.2
  /** BM25 length normalization (0=no penalty, 1=full penalty, 0.3-0.5 recommended for code) */
  bm25_b?: number; // default: 0.4
  /** Weight for vector search */
  vector_weight?: number; // default: 0.7
  /** Enable chunk_summary-based retrieval */
  chunk_summary_search_enabled?: number; // default: 1
  /** Query variants for multi-query */
  multi_query_m?: number; // default: 4
  /** Enable semantic synonym expansion */
  use_semantic_synonyms?: number; // default: 1
  /** Custom path to semantic_synonyms.json (default: data/semantic_synonyms.json) */
  tribrid_synonyms_path?: string; // default: ""
  /** Top-K for dense vector search */
  topk_dense?: number; // default: 75
  /** Top-K for sparse BM25 search */
  topk_sparse?: number; // default: 75
  /** Result hydration mode */
  hydration_mode?: string; // default: "lazy"
  /** Max characters for result hydration */
  hydration_max_chars?: number; // default: 2000
}

/** Configuration for result scoring and boosting. */
export interface ScoringConfig {
  /** Bonus score for chunks matched via chunk_summary-based retrieval */
  chunk_summary_bonus?: number; // default: 0.08
  /** Score multiplier when filename exactly matches query terms */
  filename_boost_exact?: number; // default: 1.5
  /** Score multiplier when path components match query terms */
  filename_boost_partial?: number; // default: 1.2
  /** Vendor code preference */
  vendor_mode?: string; // default: "prefer_first_party"
  /** Comma-separated path prefixes to boost */
  path_boosts?: string; // default: "/gui,/server,/indexer,/retrieval"
}

/** Configuration for sparse (BM25) search. */
export interface SparseSearchConfig {
  /** Enable sparse BM25 search in tri-brid retrieval */
  enabled?: boolean; // default: True
  /** Number of results to retrieve from sparse search */
  top_k?: number; // default: 50
  /** BM25 term frequency saturation (higher = more weight to term frequency) */
  bm25_k1?: number; // default: 1.2
  /** BM25 length normalization (0 = no penalty, 1 = full penalty) */
  bm25_b?: number; // default: 0.4
}

/** System prompts for LLM interactions - affects RAG pipeline behavior.  These prompts control how LLMs behave during query processing, code analysis, and result generation. Changes here can significantly impact RAG accuracy. */
export interface SystemPromptsConfig {
  /** Main conversational AI system prompt for answering codebase questions */
  main_rag_chat?: string; // default: "You are an expert software engineer and code an..."
  /** Generate query variants for better recall in hybrid search */
  query_expansion?: string; // default: "You are a code search query expander. Given a d..."
  /** Optimize user query for code search - expand CamelCase, include API nouns */
  query_rewrite?: string; // default: "You rewrite developer questions into search-opt..."
  /** Generate JSON summaries for code chunks during indexing */
  semantic_chunk_summaries?: string; // default: "Analyze this code chunk and create a comprehens..."
  /** Extract metadata from code chunks during indexing */
  code_enrichment?: string; // default: "Analyze this code and return a JSON object with..."
  /** Prompt for LLM-assisted semantic KG extraction (concepts + relations) */
  semantic_kg_extraction?: string; // default: "You are a semantic knowledge graph extractor.\n..."
  /** Analyze eval regressions with skeptical approach - avoid false explanations */
  eval_analysis?: string; // default: "You are an expert RAG (Retrieval-Augmented Gene..."
  /** Lightweight chunk_summary generation prompt for faster indexing */
  lightweight_chunk_summaries?: string; // default: "Extract key information from this code: symbols..."
}

/** Trace payload for a single run. */
export interface Trace {
  /** Run identifier for correlation */
  run_id: string;
  /** Corpus identifier */
  corpus_id: string;
  /** Run start time (epoch milliseconds) */
  started_at_ms: number;
  /** Run end time (epoch milliseconds) */
  ended_at_ms?: number | null; // default: None
  /** Ordered trace events */
  events?: TraceEvent[];
}

/** Single trace event (local tracing). */
export interface TraceEvent {
  /** Event kind identifier (e.g., retrieval.vector, fusion.rrf) */
  kind: string;
  /** Event timestamp (epoch milliseconds) */
  ts: number;
  /** Human-readable event message */
  msg?: string | null; // default: None
  /** Structured event payload */
  data?: Record<string, unknown>;
}

/** Observability and tracing configuration. */
export interface TracingConfig {
  /** Enable distributed tracing */
  tracing_enabled?: number; // default: 1
  /** Trace sampling rate (0.0-1.0) */
  trace_sampling_rate?: number; // default: 1.0
  /** Prometheus metrics port */
  prometheus_port?: number; // default: 9090
  /** Enable metrics collection */
  metrics_enabled?: number; // default: 1
  /** Include resolved alerts */
  alert_include_resolved?: number; // default: 1
  /** Alert webhook timeout (seconds) */
  alert_webhook_timeout?: number; // default: 5
  /** Logging level */
  log_level?: string; // default: "INFO"
  /** Tracing backend mode */
  tracing_mode?: string; // default: "langsmith"
  /** Auto-enable LangSmith tracing */
  trace_auto_ls?: number; // default: 1
  /** Number of traces to retain */
  trace_retention?: number; // default: 50
  /** Query log file path */
  tribrid_log_path?: string; // default: "data/logs/queries.jsonl"
  /** Alert severities to notify */
  alert_notify_severities?: string; // default: "critical,warning"
  /** LangChain/LangSmith API endpoint */
  langchain_endpoint?: string; // default: "https://api.smith.langchain.com"
  /** LangChain project name */
  langchain_project?: string; // default: "tribrid"
  /** Enable LangChain v2 tracing */
  langchain_tracing_v2?: number; // default: 0
  /** LangTrace API host */
  langtrace_api_host?: string; // default: ""
  /** LangTrace project ID */
  langtrace_project_id?: string; // default: ""
}

/** Reranker training configuration. */
export interface TrainingConfig {
  /** Training epochs for reranker */
  reranker_train_epochs?: number; // default: 2
  /** Training batch size */
  reranker_train_batch?: number; // default: 16
  /** Learning rate */
  reranker_train_lr?: number; // default: 2e-05
  /** Warmup steps ratio */
  reranker_warmup_ratio?: number; // default: 0.1
  /** Min triplets for training */
  triplets_min_count?: number; // default: 100
  /** Triplet mining mode */
  triplets_mine_mode?: string; // default: "replace"
  /** Reranker model path */
  tribrid_reranker_model_path?: string; // default: "models/cross-encoder-tribrid"
  /** Triplet mining mode */
  tribrid_reranker_mine_mode?: string; // default: "replace"
  /** Reset triplets file before mining */
  tribrid_reranker_mine_reset?: number; // default: 0
  /** Training triplets file path */
  tribrid_triplets_path?: string; // default: "data/training/triplets.jsonl"
}

/** User interface configuration. */
export interface UIConfig {
  /** Enable streaming responses */
  chat_streaming_enabled?: number; // default: 1
  /** Max chat history messages */
  chat_history_max?: number; // default: 50
  /** Include reasoning/thinking in streamed responses when supported by model */
  chat_stream_include_thinking?: number; // default: 1
  /** Show confidence badge on chat answers */
  chat_show_confidence?: number; // default: 0
  /** Show citations list on chat answers */
  chat_show_citations?: number; // default: 1
  /** Show routing trace panel by default */
  chat_show_trace?: number; // default: 1
  /** Show dev/debug footer under chat answers */
  chat_show_debug_footer?: number; // default: 1
  /** Default model for chat if not specified in request */
  chat_default_model?: string; // default: "gpt-4o-mini"
  /** Streaming response timeout in seconds */
  chat_stream_timeout?: number; // default: 120
  /** Max thinking tokens for Anthropic extended thinking */
  chat_thinking_budget_tokens?: number; // default: 10000
  /** Embedded editor port */
  editor_port?: number; // default: 4440
  /** Default Grafana dashboard UID */
  grafana_dashboard_uid?: string; // default: "tribrid-overview"
  /** Grafana dashboard slug */
  grafana_dashboard_slug?: string; // default: "tribrid-overview"
  /** Grafana base URL */
  grafana_base_url?: string; // default: "http://127.0.0.1:3001"
  /** Grafana authentication mode */
  grafana_auth_mode?: string; // default: "anonymous"
  /** Enable Grafana embedding */
  grafana_embed_enabled?: number; // default: 1
  /** Grafana kiosk mode */
  grafana_kiosk?: string; // default: "tv"
  /** Grafana organization ID */
  grafana_org_id?: number; // default: 1
  /** Grafana refresh interval */
  grafana_refresh?: string; // default: "10s"
  /** Editor bind mode */
  editor_bind?: string; // default: "local"
  /** Enable editor embedding */
  editor_embed_enabled?: number; // default: 1
  /** Enable embedded editor */
  editor_enabled?: number; // default: 1
  /** Editor Docker image */
  editor_image?: string; // default: "codercom/code-server:latest"
  /** UI theme mode */
  theme_mode?: string; // default: "dark"
  /** Auto-open browser on start */
  open_browser?: number; // default: 1
  /** Runtime environment mode (development uses localhost, production uses deployed URLs) */
  runtime_mode?: "development" | "production"; // default: "development"
}

/** Configuration for vector (dense) search using pgvector. */
export interface VectorSearchConfig {
  /** Enable vector search in tri-brid retrieval */
  enabled?: boolean; // default: True
  /** Number of results to retrieve from vector search */
  top_k?: number; // default: 50
  /** Minimum similarity score threshold (0 = no threshold) */
  similarity_threshold?: number; // default: 0.0
}

/** A single term in the Postgres FTS vocabulary preview. */
export interface VocabPreviewTerm {
  /** Tokenized lexeme */
  term: string;
  /** Number of chunks containing this term */
  doc_count: number;
}

/** Request payload for AI answer generation. */
export interface AnswerRequest {
  /** The question to answer */
  query: string;
  /** Corpus identifier */
  corpus_id: string;
  /** Number of chunks to use as context */
  top_k?: number;
  /** Stream the response */
  stream?: boolean;
  /** Override system prompt */
  system_prompt?: string | null;
}

/** Response from AI answer generation. */
export interface AnswerResponse {
  /** The original question */
  query: string;
  /** Generated answer */
  answer: string;
  /** Chunks used to generate answer */
  sources: ChunkMatch[];
  /** Model used for generation */
  model: string;
  /** Total tokens consumed */
  tokens_used: number;
  /** Generation latency in milliseconds */
  latency_ms: number;
}

/** Response payload for GET /api/chat/models. */
export interface ChatModelsResponse {
  models?: ChatModelInfo[];
}

/** Chat request — composable data sources, not modes. */
export interface ChatRequest {
  /** User's message */
  message: string;
  /** Corpus identifier */
  corpus_id?: string;
  /** Checked sources. Empty corpus_ids = no retrieval. If recall_default is not present, Recall is OFF for both retrieval and indexing. */
  sources?: ActiveSources;
  /** User override for Recall (chat memory) query intensity. None=auto (gate decides). Does not affect RAG corpus queries. */
  recall_intensity?: RecallIntensity | null;
  /** Continue existing conversation */
  conversation_id?: string | null;
  /** Stream the response */
  stream?: boolean;
  /** Optional images for vision (max 5) */
  images?: ImageAttachment[];
  /** Override chat model for this request (empty=default) */
  model_override?: string;
  /** Include vector retrieval results */
  include_vector?: boolean;
  /** Include sparse/BM25 retrieval results */
  include_sparse?: boolean;
  /** Advanced. Graph leg runs per-corpus; Recall only if ChatConfig.recall.graph_enabled. */
  include_graph?: boolean;
  /** Override retrieval.final_k for this message (leave null to use config default) */
  top_k?: number | null;
}

/** Response from chat endpoint. */
export interface ChatResponse {
  /** Unique identifier for this chat run (trace/log correlation) */
  run_id: string;
  /** Chat run start time (epoch milliseconds) */
  started_at_ms: number;
  /** Chat run end time (epoch milliseconds) */
  ended_at_ms?: number | null;
  /** Developer debug metadata for this answer */
  debug?: ChatDebugInfo | null;
  /** Conversation identifier */
  conversation_id: string;
  /** Assistant's response message */
  message: Message;
  /** Sources used for response */
  sources: ChunkMatch[];
  /** Tokens consumed */
  tokens_used: number;
}

/** A code chunk from the indexed repository. */
export interface Chunk {
  /** Unique identifier for this chunk */
  chunk_id: string;
  /** The actual code/text content */
  content: string;
  /** Path to the source file */
  file_path: string;
  /** Starting line number in source file */
  start_line: number;
  /** Ending line number in source file */
  end_line: number;
  /** Programming language */
  language?: string | null;
  /** Token count for embedding budget */
  token_count?: number;
  /** Vector embedding */
  embedding?: number[] | null;
  /** AI-generated chunk summary */
  summary?: string | null;
  /** Arbitrary chunk metadata */
  metadata?: Record<string, unknown>;
}

/** Request to build chunk_summaries for a repository. */
export interface ChunkSummariesBuildRequest {
  /** Corpus identifier */
  corpus_id: string;
  /** Override max summaries to build */
  max?: number | null;
  /** Override enrichment toggle for this build */
  enrich?: boolean | null;
}

/** Response payload for chunk_summaries list/build endpoints. */
export interface ChunkSummariesResponse {
  /** Corpus identifier */
  corpus_id: string;
  /** Chunk summaries for this repo */
  chunk_summaries: ChunkSummary[];
  /** Metadata about the last build, if any */
  last_build?: ChunkSummariesLastBuild | null;
}

/** Knowledge graph community/cluster of related entities. */
export interface Community {
  /** Unique identifier */
  community_id: string;
  /** Community name */
  name: string;
  /** AI-generated summary of what this community represents */
  summary: string;
  /** Entity IDs that belong to this community */
  member_ids: string[];
  /** Hierarchy level (0 = top level) */
  level: number;
}

/** User-managed corpus (formerly "repo" in earlier versions).  A corpus is the unit of isolation for: - indexing storage (Postgres) - graph storage (Neo4j) - configuration (per-corpus TriBridConfig) */
export interface Corpus {
  /** Corpus identifier (stable slug) */
  corpus_id: string;
  /** Display name */
  name: string;
  /** Root path on disk */
  path: string;
  /** Legacy alias for repo_id (UI compatibility) */
  slug?: string | null;
  /** Optional branch name (if corpus is a git repo) */
  branch?: string | null;
  /** Whether this corpus is the default selection */
  default?: boolean | null;
  /** Paths to exclude during indexing */
  exclude_paths?: string[] | null;
  /** Corpus-specific keyword boosts */
  keywords?: string[] | null;
  /** Path boost prefixes for scoring */
  path_boosts?: string[] | null;
  /** Optional layer bonus overrides (intent->layer->multiplier) */
  layer_bonuses?: Record<string, Record<string, number>> | null;
  /** Optional description */
  description?: string | null;
  /** When the corpus was created */
  created_at?: string;
  /** When the corpus was last indexed */
  last_indexed?: string | null;
}

/** Request to create a new corpus. */
export interface CorpusCreateRequest {
  /** Optional corpus ID; generated from name if omitted */
  corpus_id?: string | null;
  /** Display name */
  name: string;
  /** Root path on disk */
  path: string;
  /** Optional description */
  description?: string | null;
}

/** High-level corpus stats for UI dashboards. */
export interface CorpusStats {
  /** Corpus identifier */
  corpus_id: string;
  /** Number of files in corpus */
  file_count: number;
  /** Total size of corpus files (bytes) */
  total_size_bytes: number;
  /** Language->file count breakdown */
  language_breakdown: Record<string, number>;
  /** Index stats (if indexed) */
  index_stats?: IndexStats | null;
  /** Graph stats (if built) */
  graph_stats?: GraphStats | null;
}

/** Request to update an existing corpus. All fields optional. */
export interface CorpusUpdateRequest {
  /** Display name */
  name?: string | null;
  /** Root path on disk */
  path?: string | null;
  /** Git branch (if applicable) */
  branch?: string | null;
  /** Paths to exclude during indexing */
  exclude_paths?: string[] | null;
  /** Corpus-specific keyword boosts */
  keywords?: string[] | null;
  /** Path patterns for scoring boosts */
  path_boosts?: string[] | null;
  /** Nested map for layer bonus scoring */
  layer_bonuses?: Record<string, Record<string, number>> | null;
}

/** Response payload for Dashboard storage panels. */
export interface DashboardIndexStatsResponse {
  /** Corpus identifier */
  corpus_id: string;
  /** Storage breakdown (bytes) for major components. */
  storage_breakdown?: DashboardIndexStorageBreakdown;
  /** Number of keywords for this corpus (if generated). */
  keywords_count?: number;
  /** Total storage bytes (Postgres + Neo4j). */
  total_storage?: number;
}

/** Response payload for Dashboard index status panel. */
export interface DashboardIndexStatusResponse {
  /** Human-readable status lines for fallback display. */
  lines?: string[];
  /** Structured status metadata. */
  metadata?: DashboardIndexStatusMetadata | null;
  /** Whether indexing is currently running for this corpus. */
  running?: boolean;
  /** Indexing progress from 0.0 to 1.0 when running. */
  progress?: number | null;
  /** File currently being indexed (if running). */
  current_file?: string | null;
}

/** Response payload for a dev stack restart operation. */
export interface DevStackRestartResponse {
  /** Whether the operation was accepted and executed successfully. */
  success: boolean;
  /** Human-readable success message. */
  message?: string | null;
  /** Error message (if success=false). */
  error?: string | null;
  /** Frontend port (if applicable). */
  frontend_port?: number | null;
  /** Backend port (if applicable). */
  backend_port?: number | null;
}

/** Status of the local dev stack (frontend + backend). */
export interface DevStackStatusResponse {
  /** Whether the dev frontend (Vite) is reachable. */
  frontend_running: boolean;
  /** Whether the dev backend (FastAPI/Uvicorn) is reachable. */
  backend_running: boolean;
  /** Port for dev frontend (Vite). */
  frontend_port: number;
  /** Port for dev backend (Uvicorn). */
  backend_port: number;
  /** Resolved frontend URL (if known). */
  frontend_url?: string | null;
  /** Resolved backend URL (if known). */
  backend_url?: string | null;
  /** Human-readable diagnostic details (best-effort). */
  details?: string[];
}

/** Response payload for /api/docker/containers (and /api/docker/containers/all). */
export interface DockerContainersResponse {
  /** List of Docker containers. */
  containers?: DockerContainer[];
}

/** Response payload for /api/docker/status. */
export interface DockerStatus {
  /** Whether Docker is available and responding. */
  running?: boolean;
  /** Runtime label/version string (best-effort). */
  runtime?: string;
  /** Total number of containers (docker ps -aq). */
  containers_count?: number;
}

/** Response for /eval/analyze_comparison. */
export interface EvalAnalyzeComparisonResponse {
  /** Whether analysis succeeded */
  ok?: boolean;
  /** Markdown analysis */
  analysis?: string | null;
  /** Model identifier (if any) */
  model_used?: string | null;
  /** Error message (if any) */
  error?: string | null;
}

/** Comparison between two evaluation runs. */
export interface EvalComparisonResult {
  /** Baseline run ID */
  baseline_run_id: string;
  /** Current run ID being compared */
  current_run_id: string;
  /** Baseline run metrics */
  baseline_metrics: EvalMetrics;
  /** Current run metrics */
  current_metrics: EvalMetrics;
  /** Change in MRR (positive = improvement) */
  delta_mrr: number;
  /** Change in recall@10 */
  delta_recall_at_10: number;
  /** Entry IDs that improved */
  improved_entries?: string[];
  /** Entry IDs that degraded */
  degraded_entries?: string[];
}

/** Single evaluation dataset entry (formerly DatasetEntry). */
export interface EvalDatasetItem {
  /** Unique identifier for this entry */
  entry_id?: string;
  /** The test question */
  question: string;
  /** File paths that should be retrieved (relative or absolute) */
  expected_paths: string[];
  /** Expected answer if testing generation */
  expected_answer?: string | null;
  /** Tags for filtering/grouping */
  tags?: string[];
  /** When this entry was created */
  created_at?: string;
}

/** Request payload for evaluation run. */
export interface EvalRequest {
  /** Corpus identifier to evaluate */
  corpus_id: string;
  /** Dataset to use (None = default) */
  dataset_id?: string | null;
  /** Number of entries to sample (None = all) */
  sample_size?: number | null;
}

/** Complete evaluation run record. */
export interface EvalRun {
  /** Unique identifier for this run */
  run_id: string;
  /** Corpus identifier evaluated */
  corpus_id: string;
  /** Dataset used */
  dataset_id: string;
  /** Nested config state during evaluation */
  config_snapshot: Record<string, unknown>;
  /** Flat env-style config snapshot (for UI) */
  config?: Record<string, unknown>;
  /** Total questions evaluated */
  total?: number;
  /** Count of top-1 hits */
  top1_hits?: number;
  /** Count of top-k hits */
  topk_hits?: number;
  /** Top-1 accuracy */
  top1_accuracy?: number;
  /** Top-k accuracy */
  topk_accuracy?: number;
  /** Total run duration (seconds) */
  duration_secs?: number;
  /** Whether multi-query was enabled for this run */
  use_multi?: boolean;
  /** Final-k used for this run */
  final_k?: number;
  /** Aggregated metrics */
  metrics: EvalMetrics;
  /** Per-entry results */
  results: EvalResult[];
  /** When evaluation started */
  started_at: string;
  /** When evaluation completed */
  completed_at: string;
}

/** Response for listing eval runs. */
export interface EvalRunsResponse {
  /** Whether the request succeeded */
  ok?: boolean;
  /** Run summaries (newest first) */
  runs?: EvalRunMeta[];
}

/** Request payload for testing a single eval_dataset entry. */
export interface EvalTestRequest {
  /** Corpus identifier to evaluate */
  corpus_id: string;
  /** The test question */
  question: string;
  /** Expected file paths to retrieve */
  expected_paths: string[];
  /** Optional override for multi-query */
  use_multi?: boolean | null;
  /** Optional override for final-k */
  final_k?: number | null;
}

/** Neighbor subgraph centered on a single entity. */
export interface GraphNeighborsResponse {
  /** Entities in the neighborhood (includes the center entity) */
  entities: Entity[];
  /** Relationships between returned entities */
  relationships: Relationship[];
}

/** System health status payload for /api/health. */
export interface HealthStatus {
  /** Overall health boolean. */
  ok?: boolean;
  /** Overall status label. */
  status?: "healthy" | "unhealthy" | "unknown";
  /** Timestamp for this health snapshot (UTC). */
  ts?: string;
  /** Map of service name -> status entry. */
  services?: Record<string, HealthServiceStatus>;
}

/** Request to index a repository. */
export interface IndexRequest {
  /** Corpus identifier */
  corpus_id: string;
  /** Path to repository on disk */
  repo_path: string;
  /** Force full reindex even if up-to-date */
  force_reindex?: boolean;
}

/** Current status of repository indexing. */
export interface IndexStatus {
  /** Corpus identifier */
  corpus_id: string;
  /** Current indexing state */
  status: "idle" | "indexing" | "complete" | "error";
  /** Progress from 0.0 to 1.0 */
  progress: number;
  /** File currently being indexed */
  current_file?: string | null;
  /** Error message if status is 'error' */
  error?: string | null;
  /** When indexing started */
  started_at?: string | null;
  /** When indexing completed */
  completed_at?: string | null;
}

/** Request to generate discriminative keywords for a repository. */
export interface KeywordsGenerateRequest {
  /** Corpus identifier */
  corpus_id: string;
}

/** Response payload for keywords generation. */
export interface KeywordsGenerateResponse {
  /** Corpus identifier */
  corpus_id: string;
  /** Generated keywords */
  keywords: string[];
  /** Number of keywords returned */
  count: number;
}

/** Response payload for /api/loki/status. */
export interface LokiStatus {
  /** Whether Loki is reachable. */
  reachable?: boolean;
  /** Resolved Loki base URL if reachable (best-effort). */
  url?: string | null;
  /** Human-readable status label (best-effort). */
  status?: string;
}

/** Response payload for legacy /api/mcp/rag_search (debug UI). */
export interface MCPRagSearchResponse {
  /** Compact match list. */
  results?: MCPRagSearchResult[];
  /** Error message when the search fails. */
  error?: string | null;
}

/** Status of MCP transports built into TriBridRAG. */
export interface MCPStatusResponse {
  /** Python MCP over HTTP transport status (if implemented/enabled). */
  python_http?: MCPHTTPTransportStatus | null;
  /** Node MCP over HTTP transport status (if implemented/enabled). */
  node_http?: MCPHTTPTransportStatus | null;
  /** Whether the Python stdio MCP transport is available (client-spawned). */
  python_stdio_available?: boolean;
  /** Human-readable diagnostic details (best-effort). */
  details?: string[];
}

/** Response payload for GET /api/chat/health. */
export interface ProvidersHealthResponse {
  providers?: ProviderHealth[];
}

/** Request payload for POST /api/recall/index. */
export interface RecallIndexRequest {
  /** Conversation identifier to index into Recall */
  conversation_id: string;
}

/** Response payload for POST /api/recall/index. */
export interface RecallIndexResponse {
  /** Whether indexing was triggered */
  ok: boolean;
  /** Conversation identifier */
  conversation_id: string;
  /** Number of chunks indexed into Recall */
  chunks_indexed?: number;
}

/** Response payload for GET /api/recall/status. */
export interface RecallStatusResponse {
  /** Whether Recall is enabled */
  enabled: boolean;
  /** Recall corpus id (default recall_default) */
  corpus_id: string;
  /** Whether the Recall corpus exists in Postgres */
  exists: boolean;
  /** Approximate number of chunks stored for Recall */
  chunk_count?: number;
}

export interface RerankerTrainDiffRequest {
  baseline_run_id: string;
  current_run_id: string;
}

export interface RerankerTrainDiffResponse {
  ok?: boolean;
  /** False if primary metric/k differ */
  compatible?: boolean;
  reason?: string | null;
  primary_metric?: "mrr" | "ndcg" | "map" | null;
  primary_k?: number | null;
  baseline_primary_best?: number | null;
  current_primary_best?: number | null;
  delta_primary_best?: number | null;
  baseline_time_to_best_secs?: number | null;
  current_time_to_best_secs?: number | null;
  delta_time_to_best_secs?: number | null;
  baseline_stability_stddev?: number | null;
  current_stability_stddev?: number | null;
  delta_stability_stddev?: number | null;
}

export interface RerankerTrainMetricsResponse {
  ok?: boolean;
  events?: RerankerTrainMetricEvent[];
}

export interface RerankerTrainRunsResponse {
  ok?: boolean;
  runs?: RerankerTrainRunMeta[];
}

export interface RerankerTrainStartRequest {
  /** Corpus identifier to train against */
  corpus_id: string;
  /** Override metric (else use profile) */
  primary_metric?: "mrr" | "ndcg" | "map" | null;
  /** Override k (else use profile) */
  primary_k?: number | null;
  epochs?: number | null;
  batch_size?: number | null;
  lr?: number | null;
  warmup_ratio?: number | null;
  max_length?: number | null;
}

export interface RerankerTrainStartResponse {
  ok?: boolean;
  run_id: string;
  run: RerankerTrainRun;
}

/** Request payload for tri-brid search. */
export interface SearchRequest {
  /** The search query */
  query: string;
  /** Corpus identifier to search */
  corpus_id: string;
  /** Number of results to return */
  top_k?: number;
  /** Include vector search results */
  include_vector?: boolean;
  /** Include sparse/BM25 results */
  include_sparse?: boolean;
  /** Include graph search results */
  include_graph?: boolean;
}

/** Response from tri-brid search. */
export interface SearchResponse {
  /** The original query */
  query: string;
  /** Ranked list of matching chunks */
  matches: ChunkMatch[];
  /** Fusion method used (rrf or weighted) */
  fusion_method: string;
  /** Reranker mode used */
  reranker_mode: string;
  /** Search latency in milliseconds */
  latency_ms: number;
  /** Debug information if requested */
  debug?: Record<string, unknown> | null;
}

/** Response payload for /api/traces/latest. */
export interface TracesLatestResponse {
  /** Corpus identifier for the returned trace (if any) */
  repo?: string | null;
  /** Run identifier for the returned trace (if any) */
  run_id?: string | null;
  /** Trace payload (null if none available) */
  trace?: Trace | null;
}

/** TRIBRID RAG Engine tunable configuration parameters */
export interface TriBridConfig {
  retrieval?: RetrievalConfig;
  scoring?: ScoringConfig;
  layer_bonus?: LayerBonusConfig;
  embedding?: EmbeddingConfig;
  chunking?: ChunkingConfig;
  indexing?: IndexingConfig;
  graph_storage?: GraphStorageConfig;
  graph_indexing?: GraphIndexingConfig;
  fusion?: FusionConfig;
  vector_search?: VectorSearchConfig;
  sparse_search?: SparseSearchConfig;
  graph_search?: GraphSearchConfig;
  reranking?: RerankingConfig;
  generation?: GenerationConfig;
  enrichment?: EnrichmentConfig;
  chunk_summaries?: ChunkSummaryConfig;
  keywords?: KeywordsConfig;
  tracing?: TracingConfig;
  training?: TrainingConfig;
  ui?: UIConfig;
  chat?: ChatConfig;
  hydration?: HydrationConfig;
  evaluation?: EvaluationConfig;
  system_prompts?: SystemPromptsConfig;
  mcp?: MCPConfig;
  docker?: DockerConfig;
}

/** Response payload for the vocab preview endpoint. */
export interface VocabPreviewResponse {
  /** Corpus identifier */
  corpus_id: string;
  /** Number of top terms requested */
  top_n: number;
  /** BM25 tokenizer setting (indexing.bm25_tokenizer) */
  tokenizer: string;
  /** Stemmer language (indexing.bm25_stemmer_lang) */
  stemmer_lang?: string | null;
  /** Stopwords language code (indexing.bm25_stopwords_lang) */
  stopwords_lang?: string | null;
  /** Postgres text search configuration used for tsv + query parsing */
  ts_config: string;
  /** Total unique terms in the corpus vocabulary */
  total_terms: number;
  /** Top terms by document frequency */
  terms?: VocabPreviewTerm[];
}
