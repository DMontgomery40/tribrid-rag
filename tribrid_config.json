{
  "retrieval": {
    "rrf_k_div": 60,
    "langgraph_final_k": 20,
    "max_query_rewrites": 2,
    "langgraph_max_query_rewrites": 2,
    "fallback_confidence": 0.55,
    "final_k": 10,
    "eval_final_k": 5,
    "conf_top1": 0.62,
    "conf_avg5": 0.55,
    "conf_any": 0.55,
    "eval_multi": 1,
    "query_expansion_enabled": 1,
    "bm25_weight": 0.3,
    "bm25_k1": 1.2,
    "bm25_b": 0.4,
    "vector_weight": 0.7,
    "chunk_summary_search_enabled": 1,
    "max_chunks_per_file": 3,
    "dedup_by": "chunk_id",
    "neighbor_window": 1,
    "min_score_vector": 0.0,
    "min_score_sparse": 0.0,
    "min_score_graph": 0.0,
    "enable_mmr": false,
    "mmr_lambda": 0.7,
    "multi_query_m": 4,
    "use_semantic_synonyms": 1,
    "tribrid_synonyms_path": "",
    "topk_dense": 75,
    "topk_sparse": 75,
    "hydration_mode": "lazy",
    "hydration_max_chars": 2000
  },
  "scoring": {
    "chunk_summary_bonus": 0.08,
    "filename_boost_exact": 1.5,
    "filename_boost_partial": 1.2,
    "vendor_mode": "prefer_first_party",
    "path_boosts": "/gui,/server,/indexer,/retrieval"
  },
  "layer_bonus": {
    "gui": 0.15,
    "retrieval": 0.15,
    "indexer": 0.15,
    "vendor_penalty": -0.1,
    "freshness_bonus": 0.05,
    "intent_matrix": {
      "gui": {
        "gui": 1.2,
        "web": 1.2,
        "server": 0.9,
        "retrieval": 0.8,
        "indexer": 0.8
      },
      "retrieval": {
        "retrieval": 1.3,
        "server": 1.15,
        "common": 1.1,
        "web": 0.7,
        "gui": 0.6
      },
      "indexer": {
        "indexer": 1.3,
        "retrieval": 1.15,
        "common": 1.1,
        "web": 0.7,
        "gui": 0.6
      },
      "eval": {
        "eval": 1.3,
        "retrieval": 1.15,
        "server": 1.1,
        "web": 0.8,
        "gui": 0.7
      },
      "infra": {
        "infra": 1.3,
        "scripts": 1.15,
        "server": 1.1,
        "web": 0.9
      },
      "server": {
        "server": 1.3,
        "retrieval": 1.15,
        "common": 1.1,
        "web": 0.7,
        "gui": 0.6
      }
    }
  },
  "embedding": {
    "embedding_backend": "deterministic",
    "embedding_type": "openai",
    "embedding_model": "text-embedding-3-large",
    "embedding_dim": 3072,
    "auto_set_dimensions": true,
    "input_truncation": "truncate_end",
    "embed_text_prefix": "",
    "embed_text_suffix": "",
    "contextual_chunk_embeddings": "off",
    "late_chunking_max_doc_tokens": 8192,
    "voyage_model": "voyage-code-3",
    "embedding_model_local": "all-MiniLM-L6-v2",
    "embedding_batch_size": 64,
    "embedding_max_tokens": 8000,
    "embedding_cache_enabled": 1,
    "embedding_timeout": 30,
    "embedding_retry_max": 3
  },
  "tokenization": {
    "strategy": "tiktoken",
    "tiktoken_encoding": "o200k_base",
    "hf_tokenizer_name": "gpt2",
    "normalize_unicode": true,
    "lowercase": false,
    "max_tokens_per_chunk_hard": 8192,
    "estimate_only": false
  },
  "chunking": {
    "chunk_size": 1000,
    "chunk_overlap": 200,
    "ast_overlap_lines": 20,
    "max_indexable_file_size": 250000000,
    "max_chunk_tokens": 8000,
    "min_chunk_chars": 50,
    "greedy_fallback_target": 800,
    "chunking_strategy": "ast",
    "preserve_imports": 1,
    "target_tokens": 512,
    "overlap_tokens": 64,
    "separators": [
      "\n\n",
      "\n",
      ". ",
      " ",
      ""
    ],
    "separator_keep": "suffix",
    "recursive_max_depth": 10,
    "markdown_max_heading_level": 4,
    "markdown_include_code_fences": true,
    "emit_chunk_ordinal": true,
    "emit_parent_doc_id": true
  },
  "indexing": {
    "postgres_url": "postgresql://postgres:postgres@localhost:5432/tribrid_rag",
    "table_name": "code_chunks_{repo}",
    "collection_suffix": "default",
    "repo_path": "",
    "indexing_batch_size": 100,
    "indexing_workers": 4,
    "bm25_tokenizer": "stemmer",
    "bm25_stemmer_lang": "english",
    "bm25_stopwords_lang": "en",
    "index_excluded_exts": ".png,.jpg,.gif,.ico,.svg,.woff,.ttf",
    "index_max_file_size_mb": 250,
    "large_file_mode": "stream",
    "large_file_stream_chunk_chars": 2000000,
    "parquet_extract_max_rows": 5000,
    "parquet_extract_max_chars": 2000000,
    "parquet_extract_max_cell_chars": 20000,
    "parquet_extract_text_columns_only": 1,
    "parquet_extract_include_column_names": 1,
    "skip_dense": 0,
    "out_dir_base": "./out",
    "rag_out_base": "",
    "repos_file": "./repos.json"
  },
  "graph_storage": {
    "neo4j_uri": "bolt://localhost:7687",
    "neo4j_user": "neo4j",
    "neo4j_password": "",
    "neo4j_database": "neo4j",
    "neo4j_database_mode": "shared",
    "neo4j_database_prefix": "tribrid_",
    "neo4j_auto_create_databases": true,
    "max_hops": 2,
    "include_communities": true,
    "community_algorithm": "louvain",
    "entity_types": [
      "function",
      "class",
      "module",
      "variable",
      "import"
    ],
    "relationship_types": [
      "calls",
      "imports",
      "inherits",
      "contains",
      "references"
    ],
    "graph_search_top_k": 30
  },
  "graph_indexing": {
    "enabled": true,
    "build_lexical_graph": true,
    "store_chunk_embeddings": true,
    "semantic_kg_enabled": false,
    "ast_contains_weight": 1.0,
    "ast_inherits_weight": 1.0,
    "ast_imports_weight": 1.0,
    "ast_calls_weight": 1.0,
    "semantic_kg_mode": "heuristic",
    "semantic_kg_relation_weight_llm": 0.7,
    "semantic_kg_relation_weight_heuristic": 0.5,
    "semantic_kg_max_concepts_per_chunk": 8,
    "semantic_kg_min_concept_len": 4,
    "semantic_kg_max_relations_per_chunk": 12,
    "semantic_kg_max_chunks": 200,
    "semantic_kg_llm_model": "",
    "semantic_kg_llm_timeout_s": 30,
    "chunk_vector_index_name": "tribrid_chunk_embeddings",
    "chunk_embedding_property": "embedding",
    "vector_similarity_function": "cosine",
    "wait_vector_index_online": true,
    "vector_index_online_timeout_s": 60.0
  },
  "fusion": {
    "method": "rrf",
    "vector_weight": 0.4,
    "sparse_weight": 0.3,
    "graph_weight": 0.3,
    "rrf_k": 60,
    "normalize_scores": true
  },
  "vector_search": {
    "enabled": true,
    "top_k": 50,
    "similarity_threshold": 0.0
  },
  "sparse_search": {
    "engine": "postgres_fts",
    "query_mode": "plain",
    "highlight": false,
    "enabled": true,
    "top_k": 50,
    "bm25_k1": 1.2,
    "bm25_b": 0.4
  },
  "graph_search": {
    "mode": "chunk",
    "enabled": true,
    "chunk_neighbor_window": 1,
    "chunk_seed_overfetch_multiplier": 10,
    "chunk_entity_expansion_enabled": true,
    "chunk_entity_expansion_weight": 0.8,
    "max_hops": 2,
    "include_communities": true,
    "top_k": 30
  },
  "reranking": {
    "reranker_mode": "none",
    "reranker_cloud_provider": "cohere",
    "reranker_cloud_model": "rerank-v3.5",
    "reranker_local_model": "BAAI/bge-reranker-v2-m3",
    "tribrid_reranker_alpha": 0.7,
    "tribrid_reranker_topn": 50,
    "reranker_cloud_top_n": 50,
    "tribrid_reranker_batch": 16,
    "tribrid_reranker_maxlen": 512,
    "tribrid_reranker_reload_on_change": 0,
    "tribrid_reranker_reload_period_sec": 60,
    "reranker_timeout": 10,
    "rerank_input_snippet_chars": 700,
    "transformers_trust_remote_code": 1
  },
  "generation": {
    "gen_model": "gpt-4o-mini",
    "gen_temperature": 0.0,
    "gen_max_tokens": 2048,
    "gen_top_p": 1.0,
    "gen_timeout": 60,
    "gen_retry_max": 2,
    "enrich_model": "gpt-4o-mini",
    "enrich_backend": "openai",
    "enrich_disabled": 0,
    "ollama_num_ctx": 8192,
    "gen_model_cli": "qwen3-coder:14b",
    "gen_model_ollama": "qwen3-coder:30b",
    "gen_model_http": "",
    "gen_model_mcp": "",
    "enrich_model_ollama": "",
    "ollama_url": "http://127.0.0.1:11434/api",
    "openai_base_url": "",
    "ollama_request_timeout": 300,
    "ollama_stream_idle_timeout": 60
  },
  "enrichment": {
    "chunk_summaries_enrich_default": 1,
    "chunk_summaries_max": 100,
    "enrich_code_chunks": 1,
    "enrich_min_chars": 50,
    "enrich_max_chars": 1000,
    "enrich_timeout": 30
  },
  "chunk_summaries": {
    "exclude_dirs": [
      "docs",
      "agent_docs",
      "website",
      "tests",
      "assets",
      "internal_docs.md",
      "out",
      "checkpoints",
      "models",
      "data",
      "telemetry",
      "node_mcp",
      "public",
      "examples",
      "bin",
      "reports",
      "screenshots",
      "web/dist",
      "gui"
    ],
    "exclude_patterns": [],
    "exclude_keywords": [],
    "code_snippet_length": 2000,
    "max_symbols": 5,
    "max_routes": 5,
    "purpose_max_length": 240,
    "quick_tips": []
  },
  "keywords": {
    "keywords_max_per_repo": 50,
    "keywords_min_freq": 3,
    "keywords_boost": 1.3,
    "keywords_auto_generate": 1,
    "keywords_refresh_hours": 24
  },
  "tracing": {
    "tracing_enabled": 1,
    "trace_sampling_rate": 1.0,
    "prometheus_port": 9090,
    "metrics_enabled": 1,
    "alert_include_resolved": 1,
    "alert_webhook_timeout": 5,
    "log_level": "INFO",
    "tracing_mode": "langsmith",
    "trace_auto_ls": 1,
    "trace_retention": 50,
    "tribrid_log_path": "data/logs/queries.jsonl",
    "alert_notify_severities": "critical,warning",
    "langchain_endpoint": "https://api.smith.langchain.com",
    "langchain_project": "tribrid",
    "langchain_tracing_v2": 0,
    "langtrace_api_host": "",
    "langtrace_project_id": ""
  },
  "training": {
    "reranker_train_epochs": 2,
    "reranker_train_batch": 16,
    "reranker_train_lr": 0.00002,
    "reranker_warmup_ratio": 0.1,
    "triplets_min_count": 100,
    "triplets_mine_mode": "replace",
    "tribrid_reranker_model_path": "models/learning-reranker-epstein-files-1",
    "tribrid_reranker_mine_mode": "replace",
    "tribrid_reranker_mine_reset": 0,
    "tribrid_triplets_path": "data/training/triplets__epstein-files-1.jsonl",
    "learning_reranker_backend": "auto",
    "learning_reranker_base_model": "Qwen/Qwen3-Reranker-0.6B",
    "learning_reranker_lora_rank": 16,
    "learning_reranker_lora_alpha": 32.0,
    "learning_reranker_lora_dropout": 0.05,
    "learning_reranker_lora_target_modules": [
      "q_proj",
      "k_proj",
      "v_proj",
      "o_proj"
    ],
    "learning_reranker_negative_ratio": 5,
    "learning_reranker_grad_accum_steps": 8,
    "learning_reranker_promote_if_improves": 1,
    "learning_reranker_promote_epsilon": 0.0,
    "learning_reranker_unload_after_sec": 0
  },
  "ui": {
    "chat_streaming_enabled": 1,
    "chat_history_max": 50,
    "chat_stream_include_thinking": 1,
    "chat_show_confidence": 0,
    "chat_show_citations": 1,
    "chat_show_trace": 1,
    "chat_show_debug_footer": 1,
    "chat_default_model": "gpt-4o-mini",
    "chat_stream_timeout": 120,
    "chat_thinking_budget_tokens": 10000,
    "editor_port": 4440,
    "grafana_dashboard_uid": "tribrid-overview",
    "grafana_dashboard_slug": "tribrid-overview",
    "grafana_base_url": "http://127.0.0.1:3001",
    "grafana_auth_mode": "anonymous",
    "grafana_embed_enabled": 1,
    "grafana_kiosk": "tv",
    "grafana_org_id": 1,
    "grafana_refresh": "10s",
    "editor_bind": "local",
    "editor_embed_enabled": 1,
    "editor_enabled": 1,
    "editor_image": "codercom/code-server:latest",
    "theme_mode": "dark",
    "open_browser": 1,
    "runtime_mode": "development"
  },
  "chat": {
    "default_corpus_ids": [
      "epstein-files-1"
    ],
    "system_prompt_base": "You are a helpful assistant.",
    "system_prompt_recall_suffix": " You have access to conversation history. Reference past discussions when relevant.",
    "system_prompt_rag_suffix": " Answer questions using the provided database information.",
    "system_prompt_direct": "You are a helpful agentic RAG database assistant.\n\nThe user is chatting directly without any retrieval context. No database repositories or conversation history are being queried for this message.\n\nAnswer based on your general knowledge. If the user asks about their specific database and no context is provided, let them know they can enable RAG corpora in the Data Sources panel to query their indexed repositories.\n\nBe direct and helpful.",
    "system_prompt_rag": "You are a database assistant powered by TriBridRAG, a hybrid retrieval system that combines vector search, keyword search, and knowledge graphs to find relevant database.\n\nThe user has selected one or more database repositories to query. You will receive relevant database snippets in <rag_context>...</rag_context> tags.\n\nEach snippet includes:\n- File path and line numbers\n\nHow to use this context:\n- Base your answers on the actual database shown, not assumptions\n- Always cite file paths and line numbers when referencing database\n- If the retrieved information doesn't fully answer the question, say what's missing\n- Don't invent information that isn't in the context\n- **Connect related pieces when they appear across multiple snippets** (e.g. if the user asks about a specific database table, and you have information about the table in the context, connect the information to the question)\n\nBe helpful, friendly, and engaging, and base your answers on the actual database information you have.",
    "system_prompt_recall": "You are an agentic RAG database assistant powered by TriBridRAG. You have access to your conversation history with this user via the Recall system.\n\nRelevant snippets from past conversations appear in <recall_context>...</recall_context> tags.\n\nEach snippet includes:\n- Who said it (user or assistant)\n- Timestamp\n- The message content\n\nHow to use this context:\n- Reference past discussions naturally\n- Don't explicitly say \"according to my recall\" — incorporate it as shared context\n- Past conversations may contain decisions, preferences, or context that inform the current question\n- Prioritize recent conversations over older ones when relevant\n\nBe direct and helpful. You're continuing an ongoing collaboration with this user.",
    "system_prompt_rag_and_recall": "You are an agentic RAG database assistant powered by TriBridRAG, a hybrid retrieval system. You have access to both:\n1) The user's indexed database repositories\n2) Your conversation history with this user (Recall)\n\ndatabase context appears in <rag_context>...</rag_context> tags.\nConversation history appears in <recall_context>...</recall_context> tags.\n\nHow to use both:\n- Reference past discussions naturally\n- Connect them when relevant (e.g., a past decision and the database information that implements it)\n- If past context contradicts current database information, acknowledge the change\n- Don't say \"according to recall\" — just incorporate shared knowledge naturally\n\nBe helpful, friendly, and engaging, and base your answers on the actual database information you have.",
    "reranker": {
      "mode": "local",
      "local_model": "BAAI/bge-reranker-v2-m3",
      "cloud_provider": "cohere",
      "cloud_model": "rerank-v3.5",
      "top_n": 20,
      "recency_weight": 0.3,
      "max_age_hours": 0
    },
    "recall": {
      "enabled": true,
      "vector_backend": "pgvector",
      "auto_index": true,
      "index_delay_seconds": 5,
      "chunking_strategy": "sentence",
      "chunk_max_tokens": 256,
      "embedding_model": "",
      "max_history_tokens": 4096,
      "default_corpus_id": "recall_default",
      "graph_enabled": false
    },
    "recall_gate": {
      "enabled": true,
      "default_intensity": "standard",
      "skip_greetings": true,
      "skip_standalone_questions": true,
      "skip_when_rag_active": false,
      "skip_max_tokens": 4,
      "light_for_short_questions": true,
      "light_top_k": 3,
      "standard_top_k": 5,
      "standard_recency_weight": 0.3,
      "deep_on_explicit_reference": true,
      "deep_top_k": 10,
      "deep_recency_weight": 0.5,
      "show_gate_decision": true,
      "show_signals": false
    },
    "multimodal": {
      "vision_enabled": true,
      "max_image_size_mb": 20,
      "max_images_per_message": 5,
      "supported_formats": [
        "png",
        "jpg",
        "jpeg",
        "gif",
        "webp"
      ],
      "image_detail": "auto",
      "vision_model_override": ""
    },
    "image_gen": {
      "enabled": false,
      "provider": "local",
      "local_command": "python -m qwen_image.generate",
      "local_model_path": "",
      "use_lightning_lora": true,
      "comfyui_api_endpoint": "",
      "replicate_model": "",
      "default_steps": 8,
      "default_resolution": "1024x1024"
    },
    "local_models": {
      "providers": [
        {
          "name": "Ollama",
          "provider_type": "ollama",
          "base_url": "http://127.0.0.1:11434",
          "enabled": true,
          "priority": 0
        },
        {
          "name": "llama.cpp",
          "provider_type": "llamacpp",
          "base_url": "http://127.0.0.1:8080",
          "enabled": true,
          "priority": 1
        }
      ],
      "auto_detect": true,
      "health_check_interval": 30,
      "fallback_to_cloud": true,
      "gpu_memory_limit_gb": 0.0,
      "default_chat_model": "qwen3:8b",
      "default_vision_model": "qwen3-vl:8b",
      "default_embedding_model": "nomic-embed-text"
    },
    "openrouter": {
      "enabled": false,
      "api_key": "",
      "base_url": "https://openrouter.ai/api/v1",
      "default_model": "anthropic/claude-sonnet-4",
      "site_name": "TriBridRAG",
      "fallback_models": [
        "openai/gpt-4o",
        "google/gemini-2.0-flash"
      ]
    },
    "benchmark": {
      "enabled": true,
      "max_concurrent_models": 4,
      "save_results": true,
      "results_path": "data/benchmarks/",
      "include_cost_tracking": true,
      "include_timing_breakdown": true
    },
    "temperature": 0.3,
    "temperature_no_retrieval": 0.7,
    "max_tokens": 4096,
    "show_source_dropdown": true,
    "send_shortcut": "ctrl+enter"
  },
  "hydration": {
    "hydration_mode": "lazy",
    "hydration_max_chars": 2000
  },
  "evaluation": {
    "eval_dataset_path": "data/evaluation_dataset.json",
    "baseline_path": "data/evals/eval_baseline.json",
    "recall_at_5_k": 5,
    "recall_at_10_k": 10,
    "recall_at_20_k": 20,
    "precision_at_5_k": 5,
    "ndcg_at_10_k": 10,
    "eval_multi_m": 10
  },
  "system_prompts": {
    "main_rag_chat": "You are a helpful agentic RAG database assistant.\n\n## Your Role:\n- Answer questions about the indexed database with precision and accuracy\n- Offer practical, actionable insights based on the actual database information\n\n## Guidelines:\n- **Be Evidence-Based**: Ground every answer in the provided database information\n- **Be Honest**: If the information doesn't contain enough information, say so, but try to provide a helpful answer based on the information you have.\n\n## Response Format:\n- Start with a direct answer to the question\n- Provide a helpful answer based on the information you have\n\nYou answer strictly from the provided database information.",
    "query_expansion": "You are a database search query expander. Given a user's question,\ngenerate alternative search queries that might find the same database using different terminology.\n\nRules:\n- Output one query variant per line\n- Keep variants concise (3-8 words each)\n- Use technical synonyms (auth/authentication, config/configuration, etc.)\n- Include both abstract and specific phrasings\n- Do NOT include explanations, just the queries",
    "query_rewrite": "You rewrite developer questions into search-optimized queries without changing meaning.",
    "semantic_chunk_summaries": "Analyze this database chunk and create a comprehensive JSON summary for database search. Focus on WHAT the database does (business purpose) and HOW it works (technical details). Include all important symbols, patterns, and domain concepts.\n\nJSON format:\n{\n  \"symbols\": [\"function_name\", \"class_name\", \"variable_name\"],\n  \"purpose\": \"Clear business purpose - what problem this solves\",\n  \"technical_details\": \"Key technical implementation details\",\n  \"domain_concepts\": [\"business_term1\", \"business_term2\"],\n  \"routes\": [\"api/endpoint\", \"webhook/path\"],\n  \"dependencies\": [\"external_service\", \"library\"],\n  \"patterns\": [\"design_pattern\", \"architectural_concept\"]\n}\n\nFocus on:\n- Domain-specific terminology and concepts from this database\n- Technical patterns and architectural decisions\n- Business logic and problem being solved\n- Integration points, APIs, and external services\n- Key algorithms, data structures, and workflows",
    "code_enrichment": "Analyze this database and return a JSON object with: symbols (array of function/class/component names), purpose (one sentence description), keywords (array of technical terms). Be concise. Return ONLY valid JSON.",
    "semantic_kg_extraction": "You are a semantic knowledge graph extractor.\n\nGiven a single database/document chunk, extract a small set of reusable semantic concepts and relationships.\n\nRules:\n- Return ONLY valid JSON (no markdown, no extra text)\n- Concepts must be short, lowercase, and reusable across the corpus (e.g. \"authentication\", \"rate_limit\", \"vector_index\")\n- Prefer domain concepts and architectural concepts over implementation noise\n- Do NOT include file paths or line numbers as concepts\n- Keep the list small and high-signal\n\nJSON format:\n{\n  \"concepts\": [\"concept1\", \"concept2\"],\n  \"relations\": [\n    {\"source\": \"concept1\", \"target\": \"concept2\", \"relation_type\": \"related_to\"}\n  ]\n}\n\nAllowed relation_type values: related_to, references",
    "eval_analysis": "You are an expert RAG (Retrieval-Augmented Generation) system analyst.\nYour job is to analyze evaluation comparisons and provide HONEST, SKEPTICAL insights.\n\nCRITICAL: Do NOT force explanations that don't make sense. If the data is contradictory or confusing:\n- Say so clearly: \"This result is surprising and may indicate other factors at play\"\n- Consider: index changes, data drift, eval dataset updates, or measurement noise\n- Acknowledge when correlation != causation\n- It's BETTER to say \"I'm not sure why this happened\" than to fabricate a plausible-sounding but wrong explanation\n\nBe rigorous:\n1. Question whether the config changes ACTUALLY explain the performance delta\n2. Flag when results seem counterintuitive (e.g., disabling a feature improving results)\n3. Consider confounding variables: Was the index rebuilt? Did the test set change?\n4. Provide actionable suggestions only when you have reasonable confidence\n\nFormat your response with clear sections using markdown headers.",
    "lightweight_chunk_summaries": "Extract key information from this database: symbols (function/class names), purpose (one sentence), keywords (technical terms). Return JSON only."
  },
  "mcp": {
    "enabled": true,
    "mount_path": "/mcp",
    "stateless_http": true,
    "json_response": true,
    "enable_dns_rebinding_protection": true,
    "allowed_hosts": [
      "localhost:*",
      "127.0.0.1:*"
    ],
    "allowed_origins": [
      "http://localhost:*",
      "http://127.0.0.1:*"
    ],
    "require_api_key": false,
    "default_top_k": 20,
    "default_mode": "tribrid"
  },
  "docker": {
    "docker_host": "",
    "docker_status_timeout": 5,
    "docker_container_list_timeout": 10,
    "docker_container_action_timeout": 30,
    "docker_infra_up_timeout": 60,
    "docker_infra_down_timeout": 30,
    "docker_logs_tail": 100,
    "docker_logs_timestamps": 1,
    "dev_frontend_port": 5173,
    "dev_backend_port": 8012,
    "dev_stack_restart_timeout": 30
  }
}