{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#tribridrag-documentation","title":"TriBridRAG Documentation","text":"<ul> <li> <p> Tri-brid Retrieval</p> <p>Parallel Vector (pgvector), Sparse (PostgreSQL FTS/BM25), and Graph (Neo4j) search fused with configurable strategies.</p> </li> <li> <p> Pydantic Is The Law</p> <p>All configuration and API shapes come from <code>server/models/tribrid_config_model.py</code>. TypeScript types are generated \u2014 never hand-written.</p> </li> <li> <p> PostgreSQL Backbone</p> <p>Chunk storage, embeddings, pgvector indexing, and FTS live in one database.</p> </li> <li> <p> Knowledge Graph</p> <p>Neo4j stores entities and relationships; graph traversal augments retrieval for cross-file context.</p> </li> <li> <p> API-First</p> <p>FastAPI endpoints for indexing, retrieval, config, models, graph, health, and metrics.</p> </li> <li> <p> Operational Safety</p> <p>Field constraints, health/readiness, Prometheus metrics, and cost-aware models.</p> </li> </ul> <p>Get started Configuration API</p> <p>Read This First</p> <p>TriBridRAG is strictly Pydantic-first. If a field or feature is not in <code>server/models/tribrid_config_model.py</code>, it does not exist. Add it there, regenerate TypeScript types, then build the rest.</p> <p>Terminology \u2014 corpus vs repo_id</p> <p>The API still accepts <code>repo_id</code> for legacy reasons. Treat it as the corpus identifier. Pydantic models use <code>AliasChoices(\"repo_id\", \"corpus_id\")</code> and serialize as <code>corpus_id</code>.</p> <p>Security</p> <p>Keep <code>.env</code> out of version control. Restrict database access. Use strong passwords for PostgreSQL and Neo4j. Rotate API keys regularly.</p>"},{"location":"#what-tribridrag-does","title":"What TriBridRAG Does","text":"Feature Description Status Vector Search Dense similarity via pgvector in PostgreSQL \u2705 Active Sparse Search PostgreSQL FTS/BM25 for exact terms, identifiers \u2705 Active Graph Search Neo4j traversal to follow entities/relations \u2705 Active Fusion Weighted/reciprocal-rank fusion of sources \u2705 Active Reranker Optional cross-encoder reranking \u2705 Active"},{"location":"#end-to-end-retrieval-flow","title":"End-to-End Retrieval Flow","text":"<pre><code>flowchart LR\n    Q[\"Query\"] --&gt; V[\"Vector Search\\npgvector\"]\n    Q --&gt; S[\"Sparse Search\\nPostgreSQL FTS/BM25\"]\n    Q --&gt; G[\"Graph Search\\nNeo4j\"]\n    V --&gt; F[\"Fusion Layer\"]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[\"Optional Reranker\"]\n    R --&gt; O[\"Results\"]\n    F --&gt; O</code></pre>"},{"location":"#quickstart-run-index-search","title":"Quickstart \u2014 Run, Index, Search","text":"<ul> <li> Configure environment (.env)</li> <li> Launch services with Docker Compose</li> <li> Regenerate TypeScript types from Pydantic</li> <li> Index a corpus</li> <li> Search via API</li> <li> Tune fusion weights and confidence thresholds</li> <li> Enable reranking if needed</li> </ul> <p>Use Ctrl+C to stop local uvicorn or Docker Tail sessions.</p> Python <pre><code>import httpx, subprocess\n\nBASE = \"http://localhost:8000\"\n\n# 1) Generate TS types from Pydantic (required for UI) (1)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)\n\n# 2) Trigger indexing of a corpus (2)\nreq = {\n    \"corpus_id\": \"tribrid\",  # repo_id alias is also accepted (3)\n    \"repo_path\": \"/path/to/your/codebase\",\n    \"force_reindex\": False,\n}\nhttpx.post(f\"{BASE}/index\", json=req).raise_for_status()\n\n# 3) Poll status (4)\nstatus = httpx.get(f\"{BASE}/index/status\", params={\"corpus_id\": \"tribrid\"}).json()\nprint(status)\n\n# 4) Search (parallel vector/sparse/graph -&gt; fusion -&gt; optional rerank) (5)\npayload = {\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"How does the chunker split Python files?\",\n    \"top_k\": 8,\n}\nres = httpx.post(f\"{BASE}/search\", json=payload).json()\nfor m in res.get(\"matches\", []):\n    print(m[\"file_path\"], m[\"score\"])  # fused score\n</code></pre> curl <pre><code>BASE=http://localhost:8000\n\n# (1) Types are generated locally via Python; no curl equivalent\n\n# (2) Start indexing\ncurl -sS -X POST \"$BASE/index\" \\ \n  -H 'Content-Type: application/json' \\ \n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"repo_path\": \"/path/to/your/codebase\",\n    \"force_reindex\": false\n  }'\n\n# (4) Status\ncurl -sS \"$BASE/index/status?corpus_id=tribrid\" | jq .\n\n# (5) Search\ncurl -sS -X POST \"$BASE/search\" \\ \n  -H 'Content-Type: application/json' \\ \n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"How does the chunker split Python files?\",\n    \"top_k\": 8\n  }' | jq '.matches[] | {file_path, score}'\n</code></pre> TypeScript <pre><code>// (1) Ensure ./web/src/types/generated.ts exists (generated by Python)\nimport type { IndexRequest, SearchRequest, SearchResponse } from \"./web/src/types/generated\";\n\nasync function indexAndSearch() {\n  const base = \"http://localhost:8000\";\n\n  const indexReq: IndexRequest = {\n    corpus_id: \"tribrid\", // repo_id alias is also accepted server-side (3)\n    repo_path: \"/path/to/your/codebase\",\n    force_reindex: false,\n  };\n  await fetch(`${base}/index`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(indexReq),\n  }); // (2)\n\n  const searchReq: SearchRequest = {\n    corpus_id: \"tribrid\",\n    query: \"chunker split Python\",\n    top_k: 8,\n  } as any; // depending on generated type\n\n  const r = await fetch(`${base}/search`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(searchReq),\n  });\n  const data: SearchResponse = await r.json(); // (5)\n  console.log(data.matches.map(m =&gt; [m.file_path, m.score]));\n}\n</code></pre> <ol> <li>Generate UI types from Pydantic models \u2014 this is the contract for the frontend</li> <li>Start indexing your corpus folder</li> <li>Inputs accept <code>repo_id</code> but serialize as <code>corpus_id</code></li> <li>Poll index status to show progress in UI</li> <li>Search runs vector/sparse/graph in parallel, fuses, then optionally reranks</li> </ol> <p>One Config To Rule Them All</p> <p>Every behavior above is configured by <code>TriBridConfig</code>. Adjust fusion weights, hop limits, Top-K, and reranking in the config and the system adapts immediately.</p>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart TB\n    subgraph Client\n      U[\"User / UI / API Client\"]\n    end\n\n    U --&gt; A[\"FastAPI\"]\n    A --&gt; V[\"VectorRetriever\\nPostgres+pgvector\"]\n    A --&gt; S[\"SparseRetriever\\nPostgres FTS/BM25\"]\n    A --&gt; G[\"GraphRetriever\\nNeo4j\"]\n    V --&gt; F[\"Fusion\"]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[\"Reranker (optional)\"]\n    R --&gt; O[\"Final Results\"]\n    F --&gt; O\n\n    subgraph Storage\n      P[(\"PostgreSQL\")]\n      N[(\"Neo4j\")]\n    end\n\n    V &lt;--&gt; P\n    S &lt;--&gt; P\n    G &lt;--&gt; N</code></pre> Advanced Topics <ul> <li>Fusion math: supports weighted linear combination and Reciprocal Rank Fusion with configurable <code>rrf_k</code>.</li> <li>Retrieval cache: cache keys include <code>corpus_id</code>, <code>query</code>, and a hash of the retrieval config segment for correctness.</li> <li>Failure isolation: vector, sparse, and graph legs are resilient; a failure in one path degrades gracefully without crashing the whole search.</li> </ul>"},{"location":"api/","title":"API","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<ul> <li> <p> FastAPI Endpoints</p> <p>Endpoints for config, indexing, retrieval, graph, models, keywords, reranker, and health.</p> </li> <li> <p> Schema by Pydantic</p> <p>Request/response models are defined in Pydantic. The frontend imports generated TypeScript types.</p> </li> <li> <p> Secrets Check</p> <p>Validate configured API keys and DB connections via <code>/secrets/check</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Inspect Schemas</p> <p>Prefer calling <code>/config</code> first to align UI interactions with actual server capabilities. All shapes are Pydantic-driven.</p> <p>HTTP Conventions</p> <ul> <li>JSON requests/responses</li> <li>Errors via standard status codes with <code>detail</code></li> <li>Streaming responses for long operations are <code>text/event-stream</code> or chunked JSON</li> </ul> <p>Model Usage Costs</p> <p>Reranking and keyword generation may incur API costs depending on selected models. Control via <code>data/models.json</code> and <code>TriBridConfig</code>.</p>"},{"location":"api/#endpoint-inventory","title":"Endpoint Inventory","text":"Area Route Method Purpose Config <code>/config</code> GET Get full config Config <code>/config/reset</code> POST Reset to defaults Config <code>/config/{section}</code> PATCH Sectional patch, e.g., <code>fusion</code> Secrets <code>/secrets/check</code> GET Check provider keys + DB connections Index <code>/index</code> POST Start indexing Index <code>/index/status</code> GET Status for a corpus Index <code>/index/stats</code> GET Storage stats summary Search <code>/search</code> POST Tri-brid retrieval + fusion (+reranker) Answer <code>/answer</code> POST Retrieval + LLM answer generation Graph <code>/graph/{corpus_id}/entities</code> GET List entities Graph <code>/graph/{corpus_id}/entity/{id}</code> GET Entity details Graph <code>/graph/{corpus_id}/entity/{id}/neighbors</code> GET Neighborhood Models <code>/models/by-type/{component}</code> GET Models by component <code>GEN/EMB/RERANK</code> Keywords <code>/keywords/generate</code> POST Generate discriminative keywords Reranker <code>/reranker/*</code> mixed Status / mine / train / evaluate Health <code>/health</code> GET Liveness Health <code>/ready</code> GET Readiness Metrics <code>/metrics</code> GET Prometheus exposition <pre><code>flowchart TB\n    CLI[\"Client\"] --&gt; API[\"FastAPI\"]\n    API --&gt; PC[\"Postgres Client\"]\n    API --&gt; NC[\"Neo4j Client\"]\n    API --&gt; CFG[\"Pydantic Models\"]\n    API --&gt; ML[\"Model Catalog\"]\n    PC --&gt; DB[(\"PostgreSQL\")]\n    NC --&gt; GDB[(\"Neo4j\")]</code></pre>"},{"location":"api/#example-search-roundtrip-annotated","title":"Example: Search Roundtrip (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\npayload = {\n    \"corpus_id\": \"tribrid\",  # (1)\n    \"query\": \"authentication flow\",\n    \"top_k\": 10\n}\nresp = httpx.post(f\"{base}/search\", json=payload)\nresp.raise_for_status()\nres = resp.json()  # type: SearchResponse (2)\nprint(res[\"fusion_method\"], len(res[\"matches\"]))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"corpus_id\":\"tribrid\",\"query\":\"authentication flow\",\"top_k\":10}' | jq '.fusion_method, .matches | length'\n</code></pre> TypeScript <pre><code>import type { SearchRequest, SearchResponse } from \"../web/src/types/generated\";\n\nasync function run(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const r = await fetch(\"/search\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) });\n  return await r.json(); // (2)\n}\n</code></pre> <ol> <li>Always scope by <code>corpus_id</code> (legacy <code>repo_id</code> is accepted)</li> <li>Response includes <code>fusion_method</code>, <code>reranker_mode</code>, <code>latency_ms</code>, and <code>matches</code> with provenance</li> </ol> <p>Model Catalog Endpoint</p> <p>The UI must populate model selectors from <code>/models/...</code>. Do not hardcode lists.</p>"},{"location":"api/#health-and-metrics","title":"Health and Metrics","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/ready\").json())   # readiness\nprint(httpx.get(\"http://localhost:8000/metrics\").text[:300])  # metrics sample\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/ready').then(r =&gt; r.ok || Promise.reject('Not ready'))\nconst metrics = await (await fetch('/metrics')).text()\nconsole.log(metrics.split('\\n').slice(0,5))\n</code></pre> Streaming <p>Endpoints that can stream long-running operations (e.g., evaluation logs, training metrics) use Server-Sent Events or chunked JSON. Use backpressure-aware clients.</p>"},{"location":"api_extra/","title":"API Cheatsheet (Quick Calls)","text":""},{"location":"api_extra/#api-cheatsheet-quick-calls","title":"API Cheatsheet (Quick Calls)","text":"<ul> <li> <p> Fast Paths</p> <p>Minimal calls to get from zero to search.</p> </li> <li> <p> Config</p> <p>Read, patch, reset.</p> </li> <li> <p> Search</p> <p>Tri-brid retrieval with optional reranking.</p> </li> </ul> <p>Get started Configuration API</p> Python <pre><code>import httpx\nB = \"http://localhost:8000\"\nhttpx.get(f\"{B}/ready\").raise_for_status()\nhttpx.post(f\"{B}/index\", json={\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":False})\nprint(httpx.post(f\"{B}/search\", json={\"corpus_id\":\"tribrid\",\"query\":\"auth flow\",\"top_k\":10}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/ready\" | jq .\ncurl -sS -X POST \"$BASE/index\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":false}'\ncurl -sS -X POST \"$BASE/search\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"query\":\"auth flow\",\"top_k\":10}' | jq .\n</code></pre> TypeScript <pre><code>await fetch('/ready')\nawait fetch('/index', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', repo_path:'/repo', force_reindex:false }) })\nconst data = await (await fetch('/search', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', query:'auth flow', top_k:10 }) })).json()\nconsole.log(data)\n</code></pre> <p>Use generated types</p> <p>In TS code, import <code>SearchRequest</code>, <code>SearchResponse</code>, <code>IndexRequest</code> from <code>web/src/types/generated.ts</code>.</p>"},{"location":"api_graph/","title":"Graph API (Entities and Relationships)","text":""},{"location":"api_graph/#graph-api-entities-and-relationships","title":"Graph API (Entities and Relationships)","text":"<ul> <li> <p> Entities</p> <p>Functions, classes, modules, variables, concepts.</p> </li> <li> <p> Relationships</p> <p>calls, imports, inherits, contains, references.</p> </li> <li> <p> Communities</p> <p>Optional clustering for related entities.</p> </li> </ul> <p>Get started Configuration API</p> Route Method Description <code>/graph/{corpus_id}/entities</code> GET List entities <code>/graph/{corpus_id}/entity/{entity_id}</code> GET Entity details <code>/graph/{corpus_id}/entity/{entity_id}/relationships</code> GET Direct edges <code>/graph/{corpus_id}/entity/{entity_id}/neighbors</code> GET 1-hop neighborhood <code>/graph/{corpus_id}/communities</code> GET List communities <pre><code>flowchart LR\n    Center[\"Entity\"] --&gt; Calls[\"calls\"]\n    Center --&gt; Imports[\"imports\"]\n    Center --&gt; Inherits[\"inherits\"]\n    Center --&gt; Contains[\"contains\"]\n    Center --&gt; Refs[\"references\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nents = httpx.get(f\"{base}/graph/tribrid/entities\").json()\nprint(\"entities\", len(ents))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/graph/tribrid/entities\" | jq '.[0]'\n</code></pre> TypeScript <pre><code>const ents = await (await fetch('/graph/tribrid/entities')).json();\nconsole.log(ents.length)\n</code></pre>"},{"location":"api_health/","title":"Health, Readiness, and Metrics API","text":""},{"location":"api_health/#health-readiness-and-metrics-api","title":"Health, Readiness, and Metrics API","text":"<ul> <li> <p> Liveness</p> <p><code>/health</code> returns process liveness.</p> </li> <li> <p> Readiness</p> <p><code>/ready</code> verifies DB connectivity.</p> </li> <li> <p> Metrics</p> <p><code>/metrics</code> exposes Prometheus metrics.</p> </li> </ul> <p>Get started Configuration API</p> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/health\").json())\nprint(httpx.get(\"http://localhost:8000/ready\").json())\nprint(httpx.get(\"http://localhost:8000/metrics\").text[:200])\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/health')\nawait fetch('/ready')\nconst m = await (await fetch('/metrics')).text();\nconsole.log(m.split('\\n').slice(0,5))\n</code></pre> <p>Gate Traffic</p> <p>Route production traffic only after readiness returns 200.</p>"},{"location":"api_indexing/","title":"Indexing API","text":""},{"location":"api_indexing/#indexing-api","title":"Indexing API","text":"<ul> <li> <p> Start</p> <p><code>POST /index</code> with <code>IndexRequest</code>.</p> </li> <li> <p> Status</p> <p><code>GET /index/status</code> returns progress, current file.</p> </li> <li> <p> Stats</p> <p><code>GET /index/stats</code> returns storage breakdown.</p> </li> </ul> <p>Get started Configuration API</p> Route Method Description <code>/index</code> POST Start indexing <code>/index/status</code> GET Current state <code>/index/stats</code> GET Storage stats <pre><code>flowchart LR\n    Start[\"POST /index\"] --&gt; Worker[\"Indexer\"]\n    Worker --&gt; Status[\"GET /index/status\"]\n    Worker --&gt; Stats[\"GET /index/stats\"]</code></pre> Python <pre><code>import httpx\nhttpx.post(\"http://localhost:8000/index\", json={\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":False})\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/index -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":false}'\n</code></pre> TypeScript <pre><code>await fetch('/index', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', repo_path:'/repo', force_reindex:false }) })\n</code></pre> <p>Storage</p> <p>See <code>DashboardIndexStatsResponse</code> for per-corpus bytes in Postgres (chunks, embeddings, pgvector index, BM25) and Neo4j store size.</p>"},{"location":"api_models/","title":"Domain Models (Core Shapes)","text":""},{"location":"api_models/#domain-models-core-shapes","title":"Domain Models (Core Shapes)","text":"<ul> <li> <p> Chunks</p> <p><code>Chunk</code>, <code>ChunkMatch</code>, <code>ChunkSummary</code> are the bread-and-butter types for RAG.</p> </li> <li> <p> Search/Answer</p> <p><code>SearchRequest/Response</code>, <code>AnswerRequest/Response</code>.</p> </li> <li> <p> Chat</p> <p><code>ChatRequest/Response</code> with debug metadata.</p> </li> </ul> <p>Get started Configuration API</p> Model Key Fields <code>Chunk</code> <code>chunk_id</code>, <code>content</code>, <code>file_path</code>, <code>start_line</code> <code>ChunkMatch</code> <code>chunk_id</code>, <code>score</code>, <code>source</code>, <code>metadata</code> <code>SearchRequest</code> <code>corpus_id</code>, <code>query</code>, <code>top_k</code> <code>SearchResponse</code> <code>matches</code>, <code>fusion_method</code>, <code>reranker_mode</code>, <code>latency_ms</code> <code>AnswerRequest</code> <code>corpus_id</code>, <code>query</code>, <code>top_k</code>, <code>stream</code> <code>AnswerResponse</code> <code>answer</code>, <code>sources</code>, <code>model</code>, <code>tokens_used</code> <pre><code>flowchart LR\n    Req[\"SearchRequest\"] --&gt; API\n    API --&gt; Res[\"SearchResponse\"]\n    Res --&gt; UI[\"UI Components\"]</code></pre> Python <pre><code># Example shape peek\nfrom pprint import pprint\nimport httpx\npprint(httpx.post(\"http://localhost:8000/search\", json={\"corpus_id\":\"tribrid\",\"query\":\"auth\",\"top_k\":5}).json())\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/search -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"query\":\"auth\",\"top_k\":5}' | jq .\n</code></pre> TypeScript <pre><code>import type { SearchResponse } from \"./web/src/types/generated\";\nconst data: SearchResponse = await (await fetch('/search', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', query:'auth', top_k:5 }) })).json();\n</code></pre>"},{"location":"api_models_chat/","title":"Chat Models","text":""},{"location":"api_models_chat/#chat-models","title":"Chat Models","text":"<ul> <li> <p> Request/Response</p> <p><code>ChatRequest</code> and <code>ChatResponse</code> with streaming option.</p> </li> <li> <p> Debug Info</p> <p><code>ChatDebugInfo</code> includes per-leg enablement and fusion params.</p> </li> <li> <p> Tracing</p> <p><code>Trace</code>, <code>TraceEvent</code>, and <code>/api/traces/latest</code> for last run.</p> </li> </ul> <p>Get started Configuration API</p> Model Key Fields <code>ChatRequest</code> <code>message</code>, <code>corpus_id</code>, <code>top_k</code>, <code>include_vector/sparse/graph</code>, <code>stream</code> <code>ChatResponse</code> <code>message</code>, <code>sources</code>, <code>tokens_used</code>, <code>debug</code> <code>ChatDebugInfo</code> <code>fusion_method</code>, <code>rrf_k</code>, per-leg weights, confidence thresholds <pre><code>flowchart LR\n    Req[\"ChatRequest\"] --&gt; API\n    API --&gt; Res[\"ChatResponse\"]\n    Res --&gt; UI[\"Render + Sources\"]</code></pre> Python <pre><code>import httpx\nprint(httpx.post(\"http://localhost:8000/chat\", json={\"corpus_id\":\"tribrid\",\"message\":\"where is auth?\"}).json())\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/chat -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"message\":\"where is auth?\"}' | jq .\n</code></pre> TypeScript <pre><code>const r = await (await fetch('/chat', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', message:'where is auth?' }) })).json();\n</code></pre>"},{"location":"api_models_eval/","title":"Evaluation Models","text":""},{"location":"api_models_eval/#evaluation-models","title":"Evaluation Models","text":"<ul> <li> <p> Eval Dataset</p> <p><code>EvalDatasetItem</code> defines questions and expected paths.</p> </li> <li> <p> Metrics</p> <p><code>EvalMetrics</code>, <code>EvalRun</code>, <code>EvalResult</code> capture performance.</p> </li> <li> <p> Comparisons</p> <p><code>EvalComparisonResult</code> compares two runs.</p> </li> </ul> <p>Get started Configuration API</p> Model Purpose <code>EvalDatasetItem</code> Single question + expected file paths <code>EvalMetrics</code> Aggregated metrics (MRR, Recall@K, NDCG@10, latency percentiles) <code>EvalRun</code> Complete run with config snapshot and results <code>EvalComparisonResult</code> Delta between baseline and current runs <pre><code>flowchart TB\n    Dataset[\"Eval Dataset\"] --&gt; Run[\"Eval Run\"]\n    Run --&gt; Metrics[\"Eval Metrics\"]\n    Run --&gt; Results[\"Per-Entry Results\"]\n    Metrics --&gt; Compare[\"Compare Runs\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nprint(httpx.post(f\"{base}/reranker/evaluate\", json={\"corpus_id\": \"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/evaluate\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>const report = await (await fetch('/reranker/evaluate', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id: 'tribrid' }) })).json();\n</code></pre>"},{"location":"api_models_extra/","title":"Index Dashboard Models","text":""},{"location":"api_models_extra/#index-dashboard-models","title":"Index Dashboard Models","text":"<ul> <li> <p> Storage Breakdown</p> <p><code>DashboardIndexStorageBreakdown</code> shows bytes across Postgres + Neo4j.</p> </li> <li> <p> Costs</p> <p><code>DashboardIndexCosts</code> estimates embedding costs.</p> </li> <li> <p> Embedding Config</p> <p><code>DashboardEmbeddingConfigSummary</code> summarizes vector storage settings.</p> </li> </ul> <p>Get started Configuration API</p> Model Fields <code>DashboardIndexStorageBreakdown</code> <code>chunks_bytes</code>, <code>embeddings_bytes</code>, <code>pgvector_index_bytes</code>, <code>bm25_index_bytes</code>, <code>neo4j_store_bytes</code>, <code>total_storage_bytes</code> <code>DashboardIndexStatusResponse</code> <code>lines</code>, <code>metadata</code>, <code>running</code>, <code>progress</code>, <code>current_file</code> <pre><code>flowchart LR\n    API[\"/index/stats\"] --&gt; UI[\"Dashboard Panels\"]</code></pre> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/index/stats?corpus_id=tribrid\").json())\n</code></pre> curl <pre><code>curl -sS \"http://localhost:8000/index/stats?corpus_id=tribrid\" | jq .\n</code></pre> TypeScript <pre><code>const stats = await (await fetch('/index/stats?corpus_id=tribrid')).json();\n</code></pre>"},{"location":"api_models_reranker/","title":"Reranker Training Models","text":""},{"location":"api_models_reranker/#reranker-training-models","title":"Reranker Training Models","text":"<ul> <li> <p> Runs</p> <p><code>RerankerTrainRun</code> captures hyperparameters and metrics.</p> </li> <li> <p> Streaming Metrics</p> <p><code>RerankerTrainMetricEvent</code> over SSE for progress.</p> </li> <li> <p> Diff</p> <p>Compare two runs with <code>RerankerTrainDiffResponse</code>.</p> </li> </ul> <p>Get started Configuration API</p> Model Purpose <code>RerankerTrainRun</code> Captures <code>primary_metric</code>, hyperparameters, and summary <code>RerankerTrainMetricEvent</code> Progress, metrics, and state events <code>RerankerTrainDiffResponse</code> Compatibility + delta comparisons <pre><code>flowchart LR\n    Start[\"Start Run\"] --&gt; Stream[\"Events\"]\n    Stream --&gt; Complete[\"Completed Run\"]\n    Complete --&gt; Diff[\"Compare Runs\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nprint(httpx.post(f\"{base}/reranker/train/start\", json={\"corpus_id\":\"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/train/start\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>await fetch('/reranker/train/start', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid' }) })\n</code></pre>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture","title":"Architecture","text":"<ul> <li> <p> Tri-Path Retrieval</p> <p>Vector, Sparse, and Graph retrievers run concurrently for maximum recall.</p> </li> <li> <p> Fusion Layer</p> <p>Weighted fusion or RRF unifies heterogeneous scores into one ranking.</p> </li> <li> <p> Optional Reranker</p> <p>Cross-encoder can refine the fused list by understanding local context.</p> </li> <li> <p> Pydantic-Orchestrated</p> <p>All engine parameters are Pydantic fields with constraints and defaults.</p> </li> <li> <p> FastAPI Surface</p> <p>Clean endpoints for indexing, retrieval, graph queries, and system health.</p> </li> <li> <p> Observability</p> <p>Readiness + Prometheus metrics + PostgreSQL exporter.</p> </li> </ul> <p>Get started Configuration API</p> <p>Concurrency</p> <p>TriBridRAG parallelizes retrievers with async I/O. Size DB connection pools to match concurrency and avoid I/O starvation.</p> <p>Failure Isolation</p> <p>Each retriever is wrapped so failures degrade that leg only. Fusion runs on the subset that succeeded; fused results keep provenance in <code>ChunkMatch.source</code>.</p> <p>Graph Availability</p> <p>If Neo4j is temporarily unavailable, retrieval continues with vector + sparse. Test fallback behavior in your deployment.</p>"},{"location":"architecture/#system-diagram","title":"System Diagram","text":"<pre><code>flowchart LR\n    subgraph API\n      FAPI[\"FastAPI\"]\n    end\n\n    FAPI --&gt; V[\"VectorRetriever\"]\n    FAPI --&gt; S[\"SparseRetriever\"]\n    FAPI --&gt; G[\"GraphRetriever\"]\n\n    V --&gt; FU[\"Fusion\"]\n    S --&gt; FU\n    G --&gt; FU\n\n    FU --&gt; RR[\"Reranker (optional)\"]\n    RR --&gt; RES[\"Results\"]\n    FU --&gt; RES\n\n    V &lt;--&gt; PG[\"(\"PostgreSQL\\n(pgvector+FTS)\")\"]\n    S &lt;--&gt; PG\n    G &lt;--&gt; NEO[\"(\"Neo4j\\nGraph\")\"]</code></pre>"},{"location":"architecture/#layer-responsibilities","title":"Layer Responsibilities","text":"Layer Module Responsibilities Representative Config Vector <code>server/retrieval/vector.py</code> Dense search via pgvector <code>vector_search.enabled</code>, <code>vector_search.top_k</code>, <code>embedding.*</code> Sparse <code>server/retrieval/sparse.py</code> FTS/BM25 over chunks <code>sparse_search.enabled</code>, <code>sparse_search.top_k</code>, <code>indexing.bm25_*</code> Graph <code>server/retrieval/graph.py</code> Entity traversal, context expansion <code>graph_search.enabled</code>, <code>graph_search.max_hops</code>, <code>graph_storage.*</code> Fusion <code>server/retrieval/fusion.py</code> Merge lists and scores <code>fusion.method</code>, <code>fusion.rrf_k</code>, <code>fusion.*_weight</code> Reranker <code>server/retrieval/rerank.py</code> Cross-encoder scoring <code>reranking.reranker_mode</code>, <code>reranking.*</code>"},{"location":"architecture/#hot-path-annotated","title":"Hot Path (Annotated)","text":"Python <pre><code>from server.retrieval.fusion import TriBridFusion\nfrom server.retrieval.rerank import Reranker\n\nasync def search(query: str, corpus_id: str, cfg):  # (1)\n    fusion = TriBridFusion(cfg)\n    fused = await fusion.search(corpus_id, query)   # (2)\n    if cfg.reranking.reranker_mode != \"none\":\n        rr = Reranker(cfg)\n        fused = await rr.rerank(query, fused)       # (3)\n    return fused                                   # (4)\n</code></pre> curl <pre><code>BASE=http://localhost:8000\n# (2) Fusion (vector+sparse+graph)\ncurl -sS -X POST \"$BASE/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"connection pool size\",\n    \"top_k\": 10\n  }' | jq '.matches[0]'\n</code></pre> TypeScript <pre><code>import type { SearchRequest, SearchResponse } from \"../web/src/types/generated\";\n\nexport async function triSearch(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const resp = await fetch(\"/search\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(req),\n  });\n  return await resp.json(); // (4)\n}\n</code></pre> <ol> <li>Query and corpus identifier; use <code>corpus_id</code> (alias of legacy <code>repo_id</code>)</li> <li>Fusion runs vector/sparse/graph concurrently and merges results</li> <li>Optional reranking with cross-encoder based on config</li> <li>Returns unified <code>SearchResponse</code> with provenance and latency</li> </ol>"},{"location":"architecture/#fusion-choices","title":"Fusion Choices","text":"Method Formula Strengths Notes weighted <code>w_v*sv + w_s*ss + w_g*sg</code> Interpretable weight tuning Normalize scores if distributions differ rrf <code>sum 1/(k+rank_i)</code> Robust across heterogeneous scales Tune <code>rrf_k</code> in <code>fusion.rrf_k</code> <pre><code>flowchart TB\n    Q[\"Query\"] --&gt; V[\"Vector Top-K\"]\n    Q --&gt; S[\"Sparse Top-K\"]\n    Q --&gt; G[\"Graph Top-K\"]\n    V --&gt; FU[\"Fusion\"]\n    S --&gt; FU\n    G --&gt; FU\n    FU --&gt; OUT[\"Top-N Results\"]</code></pre> Implementation Notes <ul> <li>All configurable fields (weights, top_k, thresholds) live in <code>TriBridConfig</code>. Frontend sliders and toggles must map 1:1 to these fields via <code>generated.ts</code>.</li> <li>DB clients: <code>server/db/postgres.py</code> (pgvector + FTS) and <code>server/db/neo4j.py</code> (graph). Keep pools separate to avoid head-of-line blocking.</li> </ul> <p>Do Not Hand-Write Types</p> <p>All API types must be imported from <code>web/src/types/generated.ts</code>. Regenerate with <code>uv run scripts/generate_types.py</code> whenever Pydantic models change.</p>"},{"location":"architecture_extra/","title":"Request Lifecycle (Deep Dive)","text":""},{"location":"architecture_extra/#request-lifecycle-deep-dive","title":"Request Lifecycle (Deep Dive)","text":"<ul> <li> <p> Routing</p> <p>Requests pass through validation, retrieval, fusion, and optional reranking.</p> </li> <li> <p> Latency Budget</p> <p>Each stage contributes; measure and tune.</p> </li> <li> <p> Tracing</p> <p>Optional tracing emits per-stage events for debugging.</p> </li> </ul> <p>Get started Configuration API</p> <pre><code>flowchart TB\n    IN[\"HTTP Request\"] --&gt; VAL[\"Pydantic Validation\"]\n    VAL --&gt; RET[\"Retrievers (async)\"]\n    RET --&gt; FUS[\"Fusion\"]\n    FUS --&gt; RER[\"Reranker (optional)\"]\n    RER --&gt; OUT[\"Response JSON\"]</code></pre> Python <pre><code># server/api/search.py pseudo-flow\nasync def search(req: SearchRequest):  # (1)\n    fused = await fusion.search(req.repo_id or req.corpus_id, req.query)  # (2)\n    return rerank_if_configured(req.query, fused)  # (3)\n</code></pre> curl <pre><code># See api.md for concrete curl\n</code></pre> TypeScript <pre><code>// Client perspective: POST /search with SearchRequest\n</code></pre> <ol> <li>Pydantic validation and alias resolution (repo_id \u2192 corpus_id)</li> <li>Parallel leg execution + fusion</li> <li>Optional rerank, then return typed response</li> </ol> <p>Emit debug</p> <p>Enable <code>tracing</code> fields in config to capture per-stage events and timings for regressions.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration","title":"Configuration","text":"<ul> <li> <p> Single Source of Truth</p> <p><code>server/models/tribrid_config_model.py</code> defines every tunable parameter with Pydantic <code>Field()</code> constraints.</p> </li> <li> <p> Generated Types</p> <p><code>uv run scripts/generate_types.py</code> produces <code>web/src/types/generated.ts</code>. No hand-written interfaces.</p> </li> <li> <p> Constraints Enforced</p> <p>Min/max ranges, enums, and defaults are validated at load time with precise error messages.</p> </li> </ul> <p>Get started Configuration API</p> <p>Workflow: Pydantic First</p> <p>1) Add/modify fields in Pydantic. 2) Regenerate TS types. 3) Wire stores/hooks/components using generated types. 4) Update backend logic to honor new fields.</p> <p>Corpus ID Migration</p> <p>Use <code>corpus_id</code>. Pydantic models accept <code>repo_id</code> via <code>AliasChoices</code> for backward compatibility, but serialize <code>corpus_id</code>.</p> <p>Validation</p> <p>Invalid config values are rejected at load time. Respect <code>ge</code>, <code>le</code>, <code>Literal</code>, and <code>pattern</code> constraints or the server will refuse to start.</p>"},{"location":"configuration/#derivation-chain","title":"Derivation Chain","text":"<pre><code>flowchart TB\n    P[\"Pydantic\\ntribrid_config_model.py\"] --&gt; G[\"pydantic2ts\\n(generate_types.py)\"]\n    G --&gt; T[\"generated.ts\"]\n    T --&gt; S[\"Zustand Stores\"]\n    S --&gt; H[\"React Hooks\"]\n    H --&gt; C[\"Components\"]\n    P --&gt; A[\"FastAPI Schemas\"]\n    A --&gt; UI[\"API Responses\"]</code></pre>"},{"location":"configuration/#key-sections-representative-fields","title":"Key Sections (Representative Fields)","text":"Section Example Fields Description retrieval <code>final_k</code>, <code>topk_dense</code>, <code>topk_sparse</code>, <code>fallback_confidence</code>, <code>conf_top1</code>, <code>conf_avg5</code> Global retrieval knobs and thresholds fusion <code>method</code>, <code>vector_weight</code>, <code>sparse_weight</code>, <code>graph_weight</code>, <code>rrf_k</code>, <code>normalize_scores</code> Fusion behavior vector_search <code>enabled</code>, <code>top_k</code>, <code>similarity_threshold</code> pgvector retrieval parameters sparse_search <code>enabled</code>, <code>top_k</code>, <code>bm25_k1</code>, <code>bm25_b</code> BM25/FTS retrieval parameters graph_search <code>enabled</code>, <code>max_hops</code>, <code>top_k</code>, <code>chunk_neighbor_window</code> Neo4j traversal parameters embedding <code>embedding_type</code>, <code>embedding_model</code>, <code>embedding_dim</code>, <code>embedding_batch_size</code> Embedding provider + shapes chunking <code>chunk_size</code>, <code>chunk_overlap</code>, <code>chunking_strategy</code>, <code>max_chunk_tokens</code> Chunking behavior reranking <code>reranker_mode</code>, <code>reranker_cloud_provider</code>, <code>reranker_local_model</code>, <code>tribrid_reranker_topn</code> Cross-encoder settings tracing <code>tracing_enabled</code>, <code>trace_sampling_rate</code>, <code>prometheus_port</code> Observability controls"},{"location":"configuration/#fusion-configuration-selected","title":"Fusion Configuration (Selected)","text":"Field Type Constraints Description <code>fusion.method</code> Literal[\"rrf\",\"weighted\"] required Fusion algorithm <code>fusion.vector_weight</code> float 0.0\u20131.0 Weight for vector scores <code>fusion.sparse_weight</code> float 0.0\u20131.0 Weight for sparse scores <code>fusion.graph_weight</code> float 0.0\u20131.0 Weight for graph scores <code>fusion.rrf_k</code> int 1\u2013200 RRF smoothing constant <code>fusion.normalize_scores</code> bool \u2014 Normalize input scores before fusion"},{"location":"configuration/#graph-retrieval-configuration-selected","title":"Graph Retrieval Configuration (Selected)","text":"Field Type Constraints Description <code>graph_search.enabled</code> bool \u2014 Enable Neo4j traversal in retrieval <code>graph_search.max_hops</code> int 1\u20135 Traversal depth from seeds <code>graph_search.top_k</code> int 5\u2013100 Number of graph hits before fusion <code>graph_search.chunk_neighbor_window</code> int 0\u201310 Include neighboring chunks as context"},{"location":"configuration/#reading-and-updating-config-via-api-annotated","title":"Reading and Updating Config via API (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\n# Read full config (1)\ncfg = httpx.get(f\"{base}/config\").json()\n\n# Patch a section (2)\npatch = {\"method\": \"weighted\", \"vector_weight\": 0.5, \"sparse_weight\": 0.3, \"graph_weight\": 0.2}\nhttpx.patch(f\"{base}/config/fusion\", json=patch).raise_for_status()\n\n# Reset to defaults (3)\nhttpx.post(f\"{base}/config/reset\").raise_for_status()\n</code></pre> curl <pre><code>BASE=http://localhost:8000\n\n# (1) Read\ncurl -sS \"$BASE/config\" | jq .\n\n# (2) Patch fusion\ncurl -sS -X PATCH \"$BASE/config/fusion\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"method\":\"weighted\",\"vector_weight\":0.5,\"sparse_weight\":0.3,\"graph_weight\":0.2}' | jq .\n\n# (3) Reset\ncurl -sS -X POST \"$BASE/config/reset\" | jq .\n</code></pre> TypeScript <pre><code>import type { TriBridConfig } from \"./web/src/types/generated\";\n\nasync function loadConfig(): Promise&lt;TriBridConfig&gt; {\n  const r = await fetch(\"/config\");\n  return await r.json(); // (1)\n}\n\nasync function patchFusion() {\n  await fetch(\"/config/fusion\", {\n    method: \"PATCH\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({ method: \"weighted\", vector_weight: 0.5, sparse_weight: 0.3, graph_weight: 0.2 }),\n  }); // (2)\n}\n</code></pre> <ol> <li>The API returns the Pydantic-driven shape of the full config</li> <li>Partial patch by section is supported; validation enforced by Pydantic</li> <li>Reset restores defaults compiled into the Pydantic model</li> </ol> <p>No Adapters</p> <p>If the frontend needs a different shape, change the Pydantic model and regenerate types. Adapters introduce drift and are not allowed.</p>"},{"location":"configuration/#keyboard-shortcuts-and-tasks","title":"Keyboard Shortcuts and Tasks","text":"<ul> <li> Ctrl+C to stop local <code>uvicorn</code></li> <li> <code>uv run scripts/generate_types.py</code> to sync UI types</li> <li> <code>uv run scripts/validate_types.py</code> to verify Pydantic \u2194 TS sync</li> <li> <code>uv run scripts/check_banned.py</code> to ensure codebase hygiene</li> </ul> Config Surfaces <ul> <li><code>server/models/tribrid_config_model.py</code> \u2014 authoritative models</li> <li><code>data/models.json</code> \u2014 model catalog with pricing/context</li> <li><code>data/glossary.json</code> \u2014 tooltip texts and categories</li> </ul>"},{"location":"database/","title":"Database","text":""},{"location":"database/#databases-and-storage","title":"Databases and Storage","text":"<ul> <li> <p> PostgreSQL + pgvector</p> <p>Single store for chunks, embeddings, and FTS/BM25 indexes.</p> </li> <li> <p> Neo4j Graph</p> <p>Entities and relationships power graph traversal and community queries.</p> </li> <li> <p> Operational Controls</p> <p>Connection pools, health checks, and exporters for metrics.</p> </li> </ul> <p>Get started Configuration API</p> <p>Co-locate Storage</p> <p>Use the provided Docker Compose to run Postgres and Neo4j locally with sane defaults and persistent volumes outside the repository.</p> <p>pgvector Index Choice</p> <p>Choose HNSW for high-recall, read-heavy workloads; IVFFlat for faster build times and stable performance on mid-size corpora.</p> <p>Neo4j Memory</p> <p>Set <code>NEO4J_HEAP_INIT</code>, <code>NEO4J_HEAP_MAX</code>, and <code>NEO4J_PAGECACHE</code> environment variables for large graphs to avoid GC thrash.</p>"},{"location":"database/#services","title":"Services","text":"Service Image Ports Data Volume Postgres <code>pgvector/pgvector:pg16</code> <code>${POSTGRES_PORT:-5432}:5432</code> <code>${TRIBRID_DB_DIR}/postgres:/var/lib/postgresql/data</code> Postgres Exporter <code>prometheuscommunity/postgres-exporter:latest</code> internal n/a Neo4j <code>neo4j:5.x</code> <code>7687</code>, <code>7474</code> <code>${TRIBRID_DB_DIR}/neo4j/*</code> <pre><code>flowchart LR\n    Client --&gt; API\n    API --&gt; PG[(\"PostgreSQL + pgvector\")]\n    API --&gt; NEO[(\"Neo4j\")]\n    PG --&gt; EXP[\"Postgres Exporter\"]\n    EXP --&gt; PROM[\"Prometheus\"]</code></pre>"},{"location":"database/#connectivity-checks","title":"Connectivity Checks","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/health\").json())   # liveness\nprint(httpx.get(\"http://localhost:8000/ready\").json())    # readiness\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\n</code></pre> TypeScript <pre><code>async function readiness() {\n  const health = await (await fetch(\"/health\")).json();\n  const ready = await (await fetch(\"/ready\")).json();\n  console.log(health, ready);\n}\n</code></pre> <p>Index Footprint</p> <p>Use <code>DashboardIndexStatsResponse</code> to view <code>pgvector_index_bytes</code>, <code>bm25_index_bytes</code>, and <code>neo4j_store_bytes</code> per corpus.</p>"},{"location":"deployment/","title":"Deployment","text":""},{"location":"deployment/#deployment","title":"Deployment","text":"<ul> <li> <p> Docker-First</p> <p>Compose stack for Postgres, Neo4j, exporter, and API.</p> </li> <li> <p> Configurable</p> <p>All behavior via Pydantic config and environment variables.</p> </li> <li> <p> Portable</p> <p>Works on local dev, CI, or container platforms.</p> </li> </ul> <p>Get started Configuration API</p> <p>Persistent Volumes</p> <p>Keep DB data outside the repo. Default bind-mount path is <code>../tribrid-rag-db/</code>. Override with <code>TRIBRID_DB_DIR</code> to point elsewhere.</p> <p>Environment Template</p> <p>Copy the provided environment configuration to <code>.env</code>, fill in DB credentials and API keys, and export it into your shell for local runs.</p> <p>Production Secrets</p> <p>Use a secret manager for API keys and DB credentials in production. Do not rely on <code>.env</code> files in containerized environments.</p>"},{"location":"deployment/#services-and-ports","title":"Services and Ports","text":"Service Port Purpose API (uvicorn) 8000 REST endpoints PostgreSQL 5432 Chunk + vector + FTS storage Neo4j Bolt 7687 Graph driver Neo4j Browser 7474 Admin UI Prometheus 9090 Metrics Grafana 3001 Dashboards <pre><code>flowchart LR\n    Dev[\"Developer\"] --&gt; Compose[\"Docker Compose\"]\n    Compose --&gt; API[\"API\"]\n    Compose --&gt; Postgres[\"Postgres\"]\n    Compose --&gt; Neo4j[\"Neo4j\"]\n    Postgres --&gt; Exporter[\"Postgres Exporter\"]</code></pre>"},{"location":"deployment/#bring-up-tasks","title":"Bring-Up Tasks","text":"<ul> <li> Create <code>.env</code> with DB creds and API keys</li> <li> <code>docker compose up -d</code></li> <li> <code>uv run scripts/generate_types.py</code></li> <li> Start API service</li> </ul> Python <pre><code>import subprocess, os\n\n# Generate types from Pydantic (1)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)\n\n# Start FastAPI via uvicorn (2)\nos.system(\"uvicorn server.main:app --reload --port 8000\")  # (2)\n</code></pre> curl <pre><code># After containers are up:\ncurl -sS http://localhost:8000/ready | jq .  # readiness check (3)\n</code></pre> TypeScript <pre><code>// Frontend dev typically proxies to :8000\nconsole.log(\"Ensure generated.ts exists and API ready at /ready\");\n</code></pre> <ol> <li>Generate TS types from Pydantic</li> <li>Run API server (dev mode)</li> <li>Validate readiness gates DB connectivity</li> </ol> <pre><code>flowchart TB\n    Env[\".env\"] --&gt; Compose\n    Pydantic --&gt; Types[\"generated.ts\"]\n    Types --&gt; UI[\"Frontend\"]\n    Compose --&gt; API[\"API\"]\n    API --&gt; READY[\"/ready\"]</code></pre> Container Logs <p>Use <code>/docker/{container}/logs</code> to fetch current log lines via API for basic troubleshooting when UI access is limited.</p>"},{"location":"frontend/","title":"Frontend","text":""},{"location":"frontend/#frontend-integration-and-types","title":"Frontend Integration and Types","text":"<ul> <li> <p> Generated Types Only</p> <p><code>web/src/types/generated.ts</code> is the only source for API interfaces.</p> </li> <li> <p> Zustand Stores</p> <p>Stores consume generated types; hooks expose typed accessors.</p> </li> <li> <p> Components</p> <p>Props derive from hooks; no custom interfaces without Pydantic ancestry.</p> </li> </ul> <p>Get started Configuration API</p> <p>Generate Early</p> <p>Run <code>uv run scripts/generate_types.py</code> before starting the frontend. Hot reload relies on correct types.</p> <p>Traceability</p> <p>Every UI element (slider, toggle, input) must map to a Pydantic field. Tooltips come from <code>data/glossary.json</code>.</p> <p>No Hand-Written Interfaces</p> <p>Interfaces like <code>interface SearchResponse { ... }</code> are forbidden. Import from <code>generated.ts</code>.</p>"},{"location":"frontend/#store-and-hook-structure","title":"Store and Hook Structure","text":"File Purpose <code>web/src/stores/useConfigStore.ts</code> Holds <code>TriBridConfig</code> and patch helpers <code>web/src/hooks/useConfig.ts</code> Read/update config <code>web/src/hooks/useFusion.ts</code> Fusion-related derived state <code>web/src/hooks/useReranker.ts</code> Reranker configuration and status <pre><code>flowchart TB\n    G[generated.ts] --&gt; S[stores]\n    S --&gt; H[hooks]\n    H --&gt; C[components]</code></pre>"},{"location":"frontend/#example-usage","title":"Example Usage","text":"PythoncurlTypeScript <pre><code># Backend reference: see dev/pydantic.md for generation step (1)\n</code></pre> <pre><code># Frontend consumes API; see api.md for routes (2)\n</code></pre> <pre><code>import { TriBridConfig, SearchResponse } from '../web/src/types/generated';\n\nfunction useConfig() {\n  // typed fetch\n  const [cfg, setCfg] = React.useState&lt;TriBridConfig | null&gt;(null);\n  React.useEffect(() =&gt; { fetch('/config').then(r =&gt; r.json()).then(setCfg); }, []); // (3)\n  return cfg;\n}\n</code></pre> <ol> <li>Types generation step is mandatory</li> <li>API is the contract; no local mocks of shapes</li> <li>Fetch returns the Pydantic-driven shape of config</li> </ol> <p>Tooltip Integration</p> <p><code>data/glossary.json</code> drives hover help via <code>TooltipIcon</code> in the UI. Keep term keys stable.</p> <ul> <li> Use generated types across stores, hooks, and components</li> <li> Remove any legacy custom interfaces</li> <li> Validate prop chains map back to Pydantic fields</li> </ul> <pre><code>flowchart LR\n    Glossary[data/glossary.json] --&gt; Tooltip[TooltipIcon]\n    Tooltip --&gt; UI</code></pre> Component Inventory <ul> <li><code>DockerStatusCard.tsx</code>, <code>HealthStatusCard.tsx</code> show system state</li> <li><code>RepoSelector.tsx</code> binds UI to <code>corpus_id</code></li> <li><code>RAGTab.tsx</code>, <code>GrafanaTab.tsx</code>, <code>AdminTab.tsx</code> orchestrate panels using typed hooks</li> </ul>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#glossary","title":"Glossary","text":"<ul> <li> <p> Centralized Terms</p> <p><code>data/glossary.json</code> drives all tooltips in the UI.</p> </li> <li> <p> Cross-References</p> <p>Each term lists related entries to encourage discovery.</p> </li> <li> <p> Editable</p> <p>Update the JSON file, not components, to change tooltip content.</p> </li> </ul> <p>Get started Configuration API</p> <p>Source of Truth</p> <p><code>data/glossary.json</code> is parsed by the UI. Keep <code>key</code> values stable for long-lived tooltips.</p> <p>Representative Entries</p> <ul> <li>PostgreSQL pgvector URL (<code>POSTGRES_URL</code>)</li> <li>Neo4j Connection URI (<code>NEO4J_URI</code>)</li> <li>Final Top-K (<code>FINAL_K</code>)</li> </ul> <p>Typos</p> <p>Misspelled keys break existing tooltips silently. Validate JSON in CI.</p>"},{"location":"glossary/#example-entries","title":"Example Entries","text":"Term Key Definition PostgreSQL pgvector URL POSTGRES_URL Connection URL for pgvector-enabled Postgres Neo4j Connection URI NEO4J_URI Connection URI for Neo4j graph Final Top\u2011K FINAL_K Final result size after fusion/reranking <pre><code>flowchart LR\n    glossary[\"glossary.json\"] --&gt; Tooltip[\"TooltipIcon\"]\n    Tooltip --&gt; UI[\"UI\"]</code></pre> Python <pre><code># Backend is not reading glossary by default; UI reads the JSON.\n</code></pre> curl <pre><code># Validate glossary.json structure\neq 0 $(jq . data/glossary.json &gt;/dev/null 2&gt;&amp;1; echo $?) &amp;&amp; echo OK || echo FAIL\n</code></pre> TypeScript <pre><code>// UI side: load glossary.json and feed into TooltipIcon\n</code></pre> <p>Consistency</p> <p>Use the glossary for all UI textual explanations to avoid drift between screens.</p>"},{"location":"indexing/","title":"Indexing","text":""},{"location":"indexing/#indexing-pipeline","title":"Indexing Pipeline","text":"<ul> <li> <p> Loader</p> <p>Git-aware discovery honoring <code>.gitignore</code> with root-relative patterns.</p> </li> <li> <p> Chunker</p> <p>Fixed, AST-aware, or hybrid chunk strategies with line attribution.</p> </li> <li> <p> Embedder</p> <p>Deterministic local or provider-backed embeddings configured in Pydantic.</p> </li> <li> <p> Chunk Summaries</p> <p>Optional LLM-generated <code>chunk_summaries</code> to improve sparse search.</p> </li> <li> <p> Graph Builder</p> <p>Entity/relationship extraction and Neo4j persistence.</p> </li> </ul> <p>Get started Configuration API</p> <p>Idempotent Indexing</p> <p>Use <code>force_reindex=false</code> for incremental updates. The indexer skips unchanged files using mtime/hash checks when available.</p> <p>Storage Layout</p> <p>Chunks, embeddings, and FTS are in PostgreSQL. Graph artifacts are in Neo4j. Sizes are summarized via dashboard endpoints.</p> <p>Large Corpora</p> <p>Configure Neo4j heap and page cache in Docker env for multi-million edge graphs. Monitor Postgres disk growth for pgvector indexes.</p>"},{"location":"indexing/#pipeline-flow","title":"Pipeline Flow","text":"<pre><code>flowchart LR\n    L[\"FileLoader\"] --&gt; C[\"Chunker\"]\n    C --&gt; E[\"Embedder\"]\n    E --&gt; P[(\"PostgreSQL\")]\n    C --&gt; S[\"ChunkSummarizer\"]\n    S --&gt; P\n    C --&gt; GB[\"GraphBuilder\"]\n    GB --&gt; N[(\"Neo4j\")]</code></pre>"},{"location":"indexing/#chunking-embedding-controls-selected","title":"Chunking &amp; Embedding Controls (Selected)","text":"Section Field Default Notes chunking <code>chunk_size</code> 1000 Target chars per chunk chunking <code>chunk_overlap</code> 200 Overlap for continuity chunking <code>chunking_strategy</code> ast <code>ast | greedy | hybrid</code> chunking <code>max_chunk_tokens</code> 8000 Split recursively if larger embedding <code>embedding_type</code> openai Provider selector embedding <code>embedding_model</code> text-embedding-3-large Model id embedding <code>embedding_dim</code> 3072 Must match model outputs indexing <code>bm25_tokenizer</code> stemmer Tokenizer for FTS"},{"location":"indexing/#start-indexing-via-api-annotated","title":"Start Indexing via API (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\nreq = {\n    \"corpus_id\": \"tribrid\",   # (1)\n    \"repo_path\": \"/work/src/tribrid\",\n    \"force_reindex\": False\n}\nhttpx.post(f\"{base}/index\", json=req).raise_for_status()  # (2)\n\nstatus = httpx.get(f\"{base}/index/status\", params={\"corpus_id\": \"tribrid\"}).json()\nprint(status[\"status\"], status.get(\"progress\"))          # (3)\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/index\" -H 'Content-Type: application/json' -d '{\n  \"corpus_id\":\"tribrid\",\"repo_path\":\"/work/src/tribrid\",\"force_reindex\":false\n}'\ncurl -sS \"$BASE/index/status?corpus_id=tribrid\" | jq .\n</code></pre> TypeScript <pre><code>import type { IndexRequest, IndexStatus } from \"../web/src/types/generated\";\n\nasync function reindex(path: string) {\n  const req: IndexRequest = { corpus_id: \"tribrid\", repo_path: path, force_reindex: false };\n  await fetch(\"/index\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) }); // (2)\n  const status: IndexStatus = await (await fetch(\"/index/status?corpus_id=tribrid\")).json(); // (3)\n  console.log(status.status, status.progress);\n}\n</code></pre> <ol> <li>Create/refresh a specific corpus</li> <li>Start indexing</li> <li>Poll progress</li> </ol> <p>Sparse Boost from chunk_summaries</p> <p>Summaries can improve recall for identifier-heavy queries by adding descriptive context to FTS.</p> <pre><code>flowchart TB\n    Chunks --&gt; Summarizer\n    Summarizer --&gt; Postgres[(\"FTS Index\")]\n    Summarizer --&gt; Costs[\"Model Costs\"]\n    Costs --&gt; Models[\"data/models.json\"]</code></pre> Failure Modes <ul> <li>File decoding errors: logged and skipped</li> <li>Embedding timeouts: retried with backoff; chunk remains un-embedded if persistent</li> <li>Graph build failures: retrieval continues with vector/sparse; flagged in logs</li> </ul>"},{"location":"models/","title":"Models","text":""},{"location":"models/#model-catalog-datamodelsjson","title":"Model Catalog (data/models.json)","text":"<ul> <li> <p> Cost-Aware</p> <p>Pricing per 1k tokens with provider and family classifications.</p> </li> <li> <p> LLM/Embedding/Reranker</p> <p>Centralized catalog for generation, embeddings, and rerank models.</p> </li> <li> <p> API-Served</p> <p>UI and backend fetch from <code>/models/...</code>. No local lists.</p> </li> </ul> <p>Get started Configuration API</p> <p>Single Source</p> <p><code>data/models.json</code> is the authoritative source for model availability, pricing, and context sizes. Update it to change selectable models.</p> <p>Components</p> <p>The <code>components</code> field indicates usage: <code>GEN</code> for generation, <code>EMB</code> for embeddings, <code>RERANK</code> for cross-encoders.</p> <p>Pricing Staleness</p> <p>Prices change over time. Keep <code>last_updated</code> current and reference sources in the file header.</p>"},{"location":"models/#api-endpoints","title":"API Endpoints","text":"Route Description <code>/models/by-type/{component_type}</code> Filter by <code>GEN</code>, <code>EMB</code>, or <code>RERANK</code> <code>/models/providers</code> List providers <code>/models/providers/{provider}</code> Models for a specific provider <pre><code>flowchart LR\n    Catalog[\"data/models.json\"] --&gt; API[\"/models\"]\n    API --&gt; UI[\"Model Pickers\"]\n    API --&gt; Server[\"Embedding/Reranker Selection\"]</code></pre>"},{"location":"models/#example-queries","title":"Example Queries","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\ngens = httpx.get(f\"{base}/models/by-type/GEN\").json()  # (1)\nproviders = httpx.get(f\"{base}/models/providers\").json()  # (2)\nopenai = httpx.get(f\"{base}/models/providers/openai\").json()  # (3)\nprint(len(gens), providers, len(openai))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/models/by-type/GEN\" | jq '.[0]'\ncurl -sS \"$BASE/models/providers\" | jq .\ncurl -sS \"$BASE/models/providers/openai\" | jq '.[].model'\n</code></pre> TypeScript <pre><code>type ModelItem = { provider: string; family: string; model: string; components: string[] };\n\nasync function listGen(): Promise&lt;ModelItem[]&gt; {\n  return await (await fetch(\"/models/by-type/GEN\")).json();\n}\n</code></pre> <ol> <li>Generation models</li> <li>Provider list</li> <li>Provider-specific catalog</li> </ol> <p>UI Contract</p> <p>All selectors in the UI must call these endpoints and use generated types for request/response where applicable.</p>"},{"location":"operations/","title":"Operations","text":""},{"location":"operations/#operations-health-and-metrics","title":"Operations, Health, and Metrics","text":"<ul> <li> <p> Health</p> <p><code>/health</code> and <code>/ready</code> for liveness and readiness.</p> </li> <li> <p> Metrics</p> <p><code>/metrics</code> for Prometheus. Plus Postgres exporter for DB metrics.</p> </li> <li> <p> Runtime Control</p> <p>Inspect and restart containers via Docker endpoints.</p> </li> </ul> <p>Get started Configuration API</p> <p>Readiness Gate</p> <p>Deployments should route traffic only after <code>/ready</code> returns success. This ensures PostgreSQL and Neo4j are reachable and responsive.</p> <p>Scrape Interval</p> <p>Metrics scraping interval can be 10\u201330 seconds depending on traffic and budget.</p> <p>High-Cardinality Labels</p> <p>Avoid per-query labels in Prometheus if cardinality explodes. Aggregate at the corpus or retriever level.</p>"},{"location":"operations/#endpoints","title":"Endpoints","text":"Endpoint Description <code>/health</code> Process liveness <code>/ready</code> Readiness including DB checks <code>/metrics</code> Prometheus metrics <code>/docker/status</code> Container status <code>/docker/{container}/restart</code> Restart container <code>/docker/{container}/logs</code> Tail logs <pre><code>flowchart LR\n    Scrape[\"Prometheus\"] --&gt; API_METRICS[\"/metrics\"]\n    API_METRICS --&gt; APP[\"TriBridRAG\"]\n    APP --&gt; PG[(\"Postgres\")]\n    APP --&gt; NEO[(\"Neo4j\")]\n    Scrape --&gt; PExp[\"postgres-exporter\"]</code></pre>"},{"location":"operations/#examples","title":"Examples","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/health\").json())\nprint(httpx.get(\"http://localhost:8000/ready\").json())\nprint(httpx.get(\"http://localhost:8000/metrics\").text.splitlines()[:5])\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/health').then(r =&gt; r.ok || Promise.reject('down'))\nawait fetch('/ready').then(r =&gt; r.ok || Promise.reject('not ready'))\nconst sample = await (await fetch('/metrics')).text();\nconsole.log(sample.split('\\n').slice(0, 5));\n</code></pre> <ul> <li> Gate traffic with readiness</li> <li> Alert on 5xx and slow search</li> <li> Monitor DB connection pool saturation and timeouts</li> </ul> <pre><code>flowchart TB\n    Alert[\"Alerts\"] --&gt; OnCall[\"On-Call\"]\n    Metrics[\"Metrics\"] --&gt; Alert\n    OnCall --&gt; Mitigate[\"Mitigation\"]</code></pre> Log Access <p>Use <code>/docker/{container}/logs</code> for quick log retrieval. For long-term retention, integrate with a centralized logging solution. Loki is included in the compose stack.</p>"},{"location":"retrieval_extra/","title":"Query Expansion and Confidence Thresholds","text":""},{"location":"retrieval_extra/#query-expansion-and-confidence-thresholds","title":"Query Expansion and Confidence Thresholds","text":"<ul> <li> <p> Expansion</p> <p>Multi-query rewrites and semantic synonyms improve recall.</p> </li> <li> <p> Confidence Gates</p> <p><code>conf_top1</code>, <code>conf_avg5</code>, and <code>conf_any</code> control retry/fallback behavior.</p> </li> <li> <p> Eval Alignment</p> <p>Match eval settings (<code>eval_multi</code>, <code>eval_final_k</code>) with production.</p> </li> </ul> <p>Get started Configuration API</p> Field Default Description <code>retrieval.max_query_rewrites</code> 2 LLM rewrites for search <code>retrieval.multi_query_m</code> 4 Variants per multi-query run <code>retrieval.use_semantic_synonyms</code> 1 Expand with curated synonyms <code>retrieval.conf_top1</code> 0.62 Threshold for early-accept top-1 <code>retrieval.conf_avg5</code> 0.55 Gate for rewrite retries <code>retrieval.conf_any</code> 0.55 Safety net threshold <pre><code>flowchart TB\n    Q0[\"Original Query\"] --&gt; REW[\"Rewrites\"]\n    REW --&gt; RET[\"Parallel Retrievals\"]\n    RET --&gt; FUS[\"Fusion\"]\n    FUS --&gt; GATE[\"Confidence Gates\"]\n    GATE --&gt;|pass| Return[\"Return\"]\n    GATE --&gt;|fail| Retry[\"Rewrite + Retry\"]</code></pre>"},{"location":"security/","title":"Security","text":""},{"location":"security/#security-and-secrets","title":"Security and Secrets","text":"<ul> <li> <p> Secrets</p> <p>API keys for providers and DB credentials loaded from environment.</p> </li> <li> <p> Validation</p> <p><code>/secrets/check</code> verifies presence and connectivity.</p> </li> <li> <p> Least Privilege</p> <p>Restrict DB users and network access.</p> </li> </ul> <p>Get started Configuration API</p> <p>Separate Environments</p> <p>Use different credentials per environment (dev, staging, prod). Never reuse production secrets locally.</p> <p>.env Hygiene</p> <p><code>.env</code> is for local dev only. In production, use a secret manager and inject env vars securely.</p> <p>Transport Security</p> <p>Terminate TLS in front of the API service. Restrict DB ports to private networks.</p>"},{"location":"security/#secrets-check","title":"Secrets Check","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/secrets/check\").json())\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/secrets/check | jq .\n</code></pre> TypeScript <pre><code>async function secrets() {\n  console.log(await (await fetch('/secrets/check')).json());\n}\n</code></pre>"},{"location":"security/#environment-keys-selected","title":"Environment Keys (Selected)","text":"Key Purpose <code>OPENAI_API_KEY</code>, <code>VOYAGE_API_KEY</code>, <code>COHERE_API_KEY</code>, <code>JINA_API_KEY</code> Provider access for embedding/gen/rerank <code>POSTGRES_*</code> DB connection for pgvector + FTS <code>NEO4J_*</code> Neo4j connection <code>SERVER_PORT</code> API service port <code>CONFIG_FILE</code> Path to <code>tribrid_config.json</code> <pre><code>flowchart LR\n    Env[\"Environment\"] --&gt; API\n    API --&gt; Check[\"/secrets/check\"]\n    Check --&gt; Report[\"Status\"]</code></pre> <p>Audit</p> <p>Log access to admin endpoints (<code>/config</code>, <code>/docker/*</code>, <code>/reranker/*</code>). Monitor for unusual patterns in logs and metrics.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p> Common Failures</p> <p>Timeouts, DB connectivity, schema mismatches.</p> </li> <li> <p> Validation Errors</p> <p>Pydantic constraints fail fast with precise messages.</p> </li> <li> <p> Recovery</p> <p>Clear caches, reindex, restart services.</p> </li> </ul> <p>Get started Configuration API</p> <p>Read the Error</p> <p>Pydantic tells you exactly which field failed validation and why. Fix the config, regenerate types if needed, and retry.</p> <p>Logs</p> <p>Use <code>/docker/{container}/logs</code> and application logs to pinpoint failures. For DB errors, also inspect Postgres and Neo4j logs.</p> <p>Data Loss Risk</p> <p>Avoid deleting DB volumes unless you intend a full reset. Back up before destructive actions.</p>"},{"location":"troubleshooting/#symptom-action","title":"Symptom \u2192 Action","text":"Symptom Likely Cause Action 500 on <code>/search</code> DB unavailable Check <code>/ready</code>, restart DB containers No results from graph Neo4j empty or disconnected Rebuild graph, check credentials Validation error on <code>/config</code> Field constraints violated Adjust values to allowed ranges Slow queries High <code>max_hops</code>, large <code>top_k</code> Reduce hops, tune indexes <pre><code>flowchart TB\n    Error[\"Error\"] --&gt; Check[\"/ready\"]\n    Check --&gt;|ok| Investigate[\"Inspect Logs\"]\n    Check --&gt;|fail| Restart[\"Restart Services\"]\n    Investigate --&gt; Fix[\"Config Tune\"]</code></pre>"},{"location":"troubleshooting/#useful-commands","title":"Useful Commands","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/ready\").json())  # readiness\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/docker/status | jq .\n</code></pre> TypeScript <pre><code>await fetch('/ready').then(r =&gt; r.ok || Promise.reject('Not ready'))\n</code></pre> <ul> <li> Verify readiness</li> <li> Inspect logs</li> <li> Reduce search/fusion parameters</li> <li> Reindex corpus</li> </ul> Cache Issues <p>If you suspect stale cache, clear retrieval caches (if enabled) or include a cache-busting parameter during debugging.</p>"},{"location":"architecture/health-metrics/","title":"Health & metrics","text":""},{"location":"architecture/health-metrics/#health-and-metrics-internals","title":"Health and Metrics Internals","text":"<ul> <li> <p> Liveness/Readiness</p> <p>Handlers return fine-grained status with DB probes.</p> </li> <li> <p> Prometheus</p> <p>Export standard and custom app metrics.</p> </li> <li> <p> DB Exporter</p> <p>PostgreSQL exporter complements app metrics.</p> </li> </ul> <p>Get started Configuration API</p> <p>Scrape Intervals</p> <p>Start with 15s scraping and tighten as necessary to capture spikes while controlling overhead.</p> <p>Metric Names</p> <p>Prefix application metrics with <code>tribrid_</code> and prefer corpus-level labels.</p> <p>Cardinality</p> <p>Avoid labels that grow per-query.</p> <pre><code>flowchart TB\n    App --&gt; METRICS[\"/metrics\"]\n    METRICS --&gt; Prom[\"Prometheus\"]\n    Postgres --&gt; PExp[\"postgres-exporter\"]\n    PExp --&gt; Prom</code></pre>"},{"location":"architecture/health-metrics/#access-examples","title":"Access Examples","text":"Python <pre><code>import httpx\nassert httpx.get(\"http://localhost:8000/health\").status_code == 200\nassert httpx.get(\"http://localhost:8000/ready\").status_code == 200\nprint(httpx.get(\"http://localhost:8000/metrics\").text.splitlines()[:5])\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health\ncurl -sS http://localhost:8000/ready\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/health').then(r =&gt; r.ok || Promise.reject('down'))\nawait fetch('/ready').then(r =&gt; r.ok || Promise.reject('not ready'))\nconst sample = await (await fetch('/metrics')).text();\nconsole.log(sample.split('\\n').slice(0, 5));\n</code></pre> <p>Observability</p> <p>Combine <code>/metrics</code> with logs and tracing for a complete operational picture.</p>"},{"location":"assets/images/","title":"Screenshots Guide","text":""},{"location":"assets/images/#screenshots-guide","title":"Screenshots Guide","text":"<ul> <li> <p> High-Quality Images</p> <p>Dark theme, 1920x1080, real data.</p> </li> <li> <p> What to Capture</p> <p>RAG config, search results, graph visualization, model picker, glossary.</p> </li> <li> <p> Organization</p> <p>Save descriptive filenames in <code>docs/assets/images/</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Suggested Shots</p> <ul> <li>RAG configuration with fusion weights and reranker</li> <li>Search results with citations</li> <li>Graph visualization (entities, relationships)</li> <li>Model selector and pricing info</li> <li>Glossary tooltips in action</li> </ul> <p>Filenames</p> <ul> <li><code>rag-config-interface.png</code></li> <li><code>search-results.png</code></li> <li><code>graph-visualization.png</code></li> <li><code>model-selector.png</code></li> </ul> <p>Privacy</p> <p>Ensure screenshots do not contain secrets or PII.</p>"},{"location":"assets/images/#add-images-to-docs","title":"Add Images to Docs","text":"<pre><code>![RAG Configuration Interface](./assets/images/rag-config-interface.png)\n</code></pre> Python <pre><code># Tip: keep images under docs/assets/images and reference with relative paths\nprint(\"Embed with ![alt](./assets/images/filename.png)\")\n</code></pre> curl <pre><code># No runtime step; images are static assets.\n</code></pre> TypeScript <pre><code>// Not applicable; images are referenced in markdown.\n</code></pre> <pre><code>flowchart TB\n    Shot[\"Screenshot\"] --&gt; File[\"docs/assets/images/*.png\"]\n    File --&gt; Markdown[\"Markdown Pages\"]\n    Markdown --&gt; Site[\"MkDocs Site\"]</code></pre> <ul> <li> Use dark mode</li> <li> Real data</li> <li> Descriptive filenames</li> </ul>"},{"location":"dev/pydantic/","title":"Pydantic","text":""},{"location":"dev/pydantic/#pydantic-first-development","title":"Pydantic-First Development","text":"<ul> <li> <p> The Law</p> <p>Everything starts in <code>tribrid_config_model.py</code>. If it\u2019s not there, it does not exist.</p> </li> <li> <p> Generate Types</p> <p><code>uv run scripts/generate_types.py</code> produces <code>web/src/types/generated.ts</code>.</p> </li> <li> <p> Derivation Chain</p> <p>Pydantic \u2192 generated.ts \u2192 stores \u2192 hooks \u2192 components.</p> </li> </ul> <p>Get started Configuration API</p> <p>Workflow</p> <ul> <li>Add/modify fields in Pydantic with <code>Field()</code> constraints and descriptions.</li> <li>Generate TS types.</li> <li>Use types in stores/hooks/components.</li> <li>Implement backend behavior that uses those fields.</li> </ul> <p>Constraints</p> <p>Use <code>Field(ge=..., le=..., description=...)</code> everywhere. Descriptions power docs and UI tooltips.</p> <p>No Adapters</p> <p>Never write client-side adapters to change response shapes. Fix the Pydantic model instead and regenerate.</p>"},{"location":"dev/pydantic/#derivation-chain","title":"Derivation Chain","text":"<pre><code>flowchart TB\n    P[\"Pydantic\\ntribrid_config_model.py\"] --&gt; G[\"pydantic2ts\\n(generate_types.py)\"]\n    G --&gt; T[\"generated.ts\"]\n    T --&gt; Z[\"Zustand Stores\"]\n    Z --&gt; H[\"Hooks\"]\n    H --&gt; C[\"Components\"]\n    P --&gt; A[\"FastAPI Schemas\"]</code></pre>"},{"location":"dev/pydantic/#commands-annotated","title":"Commands (Annotated)","text":"Python <pre><code>import subprocess\n\n# Generate TS types from Pydantic (1)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)\n\n# Validate sync (2)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/validate_types.py\"])  # (2)\n</code></pre> curl <pre><code># Run locally with Python; no direct curl equivalent\n</code></pre> TypeScript <pre><code>// After generation, import from generated.ts (3)\nimport type { TriBridConfig } from '../web/src/types/generated'; // (3)\n</code></pre> <ol> <li>Generate TypeScript types from Pydantic models</li> <li>Validate that generated types match current models</li> <li>Consume generated types exclusively</li> </ol>"},{"location":"dev/pydantic/#ralph-loop-verification-based-development","title":"Ralph Loop (Verification-Based Development)","text":"<ul> <li> Start from repo root</li> <li> For each iteration: pick first unchecked TODO, implement end-to-end</li> <li> Verification sequence:</li> <li><code>uv run scripts/check_banned.py</code></li> <li><code>uv run scripts/validate_types.py</code></li> <li><code>uv run pytest -q</code></li> <li> Only mark TODO complete when verification passes</li> </ul> <pre><code>flowchart TB\n    Iteration[\"Ralph Loop Iteration\"] --&gt; TODO[\"Read TODO.md\"]\n    TODO --&gt; Implement[\"Implement Feature\"]\n    Implement --&gt; Verify[\"Run Verification\"]\n    Verify --&gt;|pass| Next[\"Next Iteration\"]\n    Verify --&gt;|fail| Fix[\"Fix Exact Failure\"]</code></pre> Testing Discipline <ul> <li>GUI changes: Playwright tests with real interactions</li> <li>API changes: pytest with real request/response assertions</li> <li>Retrieval logic: verify relevance in results</li> </ul>"},{"location":"guides/corpus/","title":"Corpus","text":""},{"location":"guides/corpus/#corpus-vs-repo_id","title":"Corpus vs repo_id","text":"<ul> <li> <p> Corpus-First</p> <p>A corpus is any folder you index: repo, docs, or subtree.</p> </li> <li> <p> Isolation</p> <p>Each corpus has separate Postgres tables, Neo4j DB, and config.</p> </li> <li> <p> Naming Migration</p> <p>API accepts <code>repo_id</code> but serializes as <code>corpus_id</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Best Practice</p> <p>Use stable, lowercase slugs for corpus ids, e.g., <code>tribrid</code>, <code>myapp-docs</code>. Avoid spaces and special characters.</p> <p>AliasChoices</p> <p>Pydantic models specify <code>validation_alias=AliasChoices(\"repo_id\", \"corpus_id\")</code> and <code>serialization_alias=\"corpus_id\"</code> to ensure forward compatibility.</p> <p>Cross-Corpus Leakage</p> <p>Never mix <code>corpus_id</code> across requests. Isolation is enforced in storage and graph layers.</p>"},{"location":"guides/corpus/#models-using-corpus_id","title":"Models Using corpus_id","text":"Model Fields <code>IndexRequest</code> <code>corpus_id</code>, <code>repo_path</code>, <code>force_reindex</code> <code>IndexStatus</code> <code>corpus_id</code>, <code>status</code>, <code>progress</code>, <code>current_file</code> <code>SearchRequest</code> <code>corpus_id</code>, <code>query</code>, <code>top_k</code> <pre><code>flowchart LR\n    UI[\"UI\"] --&gt; API[\"API\"]\n    API --&gt; Pyd[\"AliasChoices(repo_id, corpus_id)\"]\n    Pyd --&gt; Store[\"Serialized as corpus_id\"]</code></pre>"},{"location":"guides/corpus/#example-requests","title":"Example Requests","text":"Python <pre><code>import httpx\nreq = {\"corpus_id\": \"tribrid\", \"repo_path\": \"/code/tribrid\", \"force_reindex\": False}\nhttpx.post(\"http://localhost:8000/index\", json=req)\nhttpx.get(\"http://localhost:8000/index/status\", params={\"corpus_id\": \"tribrid\"})\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/index -H 'Content-Type: application/json' -d '{\n  \"corpus_id\": \"tribrid\", \"repo_path\": \"/code/tribrid\", \"force_reindex\": false\n}'\n</code></pre> TypeScript <pre><code>import type { IndexRequest } from \"../../web/src/types/generated\";\nconst req: IndexRequest = { corpus_id: 'tribrid', repo_path: '/code/tribrid', force_reindex: false };\n</code></pre> <p>Multi-Corpus UIs</p> <p>Add a repo switcher bound to <code>corpus_id</code>. All panels (RAG, Graph, Index) should update in lockstep.</p>"},{"location":"howto/reranker/","title":"Reranker","text":""},{"location":"howto/reranker/#how-to-reranker-training-and-evaluation","title":"How-To: Reranker Training and Evaluation","text":"<ul> <li> <p> Reranker</p> <p>Cross-encoder stage to refine fused retrieval results.</p> </li> <li> <p>:material-mining:{ .lg .middle } Triplet Mining</p> <p>Collect (query, positive, negative) examples from logs or heuristics.</p> </li> <li> <p> Evaluate</p> <p>Benchmark before/after reranking on an evaluation dataset.</p> </li> </ul> <p>Get started Configuration API</p> <p>Start Small</p> <p>Begin with a small <code>eval_dataset</code> and a few hundred mined triplets. Validate that gains are consistent across corpora.</p> <p>Costs</p> <p>Training and evaluation costs depend on selected <code>RERANK</code> and <code>EMB/GEN</code> models from <code>data/models.json</code>.</p> <p>Config-Governed</p> <p>Enable via <code>reranking.reranker_mode</code>. All training hyperparameters must be present in Pydantic before use.</p>"},{"location":"howto/reranker/#api-surface","title":"API Surface","text":"Route Method Description <code>/reranker/status</code> GET Load status (mode/model) <code>/reranker/info</code> GET Implementation details <code>/reranker/mine</code> POST Mine triplets <code>/reranker/train</code> POST Train reranker <code>/reranker/evaluate</code> POST Evaluate against dataset <code>/reranker/train/run/{run_id}</code> GET Inspect a training run <code>/reranker/train/run/{run_id}/metrics</code> GET Metrics stream <pre><code>flowchart TB\n    Logs[\"Retrieval Logs\"] --&gt; Mine[\"Mine Triplets\"]\n    Mine --&gt; Train[\"Train Reranker\"]\n    Train --&gt; Model[\"Reranker Model\"]\n    Model --&gt; Eval[\"Evaluate\"]\n    Eval --&gt; Report[\"Metrics\"]</code></pre>"},{"location":"howto/reranker/#example-workflow-annotated","title":"Example Workflow (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\n# Mine triplets (1)\nhttpx.post(f\"{base}/reranker/mine\", json={\"corpus_id\": \"tribrid\", \"max_pairs\": 500}).raise_for_status()\n\n# Train (2)\nhttpx.post(f\"{base}/reranker/train\", json={\"corpus_id\": \"tribrid\", \"epochs\": 2, \"batch_size\": 16}).raise_for_status()\n\n# Evaluate (3)\nprint(httpx.post(f\"{base}/reranker/evaluate\", json={\"corpus_id\": \"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/mine\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"max_pairs\":500}'\ncurl -sS -X POST \"$BASE/reranker/train\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"epochs\":2,\"batch_size\":16}'\ncurl -sS -X POST \"$BASE/reranker/evaluate\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>async function trainReranker(corpus_id: string) {\n  await fetch('/reranker/mine', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id, max_pairs: 500 }) }); // (1)\n  await fetch('/reranker/train', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id, epochs: 2, batch_size: 16 }) }); // (2)\n  const report = await (await fetch('/reranker/evaluate', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id }) })).json(); // (3)\n  console.log(report);\n}\n</code></pre> <ol> <li>Mine triplets from logs/heuristics</li> <li>Train a local cross-encoder</li> <li>Evaluate results on your <code>eval_dataset</code></li> </ol>"},{"location":"howto/reranker/#reranker-config-fields-selected","title":"Reranker Config Fields (Selected)","text":"Field Description <code>reranking.reranker_mode</code> <code>none | local | learning | cloud</code> <code>reranking.reranker_cloud_provider</code> Provider id when cloud mode <code>reranking.reranker_local_model</code> HuggingFace/local model id <code>reranking.tribrid_reranker_topn</code> Candidates to rerank <code>reranking.rerank_input_snippet_chars</code> Max chars per candidate snippet <p>Evaluation Discipline</p> <p>Use a fixed <code>eval_dataset</code> to avoid overfitting. Track MRR, Recall@K, and NDCG pre/post reranking.</p>"},{"location":"integrations/mcp/","title":"MCP Integration (Model Context Protocol)","text":""},{"location":"integrations/mcp/#mcp-integration-model-context-protocol","title":"MCP Integration (Model Context Protocol)","text":"<ul> <li> <p> Embedded MCP HTTP</p> <p>Optional stateless HTTP transport for tools and clients.</p> </li> <li> <p> Access Control</p> <p>Allowed hosts/origins, optional API key, DNS rebinding protection.</p> </li> <li> <p> Defaults</p> <p>Per-endpoint defaults for retrieval mode and Top-K.</p> </li> </ul> <p>Get started Configuration API</p> <p>Stateless Mode</p> <p>Keep the embedded MCP HTTP endpoint stateless for easier scaling and isolation.</p> <p>Path and CORS</p> <p>Align <code>mount_path</code>, <code>allowed_hosts</code>, and <code>allowed_origins</code> with your reverse proxy and UI origin to avoid CORS issues.</p> <p>Auth</p> <p>Use <code>require_api_key=true</code> in multi-tenant or exposed deployments.</p>"},{"location":"integrations/mcp/#configuration-selected","title":"Configuration (Selected)","text":"Field Default Description <code>mcp.enabled</code> true Enable embedded MCP HTTP endpoint <code>mcp.mount_path</code> <code>/mcp</code> URL path for MCP endpoint <code>mcp.stateless_http</code> true Stateless mode <code>mcp.json_response</code> true Prefer JSON responses <code>mcp.enable_dns_rebinding_protection</code> true Defense in depth <code>mcp.allowed_hosts</code> <code>localhost:*</code> Allowed Host headers <code>mcp.allowed_origins</code> <code>http://localhost:*</code> Allowed Origin values <code>mcp.require_api_key</code> false Require <code>Authorization: Bearer</code> <code>mcp.default_top_k</code> 20 Default Top-K when omitted <code>mcp.default_mode</code> <code>tribrid</code> Default retrieval mode <pre><code>flowchart LR\n    Client[\"MCP Client\"] --&gt; HTTP[\"HTTP /mcp\"]\n    HTTP --&gt; RAG[\"TriBridRAG Tools\"]\n    RAG --&gt; Search[\"Search / Answer\"]</code></pre>"},{"location":"integrations/mcp/#status-endpoint","title":"Status Endpoint","text":"Python <pre><code>import httpx\nstatus = httpx.get(\"http://localhost:8000/mcp/status\").json()\nprint(status)\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/mcp/status | jq .\n</code></pre> TypeScript <pre><code>async function mcpStatus() {\n  const s = await (await fetch('/mcp/status')).json();\n  console.log(s);\n}\n</code></pre> <ul> <li> Set allowed hosts/origins</li> <li> Enable API key when exposing outside localhost</li> <li> Choose default retrieval mode/Top-K for tools</li> </ul>"},{"location":"retrieval/fusion/","title":"Fusion Details","text":""},{"location":"retrieval/fusion/#fusion-details","title":"Fusion Details","text":"<ul> <li> <p> Weighted Fusion</p> <p>Linear combination of normalized scores with interpretable weights.</p> </li> <li> <p> Reciprocal Rank Fusion</p> <p>Rank-based fusion robust to heterogeneous score distributions.</p> </li> <li> <p> Normalization</p> <p>Optional score normalization per leg before fusion.</p> </li> </ul> <p>Get started Configuration API</p> <p>Start with RRF</p> <p>RRF is often robust without per-leg calibration. Switch to <code>weighted</code> once you have stable score distributions and want more control.</p> <p>Weights Sum</p> <p>Pydantic validators normalize tri-brid weights to sum to 1.0.</p> <p>Mismatched Scales</p> <p>If you use <code>weighted</code>, enable <code>fusion.normalize_scores</code> unless all legs produce comparable scales.</p>"},{"location":"retrieval/fusion/#configuration","title":"Configuration","text":"Field Type Default Description <code>fusion.method</code> Literal <code>rrf</code> <code>rrf | weighted</code> <code>fusion.vector_weight</code> float 0.4 Vector contribution <code>fusion.sparse_weight</code> float 0.3 Sparse contribution <code>fusion.graph_weight</code> float 0.3 Graph contribution <code>fusion.rrf_k</code> int 60 RRF smoothing constant <code>fusion.normalize_scores</code> bool true Normalize per-leg scores <pre><code>flowchart TB\n    V[\"Vector Scores\"] --&gt; N[\"Normalize (opt)\"]\n    S[\"Sparse Scores\"] --&gt; N\n    G[\"Graph Scores\"] --&gt; N\n    N --&gt; W[\"Weighted Sum\"]\n    N --&gt; RRF[\"RRF (1/(k+rank))\"]</code></pre>"},{"location":"retrieval/fusion/#annotated-implementation-sketch","title":"Annotated Implementation Sketch","text":"Python <pre><code>def fuse(vector, sparse, graph, cfg):  # (1)\n    if cfg.fusion.method == \"rrf\":\n        return rrf_fusion(vector, sparse, graph, k=cfg.fusion.rrf_k)  # (2)\n    else:\n        if cfg.fusion.normalize_scores:\n            vector, sparse, graph = map(normalize01, (vector, sparse, graph))  # (3)\n        return weighted(vector, sparse, graph, (cfg.fusion.vector_weight, cfg.fusion.sparse_weight, cfg.fusion.graph_weight))  # (4)\n</code></pre> curl <pre><code># Fusion is server-controlled via config; no direct curl\n</code></pre> TypeScript <pre><code>// Client impacts fusion by PATCH /config/fusion\n</code></pre> <ol> <li>Inputs are per-leg result lists with scores</li> <li>RRF uses ranks only; tune <code>rrf_k</code></li> <li>Optional normalization improves comparability</li> <li>Weighted sum uses tri-brid weights (sum to ~1)</li> </ol>"},{"location":"retrieval/graph/","title":"Graph Retrieval and Storage","text":""},{"location":"retrieval/graph/#graph-retrieval-and-storage","title":"Graph Retrieval and Storage","text":"<ul> <li> <p> Graph Storage</p> <p>Neo4j stores entities/relationships; per-corpus isolation via database selection.</p> </li> <li> <p>:material-route:{ .lg .middle } Traversal</p> <p>Expand from seeds with <code>max_hops</code>, optionally adding neighbor context.</p> </li> <li> <p> Indexing Hooks</p> <p>Build lexical graph, store chunk embeddings, and (optionally) semantic KG.</p> </li> </ul> <p>Get started Configuration API</p> <p>Chunk Mode</p> <p>The <code>graph_search.mode=\"chunk\"</code> blends lexical adjacency with entity expansion for practical cross-file context.</p> <p>Per-Corpus Database</p> <p>Use <code>graph_storage.neo4j_database_mode=\"per_corpus\"</code> (Neo4j Enterprise) for hard isolation.</p> <p>Vector Index</p> <p>If you store chunk embeddings in Neo4j, ensure the vector index comes ONLINE before serving traffic.</p>"},{"location":"retrieval/graph/#search-configuration-selected","title":"Search Configuration (Selected)","text":"Field Default Description <code>graph_search.enabled</code> true Enable graph leg <code>graph_search.max_hops</code> 2 Traversal depth <code>graph_search.top_k</code> 30 Hits from traversal <code>graph_search.chunk_neighbor_window</code> 1 Include adjacent chunks <code>graph_search.chunk_entity_expansion_enabled</code> true Expand via entity links"},{"location":"retrieval/graph/#storage-configuration-selected","title":"Storage Configuration (Selected)","text":"Field Default Description <code>graph_storage.neo4j_uri</code> <code>bolt://localhost:7687</code> Connection URI <code>graph_storage.neo4j_user</code> <code>neo4j</code> Username <code>graph_storage.neo4j_password</code> \u2014 Password <code>graph_storage.max_hops</code> 2 Default traversal bound <code>graph_indexing.store_chunk_embeddings</code> true Store chunk vectors on nodes <code>graph_indexing.chunk_vector_index_name</code> <code>tribrid_chunk_embeddings</code> Vector index name <pre><code>flowchart LR\n    Seed[\"Seed Chunks\"] --&gt; Walk[\"Traversal (max_hops)\"]\n    Walk --&gt; Neigh[\"Neighbors\"]\n    Neigh --&gt; Return[\"Ranked Chunk IDs\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nentities = httpx.get(f\"{base}/graph/tribrid/entities\").json()\nfirst = entities[0]\nrels = httpx.get(f\"{base}/graph/tribrid/entity/{first['entity_id']}/neighbors\").json()\nprint(first['name'], len(rels.get('relationships', [])))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/graph/tribrid/entities\" | jq '.[0]'\n</code></pre> TypeScript <pre><code>async function neighbors(corpus: string) {\n  const ents = await (await fetch(`/graph/${corpus}/entities`)).json();\n  const id = ents[0].entity_id;\n  const rels = await (await fetch(`/graph/${corpus}/entity/${id}/neighbors`)).json();\n  console.log(id, rels.relationships.length);\n}\n</code></pre>"},{"location":"retrieval/overview/","title":"Overview","text":""},{"location":"retrieval/overview/#retrieval-overview","title":"Retrieval Overview","text":"<ul> <li> <p> Vector Search</p> <p>pgvector similarity over chunk embeddings with configurable Top-K.</p> </li> <li> <p> Sparse Search</p> <p>PostgreSQL FTS/BM25 for exact tokens, identifiers, and literals.</p> </li> <li> <p> Graph Search</p> <p>Neo4j traversal to expand neighborhoods and follow relationships across files.</p> </li> <li> <p> Fusion</p> <p>Weighted or RRF; per-retriever contributions tracked for analysis.</p> </li> <li> <p> Optional Reranker</p> <p>Cross-encoder rescoring of fused candidates for precision.</p> </li> </ul> <p>Get started Configuration API</p> <p>Balance Recall and Precision</p> <p>Increase per-leg Top-K to maximize recall; use fusion weights and reranking to restore precision.</p> <p>Isolation by Corpus</p> <p>Each corpus has isolated storage and graph. Queries always require <code>corpus_id</code>.</p> <p>Latency Budget</p> <p>Graph traversal increases latency with larger hop counts. Use <code>max_hops</code> conservatively.</p>"},{"location":"retrieval/overview/#control-surface-selected","title":"Control Surface (Selected)","text":"Retriever Key Fields Defaults Vector <code>vector_search.enabled</code>, <code>vector_search.top_k</code> 50 Sparse <code>sparse_search.enabled</code>, <code>sparse_search.top_k</code>, <code>sparse_search.bm25_k1</code>, <code>sparse_search.bm25_b</code> 50 / 1.2 / 0.4 Graph <code>graph_search.enabled</code>, <code>graph_search.max_hops</code>, <code>graph_search.top_k</code> true / 2 / 30 Fusion <code>fusion.method</code>, <code>fusion.rrf_k</code>, <code>fusion.*_weight</code> rrf / 60 Reranker <code>reranking.reranker_mode</code>, <code>tribrid_reranker_topn</code> local / 50 <pre><code>flowchart LR\n    Q[\"Query\"] --&gt; V[\"Vector\"]\n    Q --&gt; S[\"Sparse\"]\n    Q --&gt; G[\"Graph\"]\n    V --&gt; F[\"Fusion\"]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[\"Reranker (opt)\"]\n    R --&gt; OUT[\"Results\"]\n    F --&gt; OUT</code></pre>"},{"location":"retrieval/overview/#programmatic-search","title":"Programmatic Search","text":"Python <pre><code>import httpx\nBASE = \"http://localhost:8000\"\nbody = {\"corpus_id\": \"tribrid\", \"query\": \"How are pgvector indexes created?\", \"top_k\": 10}\nres = httpx.post(f\"{BASE}/search\", json=body).json()  # (1)\nfor r in res.get(\"matches\", []):\n    print(r[\"file_path\"], r[\"score\"])  # fused score (2)\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/search \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"corpus_id\":\"tribrid\",\"query\":\"pgvector index\",\"top_k\":10}' | jq '.matches[0]'\n</code></pre> TypeScript <pre><code>import type { SearchRequest, SearchResponse } from \"../../web/src/types/generated\";\n\nasync function run(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const r = await fetch(\"/search\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) });\n  return await r.json();\n}\n</code></pre> <ol> <li>Search executes all retrievers concurrently</li> <li><code>score</code> is fused; provenance retained in each <code>ChunkMatch.source</code></li> </ol> <p>Auditable Fusion</p> <p><code>SearchResponse.debug</code> can include per-leg diagnostics when enabled.</p> Caching <p>Retrieval cache keys include <code>corpus_id</code>, <code>query</code>, and a hash of relevant retrieval config. Invalidate on config change or reindex.</p>"},{"location":"retrieval/vector-sparse/","title":"Vector + Sparse Retrieval","text":""},{"location":"retrieval/vector-sparse/#vector-sparse-retrieval","title":"Vector + Sparse Retrieval","text":"<ul> <li> <p> Dense Semantics</p> <p>Embeddings capture meaning beyond exact tokens.</p> </li> <li> <p> Keyword Precision</p> <p>BM25 excels at exact identifiers, error codes, and file names.</p> </li> <li> <p> Hybrid Strength</p> <p>Combining both improves recall and precision across query types.</p> </li> </ul> <p>Get started Configuration API</p> <p>Tune Weights</p> <p>Set <code>retrieval.vector_weight</code> vs <code>retrieval.bm25_weight</code> (and/or <code>fusion.*_weight</code>) based on corpus characteristics.</p> <p>Top-K Budget</p> <p>Keep <code>topk_dense</code> and <code>topk_sparse</code> high enough that <code>final_k</code> always has good candidates.</p> <p>Embedding Mismatch</p> <p>Changing embedding model/dimensions requires full reindexing.</p> Field Default Notes <code>vector_search.top_k</code> 50 Candidate set size for dense <code>sparse_search.top_k</code> 50 Candidate set size for BM25 <code>retrieval.final_k</code> 10 Returned results after fusion"}]}