{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"TriBridRAG Documentation","text":"<ul> <li> <p> Tri-brid Retrieval</p> <p>Parallel Vector (pgvector), Sparse (PostgreSQL FTS/BM25), and Graph (Neo4j) search fused with configurable strategies.</p> </li> <li> <p> Pydantic Is The Law</p> <p>All configuration and API shapes live in <code>server/models/tribrid_config_model.py</code>. Everything else derives from it.</p> </li> <li> <p> PostgreSQL Backbone</p> <p>Chunk storage, embeddings, pgvector indexing, and FTS in one database.</p> </li> <li> <p> Knowledge Graph</p> <p>Neo4j stores entities/relationships and supports traversal for cross-file context.</p> </li> <li> <p> API-First</p> <p>FastAPI endpoints for indexing, retrieval, graph, models, health, metrics, and training.</p> </li> <li> <p> Operational Safety</p> <p>Field constraints, readiness gates, metrics, and cost-aware model selection.</p> </li> </ul> <p>Get started Configuration API</p> <p>Read This First</p> <p>TriBridRAG is strictly Pydantic-first. If a field or feature is not in <code>server/models/tribrid_config_model.py</code>, it does not exist. Add it there, regenerate TypeScript types, then build the rest.</p> <p>Terminology \u2014 corpus vs repo_id</p> <p>The API still accepts <code>repo_id</code> for legacy reasons. Treat it as the corpus identifier. Pydantic models use <code>AliasChoices(\"repo_id\", \"corpus_id\")</code> and serialize as <code>corpus_id</code>.</p> <p>Security</p> <p>Keep <code>.env</code> out of version control. Restrict database access. Use strong passwords for PostgreSQL and Neo4j. Rotate API keys regularly.</p>"},{"location":"#what-tribridrag-does","title":"What TriBridRAG Does","text":"Feature Description Status Vector Search Dense similarity via pgvector in PostgreSQL \u2705 Active Sparse Search PostgreSQL FTS/BM25 for exact terms, identifiers \u2705 Active Graph Search Neo4j traversal to follow entities/relations \u2705 Active Fusion Weighted/reciprocal-rank fusion of sources \u2705 Active Reranker Optional cross-encoder reranking \u2705 Active"},{"location":"#end-to-end-retrieval-flow","title":"End-to-End Retrieval Flow","text":"<pre><code>flowchart LR\n    Q[\"Query\"] --&gt; V[\"Vector Search\\n(pgvector)\"]\n    Q --&gt; S[\"Sparse Search\\n(PostgreSQL FTS)\"]\n    Q --&gt; G[\"Graph Search\\n(Neo4j)\"]\n    V --&gt; F[\"Fusion Layer\"]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[\"Reranker\\n(optional)\"]\n    R --&gt; O[\"Results\"]\n    F --&gt; O</code></pre>"},{"location":"#quickstart-run-index-search","title":"Quickstart \u2014 Run, Index, Search","text":"<ul> <li> Configure environment (.env)</li> <li> Launch services with Docker Compose</li> <li> Regenerate TypeScript types from Pydantic</li> <li> Index a corpus</li> <li> Search via API</li> <li> Tune fusion weights and confidence thresholds</li> <li> Enable reranking if needed</li> </ul> <p>Use Ctrl+C to stop local <code>uvicorn</code> or Docker tail sessions.</p> Python <pre><code>import httpx, subprocess\n\nBASE = \"http://localhost:8000\"\n\n# 1) Generate TS types from Pydantic (required for UI) (1)!\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1) Types derive from Pydantic\n\n# 2) Trigger indexing of a corpus (2)!\nreq = {\n    \"corpus_id\": \"tribrid\",  # (3)! repo_id alias is also accepted\n    \"repo_path\": \"/path/to/your/codebase\",\n    \"force_reindex\": False,\n}\nhttpx.post(f\"{BASE}/index\", json=req).raise_for_status()\n\n# 3) Poll status (4)!\nstatus = httpx.get(f\"{BASE}/index/status\", params={\"corpus_id\": \"tribrid\"}).json()\nprint(status)\n\n# 4) Search (parallel vector/sparse/graph -&gt; fusion -&gt; optional rerank) (5)!\npayload = {\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"How does the chunker split Python files?\",\n    \"top_k\": 8,\n}\nres = httpx.post(f\"{BASE}/search\", json=payload).json()\nfor m in res.get(\"matches\", []):\n    print(m[\"file_path\"], m[\"score\"])  # fused score\n</code></pre> <ol> <li>Pydantic \u2192 generated types is a hard contract</li> <li>Start an indexing job for your corpus</li> <li>Inputs accept <code>repo_id</code> but serialize as <code>corpus_id</code></li> <li>Poll index status to show progress in UI</li> <li>Search runs vector/sparse/graph in parallel, fuses, then optionally reranks</li> </ol> curl <pre><code>BASE=http://localhost:8000\n\n# Start indexing (1)!\ncurl -sS -X POST \"$BASE/index\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"repo_path\": \"/path/to/your/codebase\",\n    \"force_reindex\": false\n  }'\n\n# Status (2)!\ncurl -sS \"$BASE/index/status?corpus_id=tribrid\" | jq .\n\n# Search (3)!\ncurl -sS -X POST \"$BASE/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"How does the chunker split Python files?\",\n    \"top_k\": 8\n  }' | jq '.matches[] | {file_path, score}'\n</code></pre> <ol> <li>Kick off corpus indexing</li> <li>Verify progress and current file</li> <li>Run tri-brid retrieval</li> </ol> TypeScript <pre><code>// Ensure ./web/src/types/generated.ts exists (generated by Python) (1)!\nimport type { IndexRequest, SearchRequest, SearchResponse } from \"./web/src/types/generated\";\n\nasync function indexAndSearch() {\n  const base = \"http://localhost:8000\";\n\n  const indexReq: IndexRequest = {\n    corpus_id: \"tribrid\", // (2)! repo_id alias also accepted server-side\n    repo_path: \"/path/to/your/codebase\",\n    force_reindex: false,\n  };\n  await fetch(`${base}/index`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(indexReq),\n  });\n\n  const searchReq: SearchRequest = {\n    corpus_id: \"tribrid\",\n    query: \"chunker split Python\",\n    top_k: 8,\n  } as any;\n\n  const r = await fetch(`${base}/search`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(searchReq),\n  });\n  const data: SearchResponse = await r.json(); // (3)!\n  console.log(data.matches.map(m =&gt; [m.file_path, m.score]));\n}\n</code></pre> <ol> <li>Import only generated API types</li> <li>Scoped by <code>corpus_id</code> (alias of legacy <code>repo_id</code>)</li> <li>Response includes fused matches and timings</li> </ol>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart TB\n    subgraph Client\n      U[\"User / UI / API Client\"]\n    end\n\n    U --&gt; A[\"FastAPI\"]\n    A --&gt; V[\"VectorRetriever\\n(Postgres+pgvector)\"]\n    A --&gt; S[\"SparseRetriever\\n(Postgres FTS)\"]\n    A --&gt; G[\"GraphRetriever\\n(Neo4j)\"]\n    V --&gt; F[\"Fusion\"]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[\"Reranker\\n(optional)\"]\n    R --&gt; O[\"Final Results\"]\n    F --&gt; O\n\n    subgraph Storage\n      P[\"PostgreSQL\"]\n      N[\"Neo4j\"]\n    end\n\n    V &lt;--&gt; P\n    S &lt;--&gt; P\n    G &lt;--&gt; N</code></pre> Advanced Topics <ul> <li>Fusion math: weighted linear combination and Reciprocal Rank Fusion with configurable <code>fusion.rrf_k</code>.</li> <li>Retrieval cache: cache keys include <code>corpus_id</code>, <code>query</code>, and a hash of the retrieval config subset.</li> <li>Failure isolation: vector, sparse, and graph legs are resilient; a failure in one leg degrades gracefully.</li> </ul>"},{"location":"api/","title":"API Reference","text":"<ul> <li> <p> FastAPI Endpoints</p> <p>Endpoints for config, indexing, retrieval, graph, models, keywords, reranker, and health.</p> </li> <li> <p> Schema by Pydantic</p> <p>Request/response models are defined in Pydantic. The frontend imports generated TypeScript types.</p> </li> <li> <p> Secrets Check</p> <p>Validate configured API keys and DB connections via <code>/secrets/check</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Inspect Schemas</p> <p>Prefer calling <code>/config</code> first to align UI interactions with actual server capabilities. All shapes are Pydantic-driven.</p> <p>HTTP Conventions</p> <ul> <li>JSON requests/responses</li> <li>Errors via standard status codes with <code>detail</code></li> <li>Streaming responses for long operations are <code>text/event-stream</code> or chunked JSON</li> </ul> <p>Model Usage Costs</p> <p>Reranking and keyword generation may incur API costs depending on selected models. Control via <code>data/models.json</code> and <code>TriBridConfig</code>.</p>"},{"location":"api/#endpoint-inventory","title":"Endpoint Inventory","text":"Area Route Method Purpose Config <code>/config</code> GET Get full config Config <code>/config</code> PUT Replace config Config <code>/config/{section}</code> PATCH Sectional patch, e.g., <code>fusion</code> Config <code>/config/reset</code> POST Reset to defaults Secrets <code>/secrets/check</code> GET Check provider keys + DB connections Index <code>/index</code> POST Start indexing Index <code>/index/status</code> GET Status for a corpus Index <code>/index/stats</code> GET Storage stats summary Index <code>/index/{corpus_id}/status</code> GET Per-corpus status Index <code>/index/{corpus_id}/stats</code> GET Per-corpus storage breakdown Index <code>/index/vocab-preview</code> GET BM25 vocabulary sample Search <code>/search</code> POST Tri-brid retrieval + fusion (+reranker) Answer <code>/answer</code> POST Retrieval + LLM answer generation Graph <code>/graph/{corpus_id}/entities</code> GET List entities Graph <code>/graph/{corpus_id}/entity/{id}</code> GET Entity details Graph <code>/graph/{corpus_id}/entity/{id}/neighbors</code> GET Neighborhood Models <code>/models/by-type/{component}</code> GET Models by component <code>GEN/EMB/RERANK</code> Keywords <code>/keywords/generate</code> POST Generate discriminative keywords Reranker <code>/reranker/*</code> mixed Status / mine / train / evaluate Health <code>/health</code> GET Liveness Health <code>/ready</code> GET Readiness Metrics <code>/metrics</code> GET Prometheus exposition Docker <code>/docker/*</code> GET/POST Infra status, logs, restart MCP <code>/mcp/status</code> GET MCP inbound transport status <pre><code>flowchart TB\n    CLI[\"Client\"] --&gt; API[\"FastAPI\"]\n    API --&gt; PC[\"Postgres Client\"]\n    API --&gt; NC[\"Neo4j Client\"]\n    API --&gt; CFG[\"Pydantic Models\"]\n    API --&gt; ML[\"Model Catalog\"]\n    PC --&gt; DB[\"PostgreSQL\"]\n    NC --&gt; GDB[\"Neo4j\"]</code></pre>"},{"location":"api/#example-search-roundtrip-annotated","title":"Example: Search Roundtrip (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\npayload = {\n    \"corpus_id\": \"tribrid\",  # (1)!\n    \"query\": \"authentication flow\",\n    \"top_k\": 10\n}\nresp = httpx.post(f\"{base}/search\", json=payload)\nresp.raise_for_status()\nres = resp.json()  # type: SearchResponse (2)!\nprint(res[\"fusion_method\"], len(res[\"matches\"]))\n</code></pre> <ol> <li>Always scope by <code>corpus_id</code> (legacy <code>repo_id</code> is accepted)</li> <li>Response includes <code>fusion_method</code>, <code>reranker_mode</code>, <code>latency_ms</code>, and <code>matches</code></li> </ol> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"corpus_id\":\"tribrid\",\"query\":\"authentication flow\",\"top_k\":10}' | jq '.fusion_method, .matches | length'\n</code></pre> TypeScript <pre><code>import type { SearchRequest, SearchResponse } from \"./web/src/types/generated\";\n\nasync function run(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const r = await fetch(\"/search\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) });\n  return await r.json(); // (2)!\n}\n</code></pre>"},{"location":"api/#health-and-metrics","title":"Health and Metrics","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/ready\").json())   # readiness\nprint(httpx.get(\"http://localhost:8000/metrics\").text[:300])  # metrics sample\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/ready').then(r =&gt; r.ok || Promise.reject('Not ready'))\nconst metrics = await (await fetch('/metrics')).text()\nconsole.log(metrics.split('\\n').slice(0,5))\n</code></pre> Streaming <p>Endpoints that can stream long-running operations (e.g., evaluation logs, training metrics) use Server-Sent Events or chunked JSON. Use backpressure-aware clients.</p>"},{"location":"api_extra/","title":"API Cheatsheet (Quick Calls)","text":"<ul> <li> <p> Fast Paths</p> <p>Minimal calls to get from zero to search.</p> </li> <li> <p> Config</p> <p>Read, patch, reset.</p> </li> <li> <p> Search</p> <p>Tri-brid retrieval with optional reranking.</p> </li> </ul> <p>Get started Configuration API</p> Python <pre><code>import httpx\nB = \"http://localhost:8000\"\nhttpx.get(f\"{B}/ready\").raise_for_status()\nhttpx.post(f\"{B}/index\", json={\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":False})\nprint(httpx.post(f\"{B}/search\", json={\"corpus_id\":\"tribrid\",\"query\":\"auth flow\",\"top_k\":10}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/ready\" | jq .\ncurl -sS -X POST \"$BASE/index\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":false}'\ncurl -sS -X POST \"$BASE/search\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"query\":\"auth flow\",\"top_k\":10}' | jq .\n</code></pre> TypeScript <pre><code>await fetch('/ready')\nawait fetch('/index', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', repo_path:'/repo', force_reindex:false }) })\nconst data = await (await fetch('/search', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', query:'auth flow', top_k:10 }) })).json()\nconsole.log(data)\n</code></pre> <p>Use generated types</p> <p>In TS code, import <code>SearchRequest</code>, <code>SearchResponse</code>, <code>IndexRequest</code> from <code>web/src/types/generated.ts</code>.</p>"},{"location":"api_graph/","title":"Graph API (Entities and Relationships)","text":"<ul> <li> <p> Entities</p> <p>Functions, classes, modules, variables, concepts.</p> </li> <li> <p> Relationships</p> <p>calls, imports, inherits, contains, references.</p> </li> <li> <p> Communities</p> <p>Optional clustering for related entities.</p> </li> </ul> <p>Get started Configuration API</p> <p>Chunk mode</p> <p>Prefer <code>graph_search.mode=chunk</code> to blend Neo4j vector search on chunk nodes with traversal.</p> <p>Database isolation</p> <p>Use <code>graph_storage.neo4j_database_mode</code> with <code>per_corpus</code> (Enterprise) to avoid cross-corpus filters.</p> <p>Hops</p> <p>High <code>max_hops</code> increases latency and noise. Start at 2.</p> Route Method Description <code>/graph/{corpus_id}/entities</code> GET List entities <code>/graph/{corpus_id}/entity/{entity_id}</code> GET Entity details <code>/graph/{corpus_id}/entity/{entity_id}/relationships</code> GET Direct edges <code>/graph/{corpus_id}/entity/{entity_id}/neighbors</code> GET 1-hop neighborhood <code>/graph/{corpus_id}/communities</code> GET List communities <pre><code>flowchart LR\n    Center[\"Entity\"] --&gt; Calls[\"calls\"]\n    Center --&gt; Imports[\"imports\"]\n    Center --&gt; Inherits[\"inherits\"]\n    Center --&gt; Contains[\"contains\"]\n    Center --&gt; Refs[\"references\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nents = httpx.get(f\"{base}/graph/tribrid/entities\").json()\nprint(\"entities\", len(ents))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/graph/tribrid/entities\" | jq '.[0]'\n</code></pre> TypeScript <pre><code>const ents = await (await fetch('/graph/tribrid/entities')).json();\nconsole.log(ents.length)\n</code></pre> Communities <p>When enabled, community detection summarizes clusters and exposes <code>Community</code> objects with members and level.</p>"},{"location":"api_health/","title":"Health, Readiness, and Metrics API","text":"<ul> <li> <p> Liveness</p> <p><code>/health</code> returns process liveness.</p> </li> <li> <p> Readiness</p> <p><code>/ready</code> verifies DB connectivity.</p> </li> <li> <p> Metrics</p> <p><code>/metrics</code> exposes Prometheus metrics.</p> </li> </ul> <p>Get started Configuration API</p> <p>Gate Traffic</p> <p>Route production traffic only after readiness returns 200.</p> <p>Exporter</p> <p>A Postgres exporter is included in the compose stack; scrape it alongside <code>/metrics</code>.</p> <p>High-cardinality</p> <p>Avoid per-query labels in custom metrics. Aggregate by corpus or retriever.</p> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/health\").json())\nprint(httpx.get(\"http://localhost:8000/ready\").json())\nprint(httpx.get(\"http://localhost:8000/metrics\").text[:200])\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/health')\nawait fetch('/ready')\nconst m = await (await fetch('/metrics')).text();\nconsole.log(m.split('\\n').slice(0,5))\n</code></pre> <pre><code>flowchart LR\n    Scrape[\"Prometheus\"] --&gt; API_METRICS[\"/metrics\"]\n    API_METRICS --&gt; APP[\"TriBridRAG\"]\n    APP --&gt; PG[\"Postgres\"]\n    APP --&gt; NEO[\"Neo4j\"]\n    Scrape --&gt; PExp[\"postgres-exporter\"]</code></pre> Loki/Grafana <p>Logs and dashboards are available via Loki and Grafana services started by <code>docker compose</code>.</p>"},{"location":"api_indexing/","title":"Indexing API","text":"<ul> <li> <p> Start</p> <p><code>POST /index</code> with <code>IndexRequest</code>.</p> </li> <li> <p> Status</p> <p><code>GET /index/status</code> returns progress, current file.</p> </li> <li> <p> Stats</p> <p><code>GET /index/stats</code> returns storage breakdown.</p> </li> </ul> <p>Get started Configuration API</p> <p>Force reindex</p> <p>Set <code>force_reindex=true</code> only when you need a clean rebuild. Incremental updates are cheaper.</p> <p>BM25 vocabulary</p> <p><code>/index/vocab-preview</code> helps debug tokenizer/stemmer stopword settings.</p> <p>Repo path</p> <p>Ensure <code>repo_path</code> points to a locally accessible directory (bind-mount in Docker).</p> Route Method Description <code>/index</code> POST Start indexing <code>/index/status</code> GET Current state <code>/index/stats</code> GET Storage stats <pre><code>flowchart LR\n    Start[\"POST /index\"] --&gt; Worker[\"Indexer\"]\n    Worker --&gt; Status[\"GET /index/status\"]\n    Worker --&gt; Stats[\"GET /index/stats\"]</code></pre> Python <pre><code>import httpx\nhttpx.post(\"http://localhost:8000/index\", json={\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":False})\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/index -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"repo_path\":\"/repo\",\"force_reindex\":false}'\n</code></pre> TypeScript <pre><code>await fetch('/index', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', repo_path:'/repo', force_reindex:false }) })\n</code></pre> Dashboard <p>Use <code>DashboardIndexStatusResponse</code> and <code>DashboardIndexStatsResponse</code> to populate UI storage and status panels per corpus.</p>"},{"location":"api_models/","title":"Domain Models (Core Shapes)","text":"<ul> <li> <p> Chunks</p> <p><code>Chunk</code>, <code>ChunkMatch</code>, <code>ChunkSummary</code> are the bread-and-butter types for RAG.</p> </li> <li> <p> Search/Answer</p> <p><code>SearchRequest/Response</code>, <code>AnswerRequest/Response</code>.</p> </li> <li> <p> Chat</p> <p><code>ChatRequest/Response</code> with debug metadata.</p> </li> </ul> <p>Get started Configuration API</p> <p>Use generated types</p> <p>Import types from <code>web/src/types/generated.ts</code>. Do not hand-write interfaces.</p> <p>Provenance</p> <p><code>ChunkMatch.source</code> preserves which leg (vector/sparse/graph) produced the match.</p> <p>Line Ranges</p> <p>When hydrating content, respect <code>hydration_max_chars</code> to avoid oversized payloads.</p> Model Key Fields <code>Chunk</code> <code>chunk_id</code>, <code>content</code>, <code>file_path</code>, <code>start_line</code>, <code>end_line</code>, <code>language</code>, <code>token_count</code> <code>ChunkMatch</code> <code>chunk_id</code>, <code>score</code>, <code>source</code>, <code>metadata</code> <code>SearchRequest</code> <code>corpus_id</code>, <code>query</code>, <code>top_k</code>, <code>include_vector/sparse/graph</code> <code>SearchResponse</code> <code>matches</code>, <code>fusion_method</code>, <code>reranker_mode</code>, <code>latency_ms</code> <code>AnswerRequest</code> <code>corpus_id</code>, <code>query</code>, <code>top_k</code>, <code>stream</code> <code>AnswerResponse</code> <code>answer</code>, <code>sources</code>, <code>model</code>, <code>tokens_used</code> <pre><code>flowchart LR\n    Req[\"SearchRequest\"] --&gt; API\n    API --&gt; Res[\"SearchResponse\"]\n    Res --&gt; UI[\"UI Components\"]</code></pre> Python <pre><code>from pprint import pprint\nimport httpx\npprint(httpx.post(\"http://localhost:8000/search\", json={\"corpus_id\":\"tribrid\",\"query\":\"auth\",\"top_k\":5}).json())\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/search -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"query\":\"auth\",\"top_k\":5}' | jq .\n</code></pre> TypeScript <pre><code>import type { SearchResponse } from \"./web/src/types/generated\";\nconst data: SearchResponse = await (await fetch('/search', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', query:'auth', top_k:5 }) })).json();\n</code></pre> Hydration <p>Hydration strategy is controlled by <code>hydration.hydration_mode</code> and <code>hydration.hydration_max_chars</code> (also surfaced under <code>retrieval.*</code> for convenience).</p>"},{"location":"api_models_chat/","title":"Chat Models","text":"<ul> <li> <p> Request/Response</p> <p><code>ChatRequest</code> and <code>ChatResponse</code> with streaming option.</p> </li> <li> <p> Debug Info</p> <p><code>ChatDebugInfo</code> includes per-leg enablement and fusion params.</p> </li> <li> <p> Tracing</p> <p><code>Trace</code>, <code>TraceEvent</code>, and <code>/traces/latest</code> for last run.</p> </li> </ul> <p>Get started Configuration API</p> <p>Data Sources</p> <p>Chat composes sources: one or more corpora and (optionally) Recall. There are no modes \u2014 everything composes.</p> <p>Vision</p> <p><code>images</code> supports up to 5 attachments when the model/provider supports multimodal.</p> <p>Recall Scope</p> <p>Recall gating only affects Recall; RAG corpora are always queried when checked.</p> Model Key Fields <code>ChatRequest</code> <code>message</code>, <code>corpus_id</code>, <code>sources</code>, <code>top_k</code>, <code>include_vector/sparse/graph</code>, <code>stream</code> <code>ChatResponse</code> <code>message</code>, <code>sources</code>, <code>tokens_used</code>, <code>debug</code>, <code>conversation_id</code> <code>ChatDebugInfo</code> <code>fusion_method</code>, <code>rrf_k</code>, per-leg weights, confidence thresholds, counts <pre><code>flowchart LR\n    Req[\"ChatRequest\"] --&gt; API\n    API --&gt; Res[\"ChatResponse\"]\n    Res --&gt; UI[\"Render + Sources\"]</code></pre> Python <pre><code>import httpx\nprint(httpx.post(\"http://localhost:8000/chat\", json={\"corpus_id\":\"tribrid\",\"message\":\"where is auth?\"}).json())\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/chat -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"message\":\"where is auth?\"}' | jq .\n</code></pre> TypeScript <pre><code>const r = await (await fetch('/chat', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid', message:'where is auth?' }) })).json();\n</code></pre> Recall Gate <p><code>ChatResponse.debug.recall_plan</code> exposes the decision: intensity, overrides, and the signals behind them.</p>"},{"location":"api_models_eval/","title":"Evaluation Models","text":"<ul> <li> <p> Eval Dataset</p> <p><code>EvalDatasetItem</code> defines questions and expected paths.</p> </li> <li> <p> Metrics</p> <p><code>EvalMetrics</code>, <code>EvalRun</code>, <code>EvalResult</code> capture performance.</p> </li> <li> <p> Comparisons</p> <p><code>EvalComparisonResult</code> compares two runs.</p> </li> </ul> <p>Get started Configuration API</p> <p>Match Production</p> <p>Tune <code>eval_final_k</code> and <code>eval_multi</code> to reflect real usage; misaligned evals mislead.</p> <p>Config Snapshots</p> <p><code>EvalRun</code> stores both nested and flat config snapshots for reproducibility.</p> <p>Latency Budget</p> <p>Track <code>latency_p95_ms</code> across runs to guard against regressions.</p> Model Purpose <code>EvalDatasetItem</code> Single question + expected file paths <code>EvalMetrics</code> Aggregated metrics (MRR, Recall@K, NDCG@10, latency percentiles) <code>EvalRun</code> Complete run with config snapshot and results <code>EvalComparisonResult</code> Delta between baseline and current runs <pre><code>flowchart TB\n    Dataset[\"Eval Dataset\"] --&gt; Run[\"Eval Run\"]\n    Run --&gt; Metrics[\"Eval Metrics\"]\n    Run --&gt; Results[\"Per-Entry Results\"]\n    Metrics --&gt; Compare[\"Compare Runs\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nprint(httpx.post(f\"{base}/reranker/evaluate\", json={\"corpus_id\": \"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/evaluate\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>const report = await (await fetch('/reranker/evaluate', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id: 'tribrid' }) })).json();\n</code></pre> Top-K alignment <p>Ensure <code>eval_final_k &gt;= retrieval.final_k</code> when you want strict hit@K parity with production.</p>"},{"location":"api_models_extra/","title":"Index Dashboard Models","text":"<ul> <li> <p> Storage Breakdown</p> <p><code>DashboardIndexStorageBreakdown</code> shows bytes across Postgres + Neo4j.</p> </li> <li> <p> Costs</p> <p><code>DashboardIndexCosts</code> estimates embedding costs.</p> </li> <li> <p> Embedding Config</p> <p><code>DashboardEmbeddingConfigSummary</code> summarizes vector storage settings.</p> </li> </ul> <p>Get started Configuration API</p> <p>At-a-glance</p> <p>Use dashboard stats to detect storage drift (e.g., pgvector index growth) and plan compaction windows.</p> <p>Estimates</p> <p>Some values (e.g., GIN/GIST index allocations) may be estimated when exact attribution is not possible.</p> <p>Quotas</p> <p>Track total storage vs. quotas per environment to avoid surprise outages.</p> Model Fields <code>DashboardIndexStorageBreakdown</code> <code>chunks_bytes</code>, <code>embeddings_bytes</code>, <code>pgvector_index_bytes</code>, <code>bm25_index_bytes</code>, <code>neo4j_store_bytes</code>, <code>total_storage_bytes</code> <code>DashboardIndexStatusResponse</code> <code>lines</code>, <code>metadata</code>, <code>running</code>, <code>progress</code>, <code>current_file</code> <pre><code>flowchart LR\n    API[\"/index/stats\"] --&gt; UI[\"Dashboard Panels\"]</code></pre> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/index/stats?corpus_id=tribrid\").json())\n</code></pre> curl <pre><code>curl -sS \"http://localhost:8000/index/stats?corpus_id=tribrid\" | jq .\n</code></pre> TypeScript <pre><code>const stats = await (await fetch('/index/stats?corpus_id=tribrid')).json();\n</code></pre> Metadata <p><code>DashboardIndexStatusMetadata.embedding_config</code> aligns with the active embedding provider/model/dimensions.</p>"},{"location":"api_models_reranker/","title":"Reranker Training Models","text":"<ul> <li> <p> Runs</p> <p><code>RerankerTrainRun</code> captures hyperparameters and metrics.</p> </li> <li> <p> Streaming Metrics</p> <p><code>RerankerTrainMetricEvent</code> over SSE for progress.</p> </li> <li> <p> Diff</p> <p>Compare two runs with <code>RerankerTrainDiffResponse</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Primary Metric</p> <p>Let the profile choose <code>mrr@k</code> vs <code>ndcg@k</code> based on label structure; override only with clear reason.</p> <p>Local Logs</p> <p>Events stream and also persist to <code>metrics.jsonl</code> for later inspection.</p> <p>Compatibility</p> <p>Diff will mark runs incompatible if headline metric/k differ.</p> Model Purpose <code>RerankerTrainRun</code> Captures <code>primary_metric</code>, hyperparameters, and summary <code>RerankerTrainMetricEvent</code> Progress, metrics, and state events <code>RerankerTrainDiffResponse</code> Compatibility + delta comparisons <pre><code>flowchart LR\n    Start[\"Start Run\"] --&gt; Stream[\"Events\"]\n    Stream --&gt; Complete[\"Completed Run\"]\n    Complete --&gt; Diff[\"Compare Runs\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nprint(httpx.post(f\"{base}/reranker/train/start\", json={\"corpus_id\":\"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/train/start\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>await fetch('/reranker/train/start', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id:'tribrid' }) })\n</code></pre> Choosing batch/length <p>For constrained machines, reduce <code>tribrid_reranker_batch</code> and <code>tribrid_reranker_maxlen</code> to avoid OOM.</p>"},{"location":"architecture/","title":"Architecture","text":"<ul> <li> <p> Tri-Path Retrieval</p> <p>Vector, Sparse, and Graph retrievers run concurrently for maximum recall.</p> </li> <li> <p> Fusion Layer</p> <p>Weighted fusion or RRF unifies heterogeneous scores into one ranking.</p> </li> <li> <p> Optional Reranker</p> <p>Cross-encoder can refine the fused list by understanding local context.</p> </li> <li> <p> Pydantic-Orchestrated</p> <p>All engine parameters are Pydantic fields with constraints and defaults.</p> </li> <li> <p> FastAPI Surface</p> <p>Clean endpoints for indexing, retrieval, graph queries, and system health.</p> </li> <li> <p> Observability</p> <p>Readiness + Prometheus metrics + PostgreSQL exporter.</p> </li> </ul> <p>Get started Configuration API</p> <p>Concurrency</p> <p>TriBridRAG parallelizes retrievers with async I/O. Size DB connection pools to match concurrency and avoid I/O starvation.</p> <p>Failure Isolation</p> <p>Each retriever is wrapped so failures degrade that leg only. Fusion runs on the subset that succeeded; fused results keep provenance in <code>ChunkMatch.source</code>.</p> <p>Graph Availability</p> <p>If Neo4j is temporarily unavailable, retrieval continues with vector + sparse. Test fallback behavior in your deployment.</p>"},{"location":"architecture/#system-diagram","title":"System Diagram","text":"<pre><code>flowchart LR\n    subgraph API\n      FAPI[\"FastAPI\"]\n    end\n\n    FAPI --&gt; V[\"VectorRetriever\"]\n    FAPI --&gt; S[\"SparseRetriever\"]\n    FAPI --&gt; G[\"GraphRetriever\"]\n\n    V --&gt; FU[\"Fusion\"]\n    S --&gt; FU\n    G --&gt; FU\n\n    FU --&gt; RR[\"Reranker\\n(optional)\"]\n    RR --&gt; RES[\"Results\"]\n    FU --&gt; RES\n\n    V &lt;--&gt; PG[\"PostgreSQL\\n(pgvector+FTS)\"]\n    S &lt;--&gt; PG\n    G &lt;--&gt; NEO[\"Neo4j\\nGraph\"]</code></pre>"},{"location":"architecture/#layer-responsibilities","title":"Layer Responsibilities","text":"Layer Module Responsibilities Representative Config Vector <code>server/retrieval/vector.py</code> Dense search via pgvector <code>vector_search.enabled</code>, <code>vector_search.top_k</code>, <code>embedding.*</code> Sparse <code>server/retrieval/sparse.py</code> FTS/BM25 over chunks <code>sparse_search.enabled</code>, <code>sparse_search.top_k</code>, <code>indexing.bm25_*</code> Graph <code>server/retrieval/graph.py</code> Entity traversal, context expansion <code>graph_search.enabled</code>, <code>graph_search.max_hops</code>, <code>graph_storage.*</code> Fusion <code>server/retrieval/fusion.py</code> Merge lists and scores <code>fusion.method</code>, <code>fusion.rrf_k</code>, <code>fusion.*_weight</code> Reranker <code>server/retrieval/rerank.py</code> Cross-encoder scoring <code>reranking.reranker_mode</code>, <code>reranking.*</code>"},{"location":"architecture/#hot-path-annotated","title":"Hot Path (Annotated)","text":"Python <pre><code>from server.retrieval.fusion import TriBridFusion\nfrom server.retrieval.rerank import Reranker\n\nasync def search(query: str, corpus_id: str, cfg):  # (1)!\n    fusion = TriBridFusion(cfg)\n    fused = await fusion.search(corpus_id, query)   # (2)!\n    if cfg.reranking.reranker_mode != \"none\":\n        rr = Reranker(cfg)\n        fused = await rr.rerank(query, fused)       # (3)!\n    return fused                                    # (4)!\n</code></pre> <ol> <li>Query and corpus identifier; use <code>corpus_id</code> (alias of legacy <code>repo_id</code>)</li> <li>Fusion runs vector/sparse/graph concurrently and merges results</li> <li>Optional rerank, then return typed response</li> <li>Returns unified <code>SearchResponse</code> with provenance and latency</li> </ol> curl <pre><code>BASE=http://localhost:8000\n# (2)! Fusion (vector+sparse+graph)\ncurl -sS -X POST \"$BASE/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"connection pool size\",\n    \"top_k\": 10\n  }' | jq '.matches[0]'\n</code></pre> TypeScript <pre><code>import type { SearchRequest, SearchResponse } from \"./web/src/types/generated\";\n\nexport async function triSearch(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const resp = await fetch(\"/search\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(req),\n  });\n  return await resp.json(); // (4)!\n}\n</code></pre>"},{"location":"architecture/#fusion-choices","title":"Fusion Choices","text":"Method Formula Strengths Notes weighted <code>w_v*sv + w_s*ss + w_g*sg</code> Interpretable weight tuning Normalize scores if distributions differ rrf <code>sum 1/(k+rank_i)</code> Robust across heterogeneous scales Tune <code>rrf_k</code> in <code>fusion.rrf_k</code> <pre><code>flowchart TB\n    Q[\"Query\"] --&gt; V[\"Vector Top-K\"]\n    Q --&gt; S[\"Sparse Top-K\"]\n    Q --&gt; G[\"Graph Top-K\"]\n    V --&gt; FU[\"Fusion\"]\n    S --&gt; FU\n    G --&gt; FU\n    FU --&gt; OUT[\"Top-N Results\"]</code></pre> Implementation Notes <ul> <li>All configurable fields (weights, top_k, thresholds) live in <code>TriBridConfig</code>. Frontend sliders and toggles must map 1:1 to these fields via <code>generated.ts</code>.</li> <li>DB clients: <code>server/db/postgres.py</code> (pgvector + FTS) and <code>server/db/neo4j.py</code> (graph). Keep pools separate to avoid head-of-line blocking.</li> </ul>"},{"location":"architecture_extra/","title":"Request Lifecycle (Deep Dive)","text":"<ul> <li> <p> Routing</p> <p>Requests pass through validation, retrieval, fusion, and optional reranking.</p> </li> <li> <p> Latency Budget</p> <p>Each stage contributes; measure and tune.</p> </li> <li> <p> Tracing</p> <p>Optional tracing emits per-stage events for debugging.</p> </li> </ul> <p>Get started Configuration API</p> <p>Emit debug</p> <p>Enable <code>tracing</code> fields in config to capture per-stage events and timings for regressions.</p> <p>Validation First</p> <p>Pydantic validates shapes, ranges, and enums before any business logic runs. Use that feedback to correct clients quickly.</p> <p>Hydration Cost</p> <p><code>hydration_mode=eager</code> yields larger payloads and memory usage. Prefer <code>lazy</code> unless you specifically need full-context payloads immediately.</p> <pre><code>flowchart TB\n    IN[\"HTTP Request\"] --&gt; VAL[\"Pydantic Validation\"]\n    VAL --&gt; RET[\"Retrievers (async)\"]\n    RET --&gt; FUS[\"Fusion\"]\n    FUS --&gt; RER[\"Reranker (optional)\"]\n    RER --&gt; OUT[\"Response JSON\"]</code></pre> Python <pre><code># server/api/search.py pseudo-flow\nasync def search(req):  # (1)!\n    cid = req.corpus_id or req.repo_id  # (2)!\n    fused = await fusion.search(cid, req.query)  # (3)!\n    return await maybe_rerank(req.query, fused)  # (4)!\n</code></pre> <ol> <li>Pydantic ensures req shape matches <code>SearchRequest</code></li> <li>Alias resolution for corpus id</li> <li>Parallel legs + fusion</li> <li>Optional rerank before returning</li> </ol> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/search\" -H 'Content-Type: application/json' \\\n  -d '{\"corpus_id\":\"tribrid\",\"query\":\"pagination helper\",\"top_k\":5}' | jq .\n</code></pre> TypeScript <pre><code>// Client perspective: POST /search with SearchRequest\nimport type { SearchRequest, SearchResponse } from \"./web/src/types/generated\";\n\nasync function doSearch(): Promise&lt;SearchResponse&gt; {\n  const req: SearchRequest = { corpus_id: \"tribrid\", query: \"pagination\", top_k: 5 } as any;\n  const r = await fetch(\"/search\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) });\n  return await r.json();\n}\n</code></pre>"},{"location":"architecture_extra/#latency-budget-checklist","title":"Latency Budget Checklist","text":"<ul> <li> Keep <code>topk_dense</code> and <code>topk_sparse</code> reasonable (50\u2013100)</li> <li> Use <code>fusion.method=rrf</code> for robustness</li> <li> Set <code>reranking.tribrid_reranker_topn</code> to 40\u201360 for balance</li> <li> Avoid <code>graph_search.max_hops&gt;3</code> unless you truly need deep traversal</li> <li> Profile per-stage timings with tracing enabled</li> </ul> Minimal Trace Payload <p>Use <code>Trace</code> and <code>TraceEvent</code> models to capture <code>kind</code>, <code>ts</code>, and structured <code>data</code> per stage. The UI shows the latest via <code>/traces/latest</code>.</p>"},{"location":"configuration/","title":"Configuration","text":"<ul> <li> <p> Single Source of Truth</p> <p><code>server/models/tribrid_config_model.py</code> defines every tunable parameter with Pydantic <code>Field()</code> constraints.</p> </li> <li> <p> Generated Types</p> <p><code>uv run scripts/generate_types.py</code> produces <code>web/src/types/generated.ts</code>. No hand-written interfaces.</p> </li> <li> <p> Constraints Enforced</p> <p>Min/max ranges, enums, and defaults are validated at load time with precise error messages.</p> </li> </ul> <p>Get started Configuration API</p> <p>Workflow: Pydantic First</p> <p>1) Add/modify fields in Pydantic. 2) Regenerate TS types. 3) Wire stores/hooks/components using generated types. 4) Update backend logic to honor new fields.</p> <p>Corpus ID Migration</p> <p>Prefer <code>corpus_id</code>. Models accept <code>repo_id</code> via <code>AliasChoices</code> for backward compatibility, but serialize <code>corpus_id</code>.</p> <p>No Adapters</p> <p>If the frontend needs a different shape, change the Pydantic model and regenerate. Adapters introduce drift and are not allowed.</p>"},{"location":"configuration/#derivation-chain","title":"Derivation Chain","text":"<pre><code>flowchart TB\n    P[\"Pydantic\\ntribrid_config_model.py\"] --&gt; G[\"pydantic2ts\\n(generate_types.py)\"]\n    G --&gt; T[\"generated.ts\"]\n    T --&gt; S[\"Zustand Stores\"]\n    S --&gt; H[\"React Hooks\"]\n    H --&gt; C[\"Components\"]\n    P --&gt; A[\"FastAPI Schemas\"]\n    A --&gt; UI[\"API Responses\"]</code></pre>"},{"location":"configuration/#major-sections-selected-fields","title":"Major Sections (Selected Fields)","text":"Section Key Fields (examples) Why it matters retrieval <code>final_k</code>, <code>topk_dense</code>, <code>topk_sparse</code>, <code>fallback_confidence</code>, <code>conf_top1</code>, <code>conf_avg5</code>, <code>multi_query_m</code> Controls candidate sizes and retry/accept gates fusion <code>method</code>, <code>vector_weight</code>, <code>sparse_weight</code>, <code>graph_weight</code>, <code>rrf_k</code>, <code>normalize_scores</code> How legs combine into a single ranking vector_search <code>enabled</code>, <code>top_k</code>, <code>similarity_threshold</code> pgvector retrieval specifics sparse_search <code>enabled</code>, <code>top_k</code>, <code>bm25_k1</code>, <code>bm25_b</code> BM25/FTS scoring and candidate sizes graph_search <code>enabled</code>, <code>mode</code>, <code>max_hops</code>, <code>top_k</code>, <code>chunk_neighbor_window</code>, <code>chunk_entity_expansion_*</code> Neo4j traversal behavior embedding <code>embedding_type</code>, <code>embedding_model</code>, <code>embedding_dim</code>, <code>embedding_batch_size</code> Embedding provider + dimensions chunking <code>chunking_strategy</code>, <code>chunk_size</code>, <code>chunk_overlap</code>, <code>max_chunk_tokens</code>, <code>preserve_imports</code> Index quality and performance reranking <code>reranker_mode</code>, <code>reranker_*</code>, <code>tribrid_reranker_*</code> Cross-encoder stage tuning graph_storage <code>neo4j_*</code>, <code>neo4j_database_mode</code> Graph connectivity and isolation chat.recall_gate <code>enabled</code>, <code>default_intensity</code>, <code>skip_*</code>, <code>*top_k</code>, <code>*recency_weight</code> Smart memory gating"},{"location":"configuration/#fusion-configuration","title":"Fusion Configuration","text":"Field Type Constraints Description <code>fusion.method</code> Literal[\"rrf\",\"weighted\"] required Fusion algorithm <code>fusion.vector_weight</code> float 0.0\u20131.0 Weight for vector scores (weighted mode) <code>fusion.sparse_weight</code> float 0.0\u20131.0 Weight for sparse scores (weighted mode) <code>fusion.graph_weight</code> float 0.0\u20131.0 Weight for graph scores (weighted mode) <code>fusion.rrf_k</code> int 1\u2013200 RRF smoothing constant <code>fusion.normalize_scores</code> bool \u2014 Normalize inputs before weighted fusion <p>Weights Must Sum</p> <p>Weighted mode normalizes tri-brid weights to approximately 1.0. If total \u2264 0, safe defaults are applied.</p>"},{"location":"configuration/#graph-retrieval-configuration","title":"Graph Retrieval Configuration","text":"Field Type Constraints Description <code>graph_search.enabled</code> bool \u2014 Enable Neo4j traversal in retrieval <code>graph_search.mode</code> Literal[\"chunk\",\"entity\"] \u2014 Chunk-graph with vector seeds vs legacy entity graph <code>graph_search.max_hops</code> int 1\u20135 Traversal depth from seeds <code>graph_search.top_k</code> int 5\u2013100 Number of graph hits before fusion <code>graph_search.chunk_neighbor_window</code> int 0\u201310 Include neighboring chunks as context (chunk mode) <code>graph_search.chunk_entity_expansion_enabled</code> bool \u2014 Expand via entities linked to chunks <code>graph_search.chunk_entity_expansion_weight</code> float 0.0\u20131.0 Blending of expansion vs seed"},{"location":"configuration/#retrieval-and-confidence-gates","title":"Retrieval and Confidence Gates","text":"Field Default Description <code>retrieval.final_k</code> 10 Final top-k after fusion/rerank <code>retrieval.topk_dense</code> 75 Vector candidates (pgvector) <code>retrieval.topk_sparse</code> 75 BM25 candidates <code>retrieval.conf_top1</code> 0.62 Early accept top-1 threshold <code>retrieval.conf_avg5</code> 0.55 Group quality threshold (top-5) <code>retrieval.conf_any</code> 0.55 Safety net minimum"},{"location":"configuration/#chat-recall-gate-memory","title":"Chat Recall Gate (Memory)","text":"Field Default Meaning <code>chat.recall_gate.enabled</code> true Turn smart Recall gating on/off <code>chat.recall_gate.default_intensity</code> standard Fallback when no strong signal <code>chat.recall_gate.skip_greetings</code> true Skip trivial conversational glue <code>chat.recall_gate.light_top_k</code> 3 Light mode snippets <code>chat.recall_gate.standard_top_k</code> 5 Standard mode snippets <code>chat.recall_gate.deep_top_k</code> 10 Deep mode snippets <code>chat.recall_gate.standard_recency_weight</code> 0.3 Recent &gt; old balance <code>chat.recall_gate.deep_recency_weight</code> 0.5 Stronger recency in deep mode"},{"location":"configuration/#read-and-update-config-via-api-annotated","title":"Read and Update Config via API (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\n# Read full config (1)!\ncfg = httpx.get(f\"{base}/config\").json()\n\n# Patch a section (fusion) (2)!\npatch = {\"method\": \"weighted\", \"vector_weight\": 0.5, \"sparse_weight\": 0.3, \"graph_weight\": 0.2}\nhttpx.patch(f\"{base}/config/fusion\", json=patch).raise_for_status()\n\n# Reset to defaults (3)!\nhttpx.post(f\"{base}/config/reset\").raise_for_status()\n</code></pre> <ol> <li>Fetch authoritative nested config</li> <li>Sectional PATCH is validated by Pydantic</li> <li>Reset restores model defaults</li> </ol> curl <pre><code>BASE=http://localhost:8000\n\n# Read (1)!\ncurl -sS \"$BASE/config\" | jq .\n\n# Patch fusion (2)!\ncurl -sS -X PATCH \"$BASE/config/fusion\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"method\":\"weighted\",\"vector_weight\":0.5,\"sparse_weight\":0.3,\"graph_weight\":0.2}' | jq .\n\n# Reset (3)!\ncurl -sS -X POST \"$BASE/config/reset\" | jq .\n</code></pre> <ol> <li>Retrieve full config</li> <li>Update only the <code>fusion</code> section</li> <li>Restore defaults (useful during experiments)</li> </ol> TypeScript <pre><code>import type { TriBridConfig } from \"./web/src/types/generated\";\n\nasync function loadConfig(): Promise&lt;TriBridConfig&gt; {\n  const r = await fetch(\"/config\");\n  return await r.json(); // (1)!\n}\n\nasync function patchFusion() {\n  await fetch(\"/config/fusion\", {\n    method: \"PATCH\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({ method: \"weighted\", vector_weight: 0.5, sparse_weight: 0.3, graph_weight: 0.2 }),\n  }); // (2)!\n}\n</code></pre> <ol> <li>Typed fetch of config</li> <li>Typed partial update for fusion settings</li> </ol>"},{"location":"configuration/#safe-defaults-and-tradeoffs","title":"Safe Defaults and Tradeoffs","text":"<ul> <li>Vector vs Sparse vs Graph weights</li> <li>If unsure, do this: <code>fusion.method = \"rrf\"</code>, <code>fusion.rrf_k = 60</code>. RRF is robust across modalities.</li> <li>Candidate sizes</li> <li>Start with <code>topk_dense=75</code>, <code>topk_sparse=75</code>, <code>graph_search.top_k=30</code>. Increase for recall-heavy workloads.</li> <li>Confidence gates</li> <li>Start with <code>conf_top1=0.62</code>, <code>conf_avg5=0.55</code>. Raise to increase precision (fewer answers), lower for more answers.</li> </ul> Where values come from <p>All defaults live in Pydantic <code>Field(default=...)</code> initializers. UI sliders and inputs read min/max from the same model. The server enforces the same constraints.</p>"},{"location":"database/","title":"Storage: PostgreSQL (pgvector + FTS) and Neo4j","text":"<ul> <li> <p> PostgreSQL</p> <p>Single source for chunks, embeddings, and FTS.</p> </li> <li> <p> pgvector</p> <p>High-dimensional vector similarity for dense retrieval.</p> </li> <li> <p> Neo4j</p> <p>Entity/relationship graph and optional vector index on chunks.</p> </li> </ul> <p>Get started Configuration API</p> <p>One Postgres, Many Corpora</p> <p>Partition by <code>repo_id</code>/<code>corpus_id</code> in schema to keep corpus isolation at the data layer.</p> <p>TSConfig</p> <p><code>indexing.postgres_ts_config</code> resolves the text search config (<code>simple</code> or a stemmer language) based on tokenizer settings.</p> <p>Neo4j Isolation</p> <p><code>neo4j_database_mode=per_corpus</code> avoids expensive cross-corpus filters but requires Enterprise Edition.</p>"},{"location":"database/#postgresql-client-responsibilities","title":"PostgreSQL Client Responsibilities","text":"<ul> <li>Upsert chunk rows with metadata and content</li> <li>Upsert embeddings for pgvector similarity</li> <li>Maintain FTS (tsvector) index</li> <li>Execute vector and sparse searches with corpus scope</li> </ul>"},{"location":"database/#neo4j-client-responsibilities","title":"Neo4j Client Responsibilities","text":"<ul> <li>Ensure database exists (per mode)</li> <li>Ensure vector index on Chunk nodes when enabled</li> <li>Upsert entities and relationships</li> <li>Expand from seed hits to related chunks</li> </ul> <pre><code>flowchart LR\n    CH[\"Chunks\"] --&gt; PG[\"PostgreSQL\"]\n    EMB[\"Embeddings\"] --&gt; PG\n    ENT[\"Entities\"] --&gt; NEO[\"Neo4j\"]\n    REL[\"Relationships\"] --&gt; NEO</code></pre>"},{"location":"database/#configuration-hooks","title":"Configuration Hooks","text":"Section Field(s) Meaning indexing <code>postgres_url</code> DSN for Postgres graph_storage <code>neo4j_uri</code>, <code>neo4j_user</code>, <code>neo4j_password</code> Neo4j connectivity graph_storage <code>neo4j_database_mode</code>, <code>neo4j_database_prefix</code> DB isolation strategy graph_indexing <code>store_chunk_embeddings</code>, <code>chunk_vector_index_name</code> Neo4j vector search on chunks Python <pre><code># Resolve Neo4j database name for a corpus (1)!\nfrom server.models.tribrid_config_model import GraphStorageConfig\nprint(GraphStorageConfig().resolve_database(\"dev_corpus\"))\n</code></pre> curl <pre><code># Connectivity checks are via readiness\ncurl -sS http://localhost:8000/ready | jq .\n</code></pre> TypeScript <pre><code>// Client: no direct DB use \u2014 rely on API readiness\n</code></pre> <ol> <li>Uses prefix + sanitized corpus id in per_corpus mode</li> </ol> Vector Similarity <p>Set <code>graph_indexing.vector_similarity_function</code> to <code>cosine</code> or <code>euclidean</code> based on your embedding model norms.</p>"},{"location":"deployment/","title":"Deployment","text":"<ul> <li> <p> Docker-First</p> <p>Compose stack for Postgres, Neo4j, exporter, and API.</p> </li> <li> <p> Configurable</p> <p>All behavior via Pydantic config and environment variables.</p> </li> <li> <p> Portable</p> <p>Works on local dev, CI, or container platforms.</p> </li> </ul> <p>Get started Configuration API</p> <p>Persistent Volumes</p> <p>Keep DB data outside the repo. Default bind-mount path is <code>../tribrid-rag-db/</code>. Override with <code>TRIBRID_DB_DIR</code>.</p> <p>Environment Template</p> <p>Copy the provided environment configuration to <code>.env</code>, fill in DB credentials and API keys, and export it into your shell for local runs.</p> <p>Production Secrets</p> <p>Use a secret manager for API keys and DB credentials in production. Do not rely on <code>.env</code> files in containerized environments.</p>"},{"location":"deployment/#services-and-ports","title":"Services and Ports","text":"Service Port Purpose API (uvicorn) 8000 REST endpoints PostgreSQL 5432 Chunk + vector + FTS storage Neo4j Bolt 7687 Graph driver Neo4j Browser 7474 Admin UI Prometheus 9090 Metrics Grafana 3001 Dashboards <pre><code>flowchart LR\n    Dev[\"Developer\"] --&gt; Compose[\"Docker Compose\"]\n    Compose --&gt; API[\"API\"]\n    Compose --&gt; Postgres[\"Postgres\"]\n    Compose --&gt; Neo4j[\"Neo4j\"]\n    Postgres --&gt; Exporter[\"Postgres Exporter\"]</code></pre>"},{"location":"deployment/#bring-up-tasks","title":"Bring-Up Tasks","text":"<ul> <li> Create <code>.env</code> with DB creds and API keys</li> <li> <code>docker compose up -d</code></li> <li> <code>uv run scripts/generate_types.py</code></li> <li> Start API service</li> </ul> Python <pre><code>import subprocess, os\n\n# Generate types from Pydantic (1)!\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1) Pydantic \u2192 TS types\n\n# Start FastAPI via uvicorn (2)!\nos.system(\"uvicorn server.main:app --reload --port 8000\")  # (2) Dev server\n</code></pre> curl <pre><code># After containers are up:\ncurl -sS http://localhost:8000/ready | jq .  # readiness check (3)!\n</code></pre> TypeScript <pre><code>// Frontend dev typically proxies to :8000\nconsole.log(\"Ensure generated.ts exists and API ready at /ready\");\n</code></pre> <pre><code>flowchart TB\n    Env[\".env\"] --&gt; Compose\n    P[\"Pydantic\"] --&gt; Types[\"generated.ts\"]\n    Types --&gt; UI[\"Frontend\"]\n    Compose --&gt; API[\"API\"]\n    API --&gt; READY[\"/ready\"]</code></pre> Container Logs <p>Use <code>/docker/{container}/logs</code> to fetch current log lines via API for basic troubleshooting when UI access is limited.</p>"},{"location":"dev_workflow/","title":"Developer Workflow (Pydantic \u2192 TypeScript \u2192 UI)","text":"<ul> <li> <p> Hard Rules</p> <p>Pydantic first. No adapters. No hand-written API types.</p> </li> <li> <p> Generated Types</p> <p><code>uv run scripts/generate_types.py</code> produces <code>generated.ts</code>.</p> </li> <li> <p> Clean Flow</p> <p>models \u2192 stores \u2192 hooks \u2192 components.</p> </li> </ul> <p>Get started Configuration API</p> <p>Single Source of Truth</p> <p>All configurable parameters and data shapes live in <code>server/models/tribrid_config_model.py</code>.</p> <p>Validate Sync</p> <p>Run <code>uv run scripts/validate_types.py</code> to confirm generated types match Pydantic.</p> <p>Banned Patterns</p> <ul> <li>Hand-written interfaces for API payloads</li> <li><code>*Adapter</code>, <code>*Transformer</code>, <code>*Mapper</code> classes to reshape payloads</li> </ul>"},{"location":"dev_workflow/#derivation-chain","title":"Derivation Chain","text":"<pre><code>flowchart TB\n    P[\"Pydantic\"] --&gt; G[\"generate_types.py\"]\n    G --&gt; T[\"web/src/types/generated.ts\"]\n    T --&gt; S[\"Zustand Stores\"]\n    S --&gt; H[\"React Hooks\"]\n    H --&gt; C[\"Components\"]</code></pre>"},{"location":"dev_workflow/#commands","title":"Commands","text":"<ul> <li> <code>uv run scripts/generate_types.py</code> (after ANY Pydantic change)</li> <li> <code>uv run scripts/validate_types.py</code> (CI/verify before commit)</li> <li> <code>uv run scripts/check_banned.py</code> (guardrails)</li> </ul> Python <pre><code>import subprocess\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)!\nsubprocess.check_call([\"uv\", \"run\", \"scripts/validate_types.py\"])  # (2)!\n</code></pre> curl <pre><code># No curl for local codegen; use uv-run commands\n</code></pre> TypeScript <pre><code>// Use generated types only\nimport type { SearchRequest } from \"../types/generated\"; // (3)!\n</code></pre> <ol> <li>Generate TS types from Pydantic</li> <li>Validate that TS matches server models</li> <li>Client code imports generated types</li> </ol>"},{"location":"dev_workflow/#directory-purposes","title":"Directory Purposes","text":"Path Purpose <code>server/models/tribrid_config_model.py</code> Pydantic models \u2014 THE LAW <code>web/src/types/generated.ts</code> Auto-generated API types <code>web/src/stores/*.ts</code> Zustand stores using generated types <code>web/src/hooks/*.ts</code> React hooks wrapping stores <code>web/src/components/**/*.tsx</code> Components consuming hooks Ralph Loop <p>Use the recommended loop to implement TODOs end-to-end with verification: validators, tests, and Stop hook enforcement.</p>"},{"location":"eval_guide/","title":"Evaluation Guide","text":"<ul> <li> <p> Goals</p> <p>Detect regressions, compare configs, and track latency.</p> </li> <li> <p> Datasets</p> <p>Use <code>EvalDatasetItem</code> with expected file paths.</p> </li> <li> <p> Metrics</p> <p>MRR, Recall@K, NDCG@10, p50/p95 latency.</p> </li> </ul> <p>Get started Configuration API</p> <p>Match prod</p> <p>Align <code>eval_final_k</code> and <code>eval_multi</code> with production to avoid misleading results.</p> <p>Compare Runs</p> <p>Use <code>/reranker/train/diff</code> or evaluation comparison endpoints to see deltas and compatibility.</p> <p>Small samples</p> <p>Use small samples for iteration, but run full suites before shipping changes.</p>"},{"location":"eval_guide/#typical-flow","title":"Typical Flow","text":"<pre><code>flowchart TB\n    PREP[\"Prepare eval dataset\"] --&gt; RUN[\"Run evaluation\"]\n    RUN --&gt; ANALYZE[\"Analyze metrics\"]\n    ANALYZE --&gt; TUNE[\"Tune config\"]\n    TUNE --&gt; RUN</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n# Trigger evaluation (1)!\nprint(httpx.post(f\"{base}/reranker/evaluate\", json={\"corpus_id\":\"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/evaluate\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>// Load eval results and render charts\nconst result = await (await fetch('/reranker/evaluate', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id: 'tribrid' }) })).json();\n</code></pre> Knob Where Default <code>evaluation.eval_multi_m</code> <code>TriBridConfig.evaluation</code> 10 <code>retrieval.eval_final_k</code> <code>TriBridConfig.retrieval</code> 5 <code>retrieval.eval_multi</code> <code>TriBridConfig.retrieval</code> 1 (on) Prompt analysis <p>Use <code>system_prompts.eval_analysis</code> to generate skeptical post-hoc analysis comparing two runs.</p>"},{"location":"frontend/","title":"Frontend Integration and Types","text":"<ul> <li> <p> Generated Types Only</p> <p><code>web/src/types/generated.ts</code> is the only source for API interfaces.</p> </li> <li> <p> Zustand Stores</p> <p>Stores consume generated types; hooks expose typed accessors.</p> </li> <li> <p> Components</p> <p>Props derive from hooks; no custom interfaces without Pydantic ancestry.</p> </li> </ul> <p>Get started Configuration API</p> <p>Generate Early</p> <p>Run <code>uv run scripts/generate_types.py</code> before starting the frontend. Hot reload relies on correct types.</p> <p>Traceability</p> <p>Every UI element (slider, toggle, input) must map to a Pydantic field. Tooltips come from <code>data/glossary.json</code>.</p> <p>No Hand-Written Interfaces</p> <p>Interfaces like <code>interface SearchResponse { ... }</code> are forbidden. Import from <code>generated.ts</code>.</p>"},{"location":"frontend/#store-and-hook-structure","title":"Store and Hook Structure","text":"File Purpose <code>web/src/stores/useConfigStore.ts</code> Holds <code>TriBridConfig</code> and patch helpers <code>web/src/hooks/useConfig.ts</code> Read/update config <code>web/src/hooks/useFusion.ts</code> Fusion-related derived state <code>web/src/hooks/useReranker.ts</code> Reranker configuration and status <pre><code>flowchart TB\n    G[generated.ts] --&gt; S[stores]\n    S --&gt; H[hooks]\n    H --&gt; C[components]</code></pre>"},{"location":"frontend/#example-usage","title":"Example Usage","text":"PythoncurlTypeScript <pre><code># Backend reference: see dev/pydantic.md for generation step (1)\n</code></pre> <pre><code># Frontend consumes API; see api.md for routes (2)\n</code></pre> <pre><code>import { TriBridConfig, SearchResponse } from '../web/src/types/generated';\n\nfunction useConfig() {\n  // typed fetch\n  const [cfg, setCfg] = React.useState&lt;TriBridConfig | null&gt;(null);\n  React.useEffect(() =&gt; { fetch('/config').then(r =&gt; r.json()).then(setCfg); }, []); // (3)\n  return cfg;\n}\n</code></pre> <ol> <li>Types generation step is mandatory</li> <li>API is the contract; no local mocks of shapes</li> <li>Fetch returns the Pydantic-driven shape of config</li> </ol> <p>Tooltip Integration</p> <p><code>data/glossary.json</code> drives hover help via <code>TooltipIcon</code> in the UI. Keep term keys stable.</p> <ul> <li> Use generated types across stores, hooks, and components</li> <li> Remove any legacy custom interfaces</li> <li> Validate prop chains map back to Pydantic fields</li> </ul> <pre><code>flowchart LR\n    Glossary[data/glossary.json] --&gt; Tooltip[TooltipIcon]\n    Tooltip --&gt; UI</code></pre> Component Inventory <ul> <li><code>DockerStatusCard.tsx</code>, <code>HealthStatusCard.tsx</code> show system state</li> <li><code>RepoSelector.tsx</code> binds UI to <code>corpus_id</code></li> <li><code>RAGTab.tsx</code>, <code>GrafanaTab.tsx</code>, <code>AdminTab.tsx</code> orchestrate panels using typed hooks</li> </ul>"},{"location":"glossary/","title":"Glossary","text":"<ul> <li> <p> Centralized Terms</p> <p><code>data/glossary.json</code> drives all tooltips in the UI.</p> </li> <li> <p> Cross-References</p> <p>Each term lists related entries to encourage discovery.</p> </li> <li> <p> Editable</p> <p>Update the JSON file, not components, to change tooltip content.</p> </li> </ul> <p>Get started Configuration API</p> <p>Source of Truth</p> <p><code>data/glossary.json</code> is parsed by the UI. Keep <code>key</code> values stable for long-lived tooltips.</p> <p>Representative Entries</p> <ul> <li>PostgreSQL pgvector URL (<code>POSTGRES_URL</code>)</li> <li>Neo4j Connection URI (<code>NEO4J_URI</code>)</li> <li>Final Top\u2011K (<code>FINAL_K</code>)</li> </ul> <p>Typos</p> <p>Misspelled keys break existing tooltips silently. Validate JSON in CI.</p> Term Key Definition PostgreSQL pgvector URL POSTGRES_URL Connection URL for pgvector-enabled Postgres Neo4j Connection URI NEO4J_URI Connection URI for Neo4j graph Final Top\u2011K FINAL_K Final result size after fusion/reranking <pre><code>flowchart LR\n    glossary[\"glossary.json\"] --&gt; Tooltip[\"TooltipIcon\"]\n    Tooltip --&gt; UI[\"UI\"]</code></pre> Python <pre><code># Backend does not read glossary; UI loads JSON directly.\n</code></pre> curl <pre><code># Validate glossary.json structure\neq 0 $(jq . data/glossary.json &gt;/dev/null 2&gt;&amp;1; echo $?) &amp;&amp; echo OK || echo FAIL\n</code></pre> TypeScript <pre><code>// UI side: load glossary.json and feed into TooltipIcon\n</code></pre> Categories <p>The JSON includes <code>category</code> tags to group terms (retrieval, chunking, infrastructure, generation, etc.).</p>"},{"location":"indexing/","title":"Indexing Pipeline","text":"<ul> <li> <p> Loader</p> <p>Git-aware discovery honoring <code>.gitignore</code> with root-relative patterns.</p> </li> <li> <p> Chunker</p> <p>Fixed, AST-aware, or hybrid chunk strategies with line attribution.</p> </li> <li> <p> Embedder</p> <p>Deterministic local or provider-backed embeddings configured in Pydantic.</p> </li> <li> <p> Chunk Summaries</p> <p>Optional LLM-generated <code>chunk_summaries</code> to improve sparse search.</p> </li> <li> <p> Graph Builder</p> <p>Entity/relationship extraction and Neo4j persistence.</p> </li> </ul> <p>Get started Configuration API</p> <p>Idempotent Indexing</p> <p>Use <code>force_reindex=false</code> for incremental updates. The indexer skips unchanged files using mtime/hash checks where available.</p> <p>Storage Layout</p> <p>Chunks, embeddings, and FTS are in PostgreSQL. Graph artifacts are in Neo4j. Sizes are summarized via dashboard endpoints.</p> <p>Large Corpora</p> <p>Configure Neo4j heap and page cache via environment for multi-million edge graphs. Monitor Postgres disk growth for pgvector indexes.</p>"},{"location":"indexing/#pipeline-flow","title":"Pipeline Flow","text":"<pre><code>flowchart LR\n    L[\"FileLoader\"] --&gt; C[\"Chunker\"]\n    C --&gt; E[\"Embedder\"]\n    E --&gt; P[\"PostgreSQL\"]\n    C --&gt; S[\"ChunkSummarizer\"]\n    S --&gt; P\n    C --&gt; GB[\"GraphBuilder\"]\n    GB --&gt; N[\"Neo4j\"]</code></pre>"},{"location":"indexing/#chunking-embedding-controls-selected","title":"Chunking &amp; Embedding Controls (Selected)","text":"Section Field Default Notes chunking <code>chunk_size</code> 1000 Target chars per chunk chunking <code>chunk_overlap</code> 200 Overlap for continuity chunking <code>chunking_strategy</code> ast <code>ast \\| greedy \\| hybrid</code> chunking <code>max_chunk_tokens</code> 8000 Split recursively if larger embedding <code>embedding_type</code> openai Provider selector embedding <code>embedding_model</code> text-embedding-3-large Model id embedding <code>embedding_dim</code> 3072 Must match model outputs indexing <code>bm25_tokenizer</code> stemmer Tokenizer for FTS"},{"location":"indexing/#start-indexing-via-api-annotated","title":"Start Indexing via API (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\nreq = {\n    \"corpus_id\": \"tribrid\",   # (1)!\n    \"repo_path\": \"/work/src/tribrid\",\n    \"force_reindex\": False\n}\nhttpx.post(f\"{base}/index\", json=req).raise_for_status()  # (2)!\n\nstatus = httpx.get(f\"{base}/index/status\", params={\"corpus_id\": \"tribrid\"}).json()\nprint(status[\"status\"], status.get(\"progress\"))          # (3)!\n</code></pre> <ol> <li>Create/refresh a specific corpus</li> <li>Start indexing</li> <li>Poll progress</li> </ol> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/index\" -H 'Content-Type: application/json' -d '{\n  \"corpus_id\":\"tribrid\",\"repo_path\":\"/work/src/tribrid\",\"force_reindex\":false\n}'\ncurl -sS \"$BASE/index/status?corpus_id=tribrid\" | jq .\n</code></pre> TypeScript <pre><code>import type { IndexRequest, IndexStatus } from \"./web/src/types/generated\";\n\nasync function reindex(path: string) {\n  const req: IndexRequest = { corpus_id: \"tribrid\", repo_path: path, force_reindex: false } as any;\n  await fetch(\"/index\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) }); // (2)!\n  const status: IndexStatus = await (await fetch(\"/index/status?corpus_id=tribrid\")).json(); // (3)!\n  console.log(status.status, status.progress);\n}\n</code></pre>"},{"location":"indexing/#graph-indexing-neo4j","title":"Graph Indexing (Neo4j)","text":"Field Default Meaning <code>graph_indexing.enabled</code> true Enable graph building during indexing <code>graph_indexing.build_lexical_graph</code> true Add Chunk/NEXT_CHUNK structure <code>graph_indexing.store_chunk_embeddings</code> true Store chunk vectors for Neo4j vector search <code>graph_indexing.semantic_kg_enabled</code> false Extract concept relations (heuristic or LLM) Failure Modes <ul> <li>File decoding errors: logged and skipped.</li> <li>Embedding timeouts: retried with backoff; chunk remains un-embedded if persistent.</li> <li>Graph build failures: retrieval continues with vector/sparse; flagged in logs.</li> </ul>"},{"location":"mcp/","title":"MCP (Model Context Protocol)","text":"<ul> <li> <p> Inbound HTTP</p> <p>Optional embedded MCP HTTP transport, stateless by default.</p> </li> <li> <p> Safety</p> <p>DNS rebinding protection, host/origin allowlists, optional API key.</p> </li> <li> <p> Defaults</p> <p><code>default_top_k</code>, <code>default_mode</code> for tri-brid retrieval.</p> </li> </ul> <p>Get started Configuration API</p> <p>Keep Stateless</p> <p><code>mcp.stateless_http=true</code> is recommended; clients provide full context each call.</p> <p>Allowlists</p> <p>Use <code>mcp.allowed_hosts</code> and <code>mcp.allowed_origins</code> with wildcards like <code>*:*</code> only in development.</p> <p>Auth</p> <p>Set <code>mcp.require_api_key=true</code> and pass <code>Authorization: Bearer $MCP_API_KEY</code> in production.</p>"},{"location":"mcp/#configuration-selected","title":"Configuration (Selected)","text":"Field Default Meaning <code>mcp.enabled</code> true Enable embedded MCP HTTP server <code>mcp.mount_path</code> <code>/mcp</code> Path prefix <code>mcp.stateless_http</code> true Stateless handling per request <code>mcp.json_response</code> true Prefer JSON over text <code>mcp.enable_dns_rebinding_protection</code> true Prevent DNS rebinding <code>mcp.allowed_hosts</code> <code>localhost:*</code> Allowed Host header values <code>mcp.allowed_origins</code> <code>http://localhost:*</code> Allowed Origin values <code>mcp.require_api_key</code> false Enforce API key on requests <code>mcp.default_top_k</code> 20 Default top_k for search/answer tools <code>mcp.default_mode</code> <code>tribrid</code> Retrieval mode when not provided"},{"location":"mcp/#status-endpoint","title":"Status Endpoint","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/mcp/status\").json())\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/mcp/status | jq .\n</code></pre> TypeScript <pre><code>const status = await (await fetch('/mcp/status')).json();\n</code></pre> <pre><code>flowchart LR\n    Client[\"MCP Client\"] --&gt; HTTP[\"MCP HTTP\\n(mount /mcp)\"]\n    HTTP --&gt; RAG[\"Tri-brid Retrieval\"]</code></pre> Legacy stdio <p><code>python_stdio_available</code> indicates whether the stdio transport can be launched by clients (no daemon).</p>"},{"location":"models/","title":"Model Catalog (data/models.json)","text":"<ul> <li> <p> Cost-Aware</p> <p>Pricing per 1k tokens with provider and family classifications.</p> </li> <li> <p> LLM/Embedding/Reranker</p> <p>Centralized catalog for generation, embeddings, and rerank models.</p> </li> <li> <p> API-Served</p> <p>UI and backend fetch from <code>/models/...</code>. No local lists.</p> </li> </ul> <p>Get started Configuration API</p> <p>Single Source</p> <p><code>data/models.json</code> is the authoritative source for model availability, pricing, and context sizes. Update it to change selectable models.</p> <p>Components</p> <p>The <code>components</code> field indicates usage: <code>GEN</code> for generation, <code>EMB</code> for embeddings, <code>RERANK</code> for cross-encoders.</p> <p>Pricing Staleness</p> <p>Prices change over time. Keep <code>last_updated</code> current and reference sources in the file header.</p>"},{"location":"models/#api-endpoints","title":"API Endpoints","text":"Route Description <code>/models/by-type/{component_type}</code> Filter by <code>GEN</code>, <code>EMB</code>, or <code>RERANK</code> <code>/models/providers</code> List providers <code>/models/providers/{provider}</code> Models for a specific provider <pre><code>flowchart LR\n    Catalog[\"data/models.json\"] --&gt; API[\"/models\"]\n    API --&gt; UI[\"Model Pickers\"]\n    API --&gt; Server[\"Embedding/Reranker Selection\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\ngens = httpx.get(f\"{base}/models/by-type/GEN\").json()  # (1)!\nproviders = httpx.get(f\"{base}/models/providers\").json()  # (2)!\nopenai = httpx.get(f\"{base}/models/providers/openai\").json()  # (3)!\nprint(len(gens), providers, len(openai))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/models/by-type/GEN\" | jq '.[0]'\ncurl -sS \"$BASE/models/providers\" | jq .\ncurl -sS \"$BASE/models/providers/openai\" | jq '.[].model'\n</code></pre> TypeScript <pre><code>type ModelItem = { provider: string; family: string; model: string; components: string[] };\n\nasync function listGen(): Promise&lt;ModelItem[]&gt; {\n  return await (await fetch(\"/models/by-type/GEN\")).json();\n}\n</code></pre> UI Contract <p>All selectors in the UI must call these endpoints and use generated types for request/response where applicable.</p>"},{"location":"observability/","title":"Observability (Prometheus, Grafana, Loki)","text":"<ul> <li> <p> Metrics</p> <p><code>/metrics</code> endpoint + Postgres exporter.</p> </li> <li> <p> Dashboards</p> <p>Grafana embedded with default UID <code>tribrid-overview</code>.</p> </li> <li> <p> Logs</p> <p>Loki + Promtail for container logs and app logs.</p> </li> </ul> <p>Get started Configuration API</p> <p>Sampling</p> <p>Adjust <code>tracing.trace_sampling_rate</code> to manage cost and overhead. Use 1.0 in dev and 0.1\u20130.2 in production.</p> <p>Anonymous Grafana</p> <p>The compose stack enables anonymous access for embeds. Harden in production.</p> <p>Timestamps</p> <p><code>DOCKER_LOGS_TIMESTAMPS=1</code> helps correlate events across services.</p>"},{"location":"observability/#components","title":"Components","text":"Service Port Notes Prometheus 9090 Scrapes <code>/metrics</code> and exporter Grafana 3001 Embedded dashboard in UI Loki 3100 Log aggregation Promtail \u2014 Ships container/host logs <pre><code>flowchart LR\n    App[\"TriBridRAG\"] --&gt; METRICS[\"/metrics\"]\n    METRICS --&gt; PROM[\"Prometheus\"]\n    PROM --&gt; GRAF[\"Grafana\"]\n    LOGS[\"Docker Logs\"] --&gt; PROMTAIL[\"Promtail\"]\n    PROMTAIL --&gt; LOKI[\"Loki\"]\n    LOKI --&gt; GRAF</code></pre> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/metrics\").text.splitlines()[:5])\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>const m = await (await fetch('/metrics')).text();\nconsole.log(m.split('\\n').slice(0,5));\n</code></pre> Dashboards <p>Mount your own Grafana provisioning under <code>infra/grafana/provisioning</code> to add/override dashboards and datasources.</p>"},{"location":"operations/","title":"Operations, Health, and Metrics","text":"<ul> <li> <p> Health</p> <p><code>/health</code> and <code>/ready</code> for liveness and readiness.</p> </li> <li> <p> Metrics</p> <p><code>/metrics</code> for Prometheus. Plus Postgres exporter for DB metrics.</p> </li> <li> <p> Runtime Control</p> <p>Inspect and restart containers via Docker endpoints.</p> </li> </ul> <p>Get started Configuration API</p> <p>Readiness Gate</p> <p>Gate traffic on <code>/ready</code>. It verifies DB connectivity before admitting load.</p> <p>Container Logs</p> <p>Use <code>/docker/{container}/logs</code> for ad-hoc log pulls, or rely on Loki for aggregation.</p> <p>Restarts</p> <p>Prefer coordinated restarts via the API (or compose) to avoid dropping in-flight requests.</p>"},{"location":"operations/#endpoints","title":"Endpoints","text":"Endpoint Description <code>/docker/status</code> Container status <code>/docker/containers</code> List TriBrid-managed containers <code>/docker/containers/all</code> List all containers <code>/docker/{container}/restart</code> Restart container <code>/docker/{container}/logs</code> Tail logs <pre><code>flowchart LR\n    Scrape[\"Prometheus\"] --&gt; API_METRICS[\"/metrics\"]\n    API_METRICS --&gt; APP[\"TriBridRAG\"]\n    APP --&gt; PG[\"Postgres\"]\n    APP --&gt; NEO[\"Neo4j\"]\n    Scrape --&gt; PExp[\"postgres-exporter\"]</code></pre> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/docker/status\").json())\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/docker/status | jq .\n</code></pre> TypeScript <pre><code>await fetch('/docker/status').then(r =&gt; r.json())\n</code></pre> <ul> <li> Gate traffic with readiness</li> <li> Alert on 5xx and slow search</li> <li> Monitor DB connection pool saturation and timeouts</li> <li> Define SLOs for p95 latency per endpoint</li> </ul> Grafana <p>Default dashboard UID <code>tribrid-overview</code> is embedded in the UI. Customize datasource/dashboards via mounted provisioning files.</p>"},{"location":"reranking/","title":"Reranking (Cloud, Local, Learning)","text":"<ul> <li> <p> Reorder Candidates</p> <p>Cross-encoders refine fused candidates for precision.</p> </li> <li> <p> Local or Cloud</p> <p>Use open-source cross-encoders locally or Cohere/Voyage/Jina via API.</p> </li> <li> <p> Learning Reranker</p> <p>Mine triplets and fine-tune a task-specific reranker.</p> </li> </ul> <p>Get started Configuration API</p> <p>Balanced TopN</p> <p>Use <code>tribrid_reranker_topn=40..60</code> for quality vs latency.</p> <p>Cloud Limits</p> <p>Respect provider token limits and per-request pricing; tune <code>reranker_cloud_top_n</code> accordingly.</p> <p>Trust Remote Code</p> <p><code>transformers_trust_remote_code=1</code> executes model repo code. Only enable for trusted models.</p>"},{"location":"reranking/#modes-and-fields","title":"Modes and Fields","text":"Field Meaning <code>reranking.reranker_mode</code> <code>none</code> | <code>local</code> | <code>learning</code> | <code>cloud</code> <code>reranking.reranker_local_model</code> HF model or local path <code>reranking.reranker_cloud_provider</code> <code>cohere</code> | <code>voyage</code> | <code>jina</code> <code>reranking.reranker_cloud_model</code> Provider-scoped model id <code>reranking.tribrid_reranker_topn</code> Candidates to rerank <code>reranking.reranker_timeout</code> Timeout for API calls"},{"location":"reranking/#example-enable-weighted-fusion-local-rerank","title":"Example: Enable Weighted Fusion + Local Rerank","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nhttpx.patch(f\"{base}/config/fusion\", json={\"method\":\"weighted\",\"vector_weight\":0.4,\"sparse_weight\":0.3,\"graph_weight\":0.3}).raise_for_status()\nhttpx.patch(f\"{base}/config/reranking\", json={\"reranker_mode\":\"local\",\"reranker_local_model\":\"cross-encoder/ms-marco-MiniLM-L-12-v2\",\"tribrid_reranker_topn\":50}).raise_for_status()\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X PATCH \"$BASE/config/fusion\" -H 'Content-Type: application/json' -d '{\"method\":\"weighted\",\"vector_weight\":0.4,\"sparse_weight\":0.3,\"graph_weight\":0.3}' | jq .\ncurl -sS -X PATCH \"$BASE/config/reranking\" -H 'Content-Type: application/json' -d '{\"reranker_mode\":\"local\",\"reranker_local_model\":\"cross-encoder/ms-marco-MiniLM-L-12-v2\",\"tribrid_reranker_topn\":50}' | jq .\n</code></pre> TypeScript <pre><code>await fetch('/config/fusion', { method:'PATCH', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ method:'weighted', vector_weight:0.4, sparse_weight:0.3, graph_weight:0.3 }) });\nawait fetch('/config/reranking', { method:'PATCH', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ reranker_mode:'local', reranker_local_model:'cross-encoder/ms-marco-MiniLM-L-12-v2', tribrid_reranker_topn:50 }) });\n</code></pre> <pre><code>flowchart LR\n    FUSED[\"Fused List\"] --&gt; RR[\"Cross-Encoder\\nRerank\"]\n    RR --&gt; FINAL[\"Final Top-K\"]</code></pre> Learning Reranker <p>Use <code>/reranker/mine</code>, <code>/reranker/train/start</code>, <code>/reranker/train/run/stream</code> to build a corpus-specific reranker. See API docs for streaming metrics and diffing runs.</p>"},{"location":"retrieval_extra/","title":"Query Expansion and Confidence Thresholds","text":"<ul> <li> <p> Expansion</p> <p>Multi-query rewrites and semantic synonyms improve recall.</p> </li> <li> <p> Confidence Gates</p> <p><code>conf_top1</code>, <code>conf_avg5</code>, and <code>conf_any</code> control retry/fallback behavior.</p> </li> <li> <p> Eval Alignment</p> <p>Match eval settings (<code>eval_multi</code>, <code>eval_final_k</code>) with production.</p> </li> </ul> <p>Get started Configuration API</p> <p>Start Simple</p> <p>Begin with 2 rewrites and curated synonyms. Increase only if your evals show recall gaps.</p> <p>Synonyms File</p> <p><code>retrieval.tribrid_synonyms_path</code> points at a JSON mapping terms to arrays of synonyms. Works with <code>use_semantic_synonyms=1</code>.</p> <p>Rewrite Budget</p> <p>Every rewrite costs time (and likely tokens). Balance recall gains with latency budgets.</p> Field Default Description <code>retrieval.max_query_rewrites</code> 2 LLM rewrites for search <code>retrieval.multi_query_m</code> 4 Variants per multi-query run <code>retrieval.use_semantic_synonyms</code> 1 Expand with curated synonyms <code>retrieval.conf_top1</code> 0.62 Threshold for early-accept top-1 <code>retrieval.conf_avg5</code> 0.55 Gate for rewrite retries <code>retrieval.conf_any</code> 0.55 Safety net threshold <pre><code>flowchart TB\n    Q0[\"Original Query\"] --&gt; REW[\"Rewrites\"]\n    REW --&gt; RET[\"Parallel Retrievals\"]\n    RET --&gt; FUS[\"Fusion\"]\n    FUS --&gt; GATE[\"Confidence Gates\"]\n    GATE --&gt;|\"pass\"| Return[\"Return\"]\n    GATE --&gt;|\"fail\"| Retry[\"Rewrite + Retry\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\nsettings = {\n  \"retrieval\": {\n    \"max_query_rewrites\": 2,  # (1)!\n    \"multi_query_m\": 4,        # (2)!\n    \"use_semantic_synonyms\": 1 # (3)!\n  }\n}\nhttpx.patch(f\"{base}/config/retrieval\", json=settings[\"retrieval\"]).raise_for_status()\n</code></pre> <ol> <li>LLM rewrite budget</li> <li>RRF constant (M) for multi-query fusion</li> <li>Curated synonyms enabled</li> </ol> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X PATCH \"$BASE/config/retrieval\" -H 'Content-Type: application/json' \\\n  -d '{\"max_query_rewrites\":2,\"multi_query_m\":4,\"use_semantic_synonyms\":1}' | jq .\n</code></pre> TypeScript <pre><code>await fetch('/config/retrieval', {\n  method: 'PATCH',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({ max_query_rewrites: 2, multi_query_m: 4, use_semantic_synonyms: 1 }),\n});\n</code></pre> When to retry <ul> <li>Retry if <code>avg top-5 &lt; conf_avg5</code> and rewrite budget remains.</li> <li>Accept immediately if <code>top-1 &gt;= conf_top1</code>.</li> <li>Proceed if any result above <code>conf_any</code> when others fail.</li> </ul>"},{"location":"security/","title":"Security and Secrets","text":"<ul> <li> <p> Secrets</p> <p>API keys for providers and DB credentials loaded from environment.</p> </li> <li> <p> Validation</p> <p><code>/secrets/check</code> verifies presence and connectivity.</p> </li> <li> <p> Least Privilege</p> <p>Restrict DB users and network access.</p> </li> </ul> <p>Get started Configuration API</p> <p>Separate Environments</p> <p>Use different credentials per environment (dev, staging, prod). Never reuse production secrets locally.</p> <p>.env Hygiene</p> <p><code>.env</code> is for local dev only. In production, use a secret manager and inject env vars securely.</p> <p>Transport Security</p> <p>Terminate TLS in front of the API service. Restrict DB ports to private networks.</p>"},{"location":"security/#secrets-check","title":"Secrets Check","text":"Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/secrets/check\").json())\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/secrets/check | jq .\n</code></pre> TypeScript <pre><code>async function secrets() {\n  console.log(await (await fetch('/secrets/check')).json());\n}\n</code></pre>"},{"location":"security/#environment-keys-selected","title":"Environment Keys (Selected)","text":"Key Purpose <code>OPENAI_API_KEY</code>, <code>VOYAGE_API_KEY</code>, <code>COHERE_API_KEY</code>, <code>JINA_API_KEY</code> Provider access for embedding/gen/rerank <code>POSTGRES_*</code> DB connection for pgvector + FTS <code>NEO4J_*</code> Neo4j connection <code>SERVER_PORT</code> API service port <code>CONFIG_FILE</code> Path to <code>tribrid_config.json</code> <pre><code>flowchart LR\n    Env[\"Environment\"] --&gt; API\n    API --&gt; Check[\"/secrets/check\"]\n    Check --&gt; Report[\"Status\"]</code></pre> <p>Audit</p> <p>Log access to admin endpoints (<code>/config</code>, <code>/docker/*</code>, <code>/reranker/*</code>). Monitor for unusual patterns in logs and metrics.</p>"},{"location":"testing/","title":"Testing and Verification","text":"<ul> <li> <p> Zero-Mocked</p> <p>Real integrations: no request interception or Python mocks.</p> </li> <li> <p> Coverage by Change Type</p> <p>Components \u2192 Playwright, APIs \u2192 pytest, Retrieval \u2192 relevance.</p> </li> <li> <p> Gate to Done</p> <p>You cannot return a response unless tests run and pass.</p> </li> </ul> <p>Get started Configuration API</p> <p>Real Results</p> <p>Validate that search returns relevant chunks, not just 200 OK.</p> <p>CI Hooks</p> <p>Stop hook blocks completion until validators and tests succeed.</p> <p>No Mocks</p> <ul> <li>No Playwright <code>page.route(...).fulfill(...)</code></li> <li>No Python <code>unittest.mock</code> / <code>monkeypatch</code></li> </ul>"},{"location":"testing/#required-tests-by-change-type","title":"Required Tests by Change Type","text":"Change Required Test New component Playwright: render, interact, verify state Component edit Playwright: existing tests still pass + new behavior API endpoint pytest: real request/response/data Config field pytest: validation works, default applies Retrieval logic pytest: search returns relevant results Bug fix Test reproduces bug, then passes after fix"},{"location":"testing/#examples","title":"Examples","text":"Python <pre><code># RIGHT - verify real results\nimport httpx\n\ndef test_search_returns_relevant_chunks():\n    r = httpx.post(\"http://localhost:8000/search\", json={\n        \"query\": \"authentication flow\",\n        \"corpus_id\": \"my-corpus\",\n        \"top_k\": 10,\n    })\n    r.raise_for_status()\n    results = r.json()[\"matches\"]\n    assert len(results) &gt;= 3\n    assert any(\"auth\" in m[\"content\"].lower() for m in results)\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/search -H 'Content-Type: application/json' \\\n  -d '{\"corpus_id\":\"my-corpus\",\"query\":\"authentication flow\",\"top_k\":10}' | jq '[.matches[].file_path] | length'\n</code></pre> TypeScript <pre><code>// Playwright example skeleton\nimport { test, expect } from '@playwright/test';\n\ntest('fusion weight slider updates config', async ({ page }) =&gt; {\n  await page.goto('/rag');\n  const slider = page.getByTestId('vector-weight-slider');\n  await slider.fill('0.6');\n  await page.getByTestId('save-config').click();\n  await expect(page.getByTestId('config-saved-toast')).toBeVisible();\n  await page.reload();\n  await expect(slider).toHaveValue('0.6');\n});\n</code></pre> <ul> <li> Start full stack locally (<code>./start.sh --with-observability</code>)</li> <li> Configure LLM credentials in <code>.env</code></li> <li> Convert legacy mocked tests before editing feature areas</li> </ul> Artifacts <p>Temporary feature tests and results go in <code>.tests/</code>; permanent tests go under <code>tests/</code>.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<ul> <li> <p> Common Failures</p> <p>Timeouts, DB connectivity, schema mismatches.</p> </li> <li> <p> Validation Errors</p> <p>Pydantic constraints fail fast with precise messages.</p> </li> <li> <p> Recovery</p> <p>Clear caches, reindex, restart services.</p> </li> </ul> <p>Get started Configuration API</p> <p>Read the Error</p> <p>Pydantic tells you exactly which field failed validation and why. Fix the config, regenerate types if needed, and retry.</p> <p>Logs</p> <p>Use <code>/docker/{container}/logs</code> and application logs to pinpoint failures. For DB errors, also inspect Postgres and Neo4j logs.</p> <p>Data Loss Risk</p> <p>Avoid deleting DB volumes unless you intend a full reset. Back up before destructive actions.</p>"},{"location":"troubleshooting/#symptom-action","title":"Symptom \u2192 Action","text":"Symptom Likely Cause Action 500 on <code>/search</code> DB unavailable Check <code>/ready</code>, restart DB containers No results from graph Neo4j empty or disconnected Rebuild graph, check credentials Validation error on <code>/config</code> Field constraints violated Adjust values to allowed ranges Slow queries High <code>max_hops</code>, large <code>top_k</code> Reduce hops, tune indexes <pre><code>flowchart TB\n    Error[\"Error\"] --&gt; Check[\"/ready\"]\n    Check --&gt;|\"ok\"| Investigate[\"Inspect Logs\"]\n    Check --&gt;|\"fail\"| Restart[\"Restart Services\"]\n    Investigate --&gt; Fix[\"Config Tune\"]</code></pre> Python <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/ready\").json())  # readiness\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/docker/status | jq .\n</code></pre> TypeScript <pre><code>await fetch('/ready').then(r =&gt; r.ok || Promise.reject('Not ready'))\n</code></pre> <ul> <li> Verify readiness</li> <li> Inspect logs</li> <li> Reduce search/fusion parameters</li> <li> Reindex corpus</li> </ul> Cache Issues <p>If you suspect stale caches, clear retrieval caches (if enabled) and restart the API to invalidate in-memory state.</p>"},{"location":"architecture/health-metrics/","title":"Health and Metrics Internals","text":"<ul> <li> <p> Liveness/Readiness</p> <p>Handlers return fine-grained status with DB probes.</p> </li> <li> <p> Prometheus</p> <p>Export standard and custom app metrics.</p> </li> <li> <p> DB Exporter</p> <p>PostgreSQL exporter complements app metrics.</p> </li> </ul> <p>Get started Configuration API</p> <p>Scrape Intervals</p> <p>Start with 15s scraping and tighten as necessary to capture spikes while controlling overhead.</p> <p>Metric Names</p> <p>Prefix application metrics with <code>tribrid_</code> and prefer corpus-level labels.</p> <p>Cardinality</p> <p>Avoid labels that grow per-query.</p> <pre><code>flowchart TB\n    App --&gt; METRICS[\"/metrics\"]\n    METRICS --&gt; Prom[\"Prometheus\"]\n    Postgres --&gt; PExp[\"postgres-exporter\"]\n    PExp --&gt; Prom</code></pre>"},{"location":"architecture/health-metrics/#access-examples","title":"Access Examples","text":"Python <pre><code>import httpx\nassert httpx.get(\"http://localhost:8000/health\").status_code == 200\nassert httpx.get(\"http://localhost:8000/ready\").status_code == 200\nprint(httpx.get(\"http://localhost:8000/metrics\").text.splitlines()[:5])\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/health\ncurl -sS http://localhost:8000/ready\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> TypeScript <pre><code>await fetch('/health').then(r =&gt; r.ok || Promise.reject('down'))\nawait fetch('/ready').then(r =&gt; r.ok || Promise.reject('not ready'))\nconst sample = await (await fetch('/metrics')).text();\nconsole.log(sample.split('\\n').slice(0, 5));\n</code></pre> <p>Observability</p> <p>Combine <code>/metrics</code> with logs and tracing for a complete operational picture.</p>"},{"location":"assets/images/","title":"Screenshots Guide","text":"<ul> <li> <p> High-Quality Images</p> <p>Dark theme, 1920x1080, real data.</p> </li> <li> <p> What to Capture</p> <p>RAG config, search results, graph visualization, model picker, glossary.</p> </li> <li> <p> Organization</p> <p>Save descriptive filenames in <code>docs/assets/images/</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Suggested Shots</p> <ul> <li>RAG configuration with fusion weights and reranker</li> <li>Search results with citations</li> <li>Graph visualization (entities, relationships)</li> <li>Model selector and pricing info</li> <li>Glossary tooltips in action</li> </ul> <p>Filenames</p> <ul> <li><code>rag-config-interface.png</code></li> <li><code>search-results.png</code></li> <li><code>graph-visualization.png</code></li> <li><code>model-selector.png</code></li> </ul> <p>Privacy</p> <p>Ensure screenshots do not contain secrets or PII.</p>"},{"location":"assets/images/#add-images-to-docs","title":"Add Images to Docs","text":"<pre><code>![RAG Configuration Interface](./assets/images/rag-config-interface.png)\n</code></pre> Python <pre><code># Tip: keep images under docs/assets/images and reference with relative paths\nprint(\"Embed with ![alt](./assets/images/filename.png)\")\n</code></pre> curl <pre><code># No runtime step; images are static assets.\n</code></pre> TypeScript <pre><code>// Not applicable; images are referenced in markdown.\n</code></pre> <pre><code>flowchart TB\n    Shot[\"Screenshot\"] --&gt; File[\"docs/assets/images/*.png\"]\n    File --&gt; Markdown[\"Markdown Pages\"]\n    Markdown --&gt; Site[\"MkDocs Site\"]</code></pre> <ul> <li> Use dark mode</li> <li> Real data</li> <li> Descriptive filenames</li> </ul>"},{"location":"dev/pydantic/","title":"Pydantic-First Development","text":"<ul> <li> <p> The Law</p> <p>Everything starts in <code>tribrid_config_model.py</code>. If it\u2019s not there, it does not exist.</p> </li> <li> <p> Generate Types</p> <p><code>uv run scripts/generate_types.py</code> produces <code>web/src/types/generated.ts</code>.</p> </li> <li> <p> Derivation Chain</p> <p>Pydantic \u2192 generated.ts \u2192 stores \u2192 hooks \u2192 components.</p> </li> </ul> <p>Get started Configuration API</p> <p>Workflow</p> <ul> <li>Add/modify fields in Pydantic with <code>Field()</code> constraints and descriptions.</li> <li>Generate TS types.</li> <li>Use types in stores/hooks/components.</li> <li>Implement backend behavior that uses those fields.</li> </ul> <p>Constraints</p> <p>Use <code>Field(ge=..., le=..., description=...)</code> everywhere. Descriptions power docs and UI tooltips.</p> <p>No Adapters</p> <p>Never write client-side adapters to change response shapes. Fix the Pydantic model instead and regenerate.</p>"},{"location":"dev/pydantic/#derivation-chain","title":"Derivation Chain","text":"<pre><code>flowchart TB\n    P[\"Pydantic\\ntribrid_config_model.py\"] --&gt; G[\"pydantic2ts\\n(generate_types.py)\"]\n    G --&gt; T[\"generated.ts\"]\n    T --&gt; Z[\"Zustand Stores\"]\n    Z --&gt; H[\"Hooks\"]\n    H --&gt; C[\"Components\"]\n    P --&gt; A[\"FastAPI Schemas\"]</code></pre>"},{"location":"dev/pydantic/#commands-annotated","title":"Commands (Annotated)","text":"Python <pre><code>import subprocess\n\n# Generate TS types from Pydantic (1)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)\n\n# Validate sync (2)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/validate_types.py\"])  # (2)\n</code></pre> curl <pre><code># Run locally with Python; no direct curl equivalent\n</code></pre> TypeScript <pre><code>// After generation, import from generated.ts (3)\nimport type { TriBridConfig } from '../web/src/types/generated'; // (3)\n</code></pre> <ol> <li>Generate TypeScript types from Pydantic models</li> <li>Validate that generated types match current models</li> <li>Consume generated types exclusively</li> </ol>"},{"location":"dev/pydantic/#ralph-loop-verification-based-development","title":"Ralph Loop (Verification-Based Development)","text":"<ul> <li> Start from repo root</li> <li> For each iteration: pick first unchecked TODO, implement end-to-end</li> <li> Verification sequence:</li> <li><code>uv run scripts/check_banned.py</code></li> <li><code>uv run scripts/validate_types.py</code></li> <li><code>uv run pytest -q</code></li> <li> Only mark TODO complete when verification passes</li> </ul> <pre><code>flowchart TB\n    Iteration[\"Ralph Loop Iteration\"] --&gt; TODO[\"Read TODO.md\"]\n    TODO --&gt; Implement[\"Implement Feature\"]\n    Implement --&gt; Verify[\"Run Verification\"]\n    Verify --&gt;|pass| Next[\"Next Iteration\"]\n    Verify --&gt;|fail| Fix[\"Fix Exact Failure\"]</code></pre> Testing Discipline <ul> <li>GUI changes: Playwright tests with real interactions</li> <li>API changes: pytest with real request/response assertions</li> <li>Retrieval logic: verify relevance in results</li> </ul>"},{"location":"guides/corpus/","title":"Corpus vs repo_id","text":"<ul> <li> <p> Corpus-First</p> <p>A corpus is any folder you index: repo, docs, or subtree.</p> </li> <li> <p> Isolation</p> <p>Each corpus has separate Postgres tables, Neo4j DB, and config.</p> </li> <li> <p> Naming Migration</p> <p>API accepts <code>repo_id</code> but serializes as <code>corpus_id</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Best Practice</p> <p>Use stable, lowercase slugs for corpus ids, e.g., <code>tribrid</code>, <code>myapp-docs</code>. Avoid spaces and special characters.</p> <p>AliasChoices</p> <p>Pydantic models specify <code>validation_alias=AliasChoices(\"repo_id\", \"corpus_id\")</code> and <code>serialization_alias=\"corpus_id\"</code> to ensure forward compatibility.</p> <p>Cross-Corpus Leakage</p> <p>Never mix <code>corpus_id</code> across requests. Isolation is enforced in storage and graph layers.</p>"},{"location":"guides/corpus/#models-using-corpus_id","title":"Models Using corpus_id","text":"Model Fields <code>IndexRequest</code> <code>corpus_id</code>, <code>repo_path</code>, <code>force_reindex</code> <code>IndexStatus</code> <code>corpus_id</code>, <code>status</code>, <code>progress</code>, <code>current_file</code> <code>SearchRequest</code> <code>corpus_id</code>, <code>query</code>, <code>top_k</code> <pre><code>flowchart LR\n    UI[\"UI\"] --&gt; API[\"API\"]\n    API --&gt; Pyd[\"AliasChoices(repo_id, corpus_id)\"]\n    Pyd --&gt; Store[\"Serialized as corpus_id\"]</code></pre>"},{"location":"guides/corpus/#example-requests","title":"Example Requests","text":"Python <pre><code>import httpx\nreq = {\"corpus_id\": \"tribrid\", \"repo_path\": \"/code/tribrid\", \"force_reindex\": False}\nhttpx.post(\"http://localhost:8000/index\", json=req)\nhttpx.get(\"http://localhost:8000/index/status\", params={\"corpus_id\": \"tribrid\"})\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/index -H 'Content-Type: application/json' -d '{\n  \"corpus_id\": \"tribrid\", \"repo_path\": \"/code/tribrid\", \"force_reindex\": false\n}'\n</code></pre> TypeScript <pre><code>import type { IndexRequest } from \"../../web/src/types/generated\";\nconst req: IndexRequest = { corpus_id: 'tribrid', repo_path: '/code/tribrid', force_reindex: false };\n</code></pre> <p>Multi-Corpus UIs</p> <p>Add a repo switcher bound to <code>corpus_id</code>. All panels (RAG, Graph, Index) should update in lockstep.</p>"},{"location":"howto/reranker/","title":"How-To: Reranker Training and Evaluation","text":"<ul> <li> <p> Reranker</p> <p>Cross-encoder stage to refine fused retrieval results.</p> </li> <li> <p>:material-mining:{ .lg .middle } Triplet Mining</p> <p>Collect (query, positive, negative) examples from logs or heuristics.</p> </li> <li> <p> Evaluate</p> <p>Benchmark before/after reranking on an evaluation dataset.</p> </li> </ul> <p>Get started Configuration API</p> <p>Start Small</p> <p>Begin with a small <code>eval_dataset</code> and a few hundred mined triplets. Validate that gains are consistent across corpora.</p> <p>Costs</p> <p>Training and evaluation costs depend on selected <code>RERANK</code> and <code>EMB/GEN</code> models from <code>data/models.json</code>.</p> <p>Config-Governed</p> <p>Enable via <code>reranking.reranker_mode</code>. All training hyperparameters must be present in Pydantic before use.</p>"},{"location":"howto/reranker/#api-surface","title":"API Surface","text":"Route Method Description <code>/reranker/status</code> GET Load status (mode/model) <code>/reranker/info</code> GET Implementation details <code>/reranker/mine</code> POST Mine triplets <code>/reranker/train</code> POST Train reranker <code>/reranker/evaluate</code> POST Evaluate against dataset <code>/reranker/train/run/{run_id}</code> GET Inspect a training run <code>/reranker/train/run/{run_id}/metrics</code> GET Metrics stream <pre><code>flowchart TB\n    Logs[\"Retrieval Logs\"] --&gt; Mine[\"Mine Triplets\"]\n    Mine --&gt; Train[\"Train Reranker\"]\n    Train --&gt; Model[\"Reranker Model\"]\n    Model --&gt; Eval[\"Evaluate\"]\n    Eval --&gt; Report[\"Metrics\"]</code></pre>"},{"location":"howto/reranker/#example-workflow-annotated","title":"Example Workflow (Annotated)","text":"Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\n# Mine triplets (1)\nhttpx.post(f\"{base}/reranker/mine\", json={\"corpus_id\": \"tribrid\", \"max_pairs\": 500}).raise_for_status()\n\n# Train (2)\nhttpx.post(f\"{base}/reranker/train\", json={\"corpus_id\": \"tribrid\", \"epochs\": 2, \"batch_size\": 16}).raise_for_status()\n\n# Evaluate (3)\nprint(httpx.post(f\"{base}/reranker/evaluate\", json={\"corpus_id\": \"tribrid\"}).json())\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/mine\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"max_pairs\":500}'\ncurl -sS -X POST \"$BASE/reranker/train\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"epochs\":2,\"batch_size\":16}'\ncurl -sS -X POST \"$BASE/reranker/evaluate\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> TypeScript <pre><code>async function trainReranker(corpus_id: string) {\n  await fetch('/reranker/mine', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id, max_pairs: 500 }) }); // (1)\n  await fetch('/reranker/train', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id, epochs: 2, batch_size: 16 }) }); // (2)\n  const report = await (await fetch('/reranker/evaluate', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id }) })).json(); // (3)\n  console.log(report);\n}\n</code></pre> <ol> <li>Mine triplets from logs/heuristics</li> <li>Train a local cross-encoder</li> <li>Evaluate results on your <code>eval_dataset</code></li> </ol>"},{"location":"howto/reranker/#reranker-config-fields-selected","title":"Reranker Config Fields (Selected)","text":"Field Description <code>reranking.reranker_mode</code> <code>none | local | learning | cloud</code> <code>reranking.reranker_cloud_provider</code> Provider id when cloud mode <code>reranking.reranker_local_model</code> HuggingFace/local model id <code>reranking.tribrid_reranker_topn</code> Candidates to rerank <code>reranking.rerank_input_snippet_chars</code> Max chars per candidate snippet <p>Evaluation Discipline</p> <p>Use a fixed <code>eval_dataset</code> to avoid overfitting. Track MRR, Recall@K, and NDCG pre/post reranking.</p>"},{"location":"integrations/mcp/","title":"MCP Integration (Model Context Protocol)","text":"<ul> <li> <p> Embedded MCP HTTP</p> <p>Optional stateless HTTP transport for tools and clients.</p> </li> <li> <p> Access Control</p> <p>Allowed hosts/origins, optional API key, DNS rebinding protection.</p> </li> <li> <p> Defaults</p> <p>Per-endpoint defaults for retrieval mode and Top-K.</p> </li> </ul> <p>Get started Configuration API</p> <p>Stateless Mode</p> <p>Keep the embedded MCP HTTP endpoint stateless for easier scaling and isolation.</p> <p>Path and CORS</p> <p>Align <code>mount_path</code>, <code>allowed_hosts</code>, and <code>allowed_origins</code> with your reverse proxy and UI origin to avoid CORS issues.</p> <p>Auth</p> <p>Use <code>require_api_key=true</code> in multi-tenant or exposed deployments.</p>"},{"location":"integrations/mcp/#configuration-selected","title":"Configuration (Selected)","text":"Field Default Description <code>mcp.enabled</code> true Enable embedded MCP HTTP endpoint <code>mcp.mount_path</code> <code>/mcp</code> URL path for MCP endpoint <code>mcp.stateless_http</code> true Stateless mode <code>mcp.json_response</code> true Prefer JSON responses <code>mcp.enable_dns_rebinding_protection</code> true Defense in depth <code>mcp.allowed_hosts</code> <code>localhost:*</code> Allowed Host headers <code>mcp.allowed_origins</code> <code>http://localhost:*</code> Allowed Origin values <code>mcp.require_api_key</code> false Require <code>Authorization: Bearer</code> <code>mcp.default_top_k</code> 20 Default Top-K when omitted <code>mcp.default_mode</code> <code>tribrid</code> Default retrieval mode <pre><code>flowchart LR\n    Client[\"MCP Client\"] --&gt; HTTP[\"HTTP /mcp\"]\n    HTTP --&gt; RAG[\"TriBridRAG Tools\"]\n    RAG --&gt; Search[\"Search / Answer\"]</code></pre>"},{"location":"integrations/mcp/#status-endpoint","title":"Status Endpoint","text":"Python <pre><code>import httpx\nstatus = httpx.get(\"http://localhost:8000/mcp/status\").json()\nprint(status)\n</code></pre> curl <pre><code>curl -sS http://localhost:8000/mcp/status | jq .\n</code></pre> TypeScript <pre><code>async function mcpStatus() {\n  const s = await (await fetch('/mcp/status')).json();\n  console.log(s);\n}\n</code></pre> <ul> <li> Set allowed hosts/origins</li> <li> Enable API key when exposing outside localhost</li> <li> Choose default retrieval mode/Top-K for tools</li> </ul>"},{"location":"retrieval/fusion/","title":"Fusion Details","text":"<ul> <li> <p> Weighted Fusion</p> <p>Linear combination of normalized scores with interpretable weights.</p> </li> <li> <p> Reciprocal Rank Fusion</p> <p>Rank-based fusion robust to heterogeneous score distributions.</p> </li> <li> <p> Normalization</p> <p>Optional score normalization per leg before fusion.</p> </li> </ul> <p>Get started Configuration API</p> <p>Start with RRF</p> <p>RRF is often robust without per-leg calibration. Switch to <code>weighted</code> once you have stable score distributions and want more control.</p> <p>Weights Sum</p> <p>Pydantic validators normalize tri-brid weights to sum to 1.0.</p> <p>Mismatched Scales</p> <p>If you use <code>weighted</code>, enable <code>fusion.normalize_scores</code> unless all legs produce comparable scales.</p>"},{"location":"retrieval/fusion/#configuration","title":"Configuration","text":"Field Type Default Description <code>fusion.method</code> Literal <code>rrf</code> <code>rrf | weighted</code> <code>fusion.vector_weight</code> float 0.4 Vector contribution <code>fusion.sparse_weight</code> float 0.3 Sparse contribution <code>fusion.graph_weight</code> float 0.3 Graph contribution <code>fusion.rrf_k</code> int 60 RRF smoothing constant <code>fusion.normalize_scores</code> bool true Normalize per-leg scores <pre><code>flowchart TB\n    V[\"Vector Scores\"] --&gt; N[\"Normalize (opt)\"]\n    S[\"Sparse Scores\"] --&gt; N\n    G[\"Graph Scores\"] --&gt; N\n    N --&gt; W[\"Weighted Sum\"]\n    N --&gt; RRF[\"RRF (1/(k+rank))\"]</code></pre>"},{"location":"retrieval/fusion/#annotated-implementation-sketch","title":"Annotated Implementation Sketch","text":"Python <pre><code>def fuse(vector, sparse, graph, cfg):  # (1)\n    if cfg.fusion.method == \"rrf\":\n        return rrf_fusion(vector, sparse, graph, k=cfg.fusion.rrf_k)  # (2)\n    else:\n        if cfg.fusion.normalize_scores:\n            vector, sparse, graph = map(normalize01, (vector, sparse, graph))  # (3)\n        return weighted(vector, sparse, graph, (cfg.fusion.vector_weight, cfg.fusion.sparse_weight, cfg.fusion.graph_weight))  # (4)\n</code></pre> curl <pre><code># Fusion is server-controlled via config; no direct curl\n</code></pre> TypeScript <pre><code>// Client impacts fusion by PATCH /config/fusion\n</code></pre> <ol> <li>Inputs are per-leg result lists with scores</li> <li>RRF uses ranks only; tune <code>rrf_k</code></li> <li>Optional normalization improves comparability</li> <li>Weighted sum uses tri-brid weights (sum to ~1)</li> </ol>"},{"location":"retrieval/graph/","title":"Graph Retrieval and Storage","text":"<ul> <li> <p> Graph Storage</p> <p>Neo4j stores entities/relationships; per-corpus isolation via database selection.</p> </li> <li> <p>:material-route:{ .lg .middle } Traversal</p> <p>Expand from seeds with <code>max_hops</code>, optionally adding neighbor context.</p> </li> <li> <p> Indexing Hooks</p> <p>Build lexical graph, store chunk embeddings, and (optionally) semantic KG.</p> </li> </ul> <p>Get started Configuration API</p> <p>Chunk Mode</p> <p>The <code>graph_search.mode=\"chunk\"</code> blends lexical adjacency with entity expansion for practical cross-file context.</p> <p>Per-Corpus Database</p> <p>Use <code>graph_storage.neo4j_database_mode=\"per_corpus\"</code> (Neo4j Enterprise) for hard isolation.</p> <p>Vector Index</p> <p>If you store chunk embeddings in Neo4j, ensure the vector index comes ONLINE before serving traffic.</p>"},{"location":"retrieval/graph/#search-configuration-selected","title":"Search Configuration (Selected)","text":"Field Default Description <code>graph_search.enabled</code> true Enable graph leg <code>graph_search.max_hops</code> 2 Traversal depth <code>graph_search.top_k</code> 30 Hits from traversal <code>graph_search.chunk_neighbor_window</code> 1 Include adjacent chunks <code>graph_search.chunk_entity_expansion_enabled</code> true Expand via entity links"},{"location":"retrieval/graph/#storage-configuration-selected","title":"Storage Configuration (Selected)","text":"Field Default Description <code>graph_storage.neo4j_uri</code> <code>bolt://localhost:7687</code> Connection URI <code>graph_storage.neo4j_user</code> <code>neo4j</code> Username <code>graph_storage.neo4j_password</code> \u2014 Password <code>graph_storage.max_hops</code> 2 Default traversal bound <code>graph_indexing.store_chunk_embeddings</code> true Store chunk vectors on nodes <code>graph_indexing.chunk_vector_index_name</code> <code>tribrid_chunk_embeddings</code> Vector index name <pre><code>flowchart LR\n    Seed[\"Seed Chunks\"] --&gt; Walk[\"Traversal (max_hops)\"]\n    Walk --&gt; Neigh[\"Neighbors\"]\n    Neigh --&gt; Return[\"Ranked Chunk IDs\"]</code></pre> Python <pre><code>import httpx\nbase = \"http://localhost:8000\"\nentities = httpx.get(f\"{base}/graph/tribrid/entities\").json()\nfirst = entities[0]\nrels = httpx.get(f\"{base}/graph/tribrid/entity/{first['entity_id']}/neighbors\").json()\nprint(first['name'], len(rels.get('relationships', [])))\n</code></pre> curl <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/graph/tribrid/entities\" | jq '.[0]'\n</code></pre> TypeScript <pre><code>async function neighbors(corpus: string) {\n  const ents = await (await fetch(`/graph/${corpus}/entities`)).json();\n  const id = ents[0].entity_id;\n  const rels = await (await fetch(`/graph/${corpus}/entity/${id}/neighbors`)).json();\n  console.log(id, rels.relationships.length);\n}\n</code></pre>"},{"location":"retrieval/overview/","title":"Retrieval Overview","text":"<ul> <li> <p> Vector Search</p> <p>pgvector similarity over chunk embeddings with configurable Top-K.</p> </li> <li> <p> Sparse Search</p> <p>PostgreSQL FTS/BM25 for exact tokens, identifiers, and literals.</p> </li> <li> <p> Graph Search</p> <p>Neo4j traversal to expand neighborhoods and follow relationships across files.</p> </li> <li> <p> Fusion</p> <p>Weighted or RRF; per-retriever contributions tracked for analysis.</p> </li> <li> <p> Optional Reranker</p> <p>Cross-encoder rescoring of fused candidates for precision.</p> </li> </ul> <p>Get started Configuration API</p> <p>Balance Recall and Precision</p> <p>Increase per-leg Top-K to maximize recall; use fusion weights and reranking to restore precision.</p> <p>Isolation by Corpus</p> <p>Each corpus has isolated storage and graph. Queries always require <code>corpus_id</code>.</p> <p>Latency Budget</p> <p>Graph traversal increases latency with larger hop counts. Use <code>max_hops</code> conservatively.</p>"},{"location":"retrieval/overview/#control-surface-selected","title":"Control Surface (Selected)","text":"Retriever Key Fields Defaults Vector <code>vector_search.enabled</code>, <code>vector_search.top_k</code> 50 Sparse <code>sparse_search.enabled</code>, <code>sparse_search.top_k</code>, <code>sparse_search.bm25_k1</code>, <code>sparse_search.bm25_b</code> 50 / 1.2 / 0.4 Graph <code>graph_search.enabled</code>, <code>graph_search.max_hops</code>, <code>graph_search.top_k</code> true / 2 / 30 Fusion <code>fusion.method</code>, <code>fusion.rrf_k</code>, <code>fusion.*_weight</code> rrf / 60 Reranker <code>reranking.reranker_mode</code>, <code>tribrid_reranker_topn</code> local / 50 <pre><code>flowchart LR\n    Q[\"Query\"] --&gt; V[\"Vector\"]\n    Q --&gt; S[\"Sparse\"]\n    Q --&gt; G[\"Graph\"]\n    V --&gt; F[\"Fusion\"]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[\"Reranker (opt)\"]\n    R --&gt; OUT[\"Results\"]\n    F --&gt; OUT</code></pre>"},{"location":"retrieval/overview/#programmatic-search","title":"Programmatic Search","text":"Python <pre><code>import httpx\nBASE = \"http://localhost:8000\"\nbody = {\"corpus_id\": \"tribrid\", \"query\": \"How are pgvector indexes created?\", \"top_k\": 10}\nres = httpx.post(f\"{BASE}/search\", json=body).json()  # (1)\nfor r in res.get(\"matches\", []):\n    print(r[\"file_path\"], r[\"score\"])  # fused score (2)\n</code></pre> curl <pre><code>curl -sS -X POST http://localhost:8000/search \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"corpus_id\":\"tribrid\",\"query\":\"pgvector index\",\"top_k\":10}' | jq '.matches[0]'\n</code></pre> TypeScript <pre><code>import type { SearchRequest, SearchResponse } from \"../../web/src/types/generated\";\n\nasync function run(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const r = await fetch(\"/search\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) });\n  return await r.json();\n}\n</code></pre> <ol> <li>Search executes all retrievers concurrently</li> <li><code>score</code> is fused; provenance retained in each <code>ChunkMatch.source</code></li> </ol> <p>Auditable Fusion</p> <p><code>SearchResponse.debug</code> can include per-leg diagnostics when enabled.</p> Caching <p>Retrieval cache keys include <code>corpus_id</code>, <code>query</code>, and a hash of relevant retrieval config. Invalidate on config change or reindex.</p>"},{"location":"retrieval/vector-sparse/","title":"Vector + Sparse Retrieval","text":"<ul> <li> <p> Dense Semantics</p> <p>Embeddings capture meaning beyond exact tokens.</p> </li> <li> <p> Keyword Precision</p> <p>BM25 excels at exact identifiers, error codes, and file names.</p> </li> <li> <p> Hybrid Strength</p> <p>Combining both improves recall and precision across query types.</p> </li> </ul> <p>Get started Configuration API</p> <p>Tune Weights</p> <p>Set <code>retrieval.vector_weight</code> vs <code>retrieval.bm25_weight</code> (and/or <code>fusion.*_weight</code>) based on corpus characteristics.</p> <p>Top-K Budget</p> <p>Keep <code>topk_dense</code> and <code>topk_sparse</code> high enough that <code>final_k</code> always has good candidates.</p> <p>Embedding Mismatch</p> <p>Changing embedding model/dimensions requires full reindexing.</p> Field Default Notes <code>vector_search.top_k</code> 50 Candidate set size for dense <code>sparse_search.top_k</code> 50 Candidate set size for BM25 <code>retrieval.final_k</code> 10 Returned results after fusion"}]}