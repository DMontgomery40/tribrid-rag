{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<ul> <li> <p> TriBridRAG Overview</p> <p>Three retrieval methods fused for precise, recall-first search</p> </li> <li> <p> PostgreSQL + pgvector</p> <p>Dense vectors + FTS in a single Postgres backbone</p> </li> <li> <p> Neo4j Knowledge Graph</p> <p>Entity traversal and relationships for contextual expansion</p> </li> </ul> <p>Pro Tip</p> <p>Start by reading the Configuration page \u2014 Pydantic is the law and defines every option the system supports.</p> <p>Implementation Note</p> <p>TriBridRAG is corpus-first. The codebase and UI still call this field <code>repo_id</code>, treat it as <code>corpus_id</code>.</p> <p>Security Warning</p> <p>Never check production API keys or DB passwords into source control. Use environment variables and Ctrl+C to copy sensitive values only in secure contexts.</p>"},{"location":"#table-of-contents","title":"Table of contents","text":"<ul> <li>Architecture</li> <li>Retrieval Overview</li> <li>Configuration &amp; Models</li> <li>API Reference</li> <li>Indexing Pipeline</li> <li>Deployment &amp; Docker</li> <li>Glossary</li> </ul> Collapsible: Quick Start <p>Follow these high-level steps to get TriBridRAG running locally.</p> <ul> <li> Install dependencies</li> <li> Fill out .env (see Deployment)</li> <li> Start Docker services</li> <li> Index a corpus and build the graph</li> <li> Configure models in UI</li> </ul>"},{"location":"#key-configuration-snapshot","title":"Key configuration snapshot","text":"Feature Description Status Vector Search pgvector in PostgreSQL for semantic similarity \u2705 Active Sparse Search Postgres FTS/BM25 for exact matches \u2705 Active Graph Search Neo4j traversal for relationships \u2705 Active"},{"location":"#architecture-summary","title":"Architecture summary","text":"<pre><code>flowchart LR\n    Query[User Query] --&gt; Vector[Vector Search]\n    Query --&gt; Sparse[Sparse Search]\n    Query --&gt; Graph[Graph Search]\n    Vector --&gt; Fusion[Fusion Layer]\n    Sparse --&gt; Fusion\n    Graph --&gt; Fusion\n    Fusion --&gt; Rerank[Reranker]\n    Rerank --&gt; Results[Final Results]</code></pre> PythoncurlTypeScript <pre><code>def search(query: str, repo_id: str): # (1)\n    results = fusion.search(query, repo_id) # (2)\n    results = reranker.rerank(results, query) # (3)\n    return results\n</code></pre> <pre><code>curl -X POST \"http://localhost:8000/search\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"how to open a file\", \"repo_id\": \"my_corpus\"}'\n</code></pre> <pre><code>// (1) Use generated types from Pydantic conversion\nimport { SearchRequest } from '../types/generated'\n\nasync function runSearch(req: SearchRequest) { // (2)\n  const res = await fetch('/api/search', { method: 'POST', body: JSON.stringify(req) })\n  return res.json()\n}\n</code></pre> <ol> <li>The query and corpus identifier</li> <li>Fusion runs vector + sparse + graph in parallel</li> <li>Optional reranking with a cross-encoder reranker</li> </ol>"},{"location":"#accessibility-reading","title":"Accessibility &amp; reading","text":"<ul> <li>Clear headers and visual breaks are used for dyslexic-friendly reading</li> <li>Use Ctrl+C to copy commands</li> </ul> <ol> <li> <p>See tribrid_config_model.py for the authoritative list of configuration fields\u00a0\u21a9</p> </li> </ol>"},{"location":"api/","title":"API","text":"<ul> <li> <p> API Endpoints</p> <p>FastAPI endpoints in server/api/</p> </li> <li> <p> Search &amp; Retrieval</p> <p>/search, /graph, /chunk_summaries</p> </li> <li> <p> Config &amp; Models</p> <p>/config, /models, /reranker</p> </li> </ul> <p>Implementation Note</p> <p>The API routes map directly to the server modules under server/api. Each endpoint uses Pydantic models for request/response validation.</p> <p>Pro Tip</p> <p>Use the models endpoint (GET /models) as the authoritative list for UI dropdowns. Do not hardcode model lists elsewhere.</p> <p>Compatibility Warning</p> <p>API still uses <code>repo_id</code> naming. When scoping operations, prefer <code>corpus_id</code> but accept <code>repo_id</code> for compatibility.</p> Collapsible: Endpoint index <p>The API modules expose endpoints and helper functions. Key modules include:</p> <ul> <li>chunk_summaries.py</li> <li>config.py</li> <li>reranker.py</li> <li>models.py</li> <li>index.py</li> <li>graph.py</li> </ul>"},{"location":"api/#selected-endpoints-and-usage","title":"Selected endpoints and usage","text":"Endpoint Method Purpose Request model /search POST Run tri-brid search SearchRequest (generated) /config GET/PUT/PATCH Read/update server config TriBridConfig (generated) /models GET Serve data/models.json n/a /chunk_summaries GET/POST Read/build chunk summaries IndexScope / BuildRequest /graph/{corpus_id}/entities GET List graph entities CorpusScope <pre><code>flowchart LR\n    Client --&gt; API[FastAPI]\n    API --&gt; Search[/search]\n    API --&gt; Models[/models]\n    API --&gt; Config[/config]\n    Search --&gt; Fusion[TriBridFusion]\n    Fusion --&gt; DB[(Postgres)]\n    Fusion --&gt; Graph[(Neo4j)]</code></pre>"},{"location":"api/#example-search-call","title":"Example: search call","text":"PythoncurlTypeScript <pre><code>import requests\n\nresp = requests.post('http://localhost:8000/search', json={\n  'query': 'how to run migrations',\n  'repo_id': 'my_corpus'\n}) # (1)\nprint(resp.json())\n</code></pre> <pre><code>curl -X POST \"http://localhost:8000/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"query\":\"how to run migrations\",\"repo_id\":\"my_corpus\"}'\n</code></pre> <pre><code>import { SearchRequest, SearchResponse } from '../types/generated' // (1)\n\nasync function run(query: string, repoId: string): Promise&lt;SearchResponse&gt; {\n  const res = await fetch('/api/search', {\n    method: 'POST',\n    body: JSON.stringify({ query, repo_id: repoId }),\n  })\n  return res.json()\n}\n</code></pre> <ol> <li>Use generated types for request/response shapes</li> </ol>"},{"location":"api/#reranker-endpoints-selected","title":"Reranker endpoints (selected)","text":"Route Method Purpose /reranker/status GET Check if reranker is loaded /reranker/mine POST Mine triplets for training /reranker/train POST Train a reranker model /reranker/evaluate POST Evaluate reranker performance"},{"location":"api/#chunk-summaries-endpoints","title":"Chunk summaries endpoints","text":"Route Method Purpose /chunk_summaries GET List summaries for a corpus /chunk_summaries/build POST Trigger background build of chunk summaries <ul> <li> Use Ctrl+C to copy curl snippets</li> <li> Use generated TypeScript types from Pydantic for API contracts</li> </ul> Collapsible: Error handling <p>FastAPI returns structured errors when validation fails. Check status codes and error messages that include the failing field path.</p>"},{"location":"architecture/","title":"Architecture","text":"<ul> <li> <p> Tri-Bridge Fusion</p> <p>Fusion engine merges signals from multiple retrievers</p> </li> <li> <p> Single Postgres Store</p> <p>Embeddings (pgvector) + FTS for sparse search</p> </li> <li> <p> Knowledge Graph</p> <p>Neo4j holds entity nodes and relationships</p> </li> </ul> <p>Pro Tip</p> <p>Design UI controls only after adding fields to the Pydantic model. Generated TypeScript types drive the front-end stores.</p> <p>Implementation Note</p> <p>The derived TypeScript in web/src/types/generated.ts is auto-generated from server/models/tribrid_config_model.py.</p> <p>Critical</p> <p>The Pydantic schema is the source of truth. If it's missing a field, that feature does not exist.</p> Collapsible: Architecture detail <p>This section explains how repositories (corpora) map to storage and graph.</p>"},{"location":"architecture/#high-level-architecture","title":"High-level architecture","text":"<pre><code>flowchart LR\n    User[User / UI] --&gt; API[FastAPI Server]\n    API --&gt; Postgres[(PostgreSQL + pgvector + FTS)]\n    API --&gt; Neo4j[(Neo4j Graph DB)]\n    API --&gt; Models[(LLM / Embedding Providers)]\n    Postgres --&gt; Fusion[TriBridFusion]\n    Neo4j --&gt; Fusion\n    Fusion --&gt; Reranker[(Reranker Service)]\n    Reranker --&gt; API</code></pre>"},{"location":"architecture/#components-and-responsibilities","title":"Components and responsibilities","text":"Component Responsibility Example Files API Server Exposes endpoints, orchestrates retrieval and indexing server/api/*.py Postgres Index Stores chunks, embeddings, FTS index server/db/postgres.py Neo4j Graph Stores entities, relationships, communities server/db/neo4j.py Indexing Chunking, embedding, summarization server/indexing/* Retrieval Vector, Sparse, Graph retrievers + Fusion server/retrieval/* PythoncurlTypeScript <pre><code># (1) Example: wiring clients\nfrom server.db.postgres import PostgresClient\nfrom server.db.neo4j import Neo4jClient\n\npg = PostgresClient()\nng = Neo4jClient()\n\npg.connect() # (2)\nng.connect()\n</code></pre> <pre><code># (1) Ping health endpoint\ncurl http://localhost:8000/health\n</code></pre> <pre><code>// (1) Frontend reads types from generated.ts\nimport { TriBridConfig } from '../types/generated'\n\n// (2) useConfig() hook returns typed config\nconst cfg = useConfig()\n</code></pre> <ol> <li>Example annotations for code wiring</li> <li>Connect calls open DB connections</li> </ol>"},{"location":"architecture/#merits-of-tri-brid-approach","title":"Merits of tri-brid approach","text":"Feature Benefit Notes Parallel retrieval Better recall across query types Vector=semantic, Sparse=identifiers, Graph=relationships Corpus isolation Separate storage and graph per corpus Use repo_id as corpus identifier Config-driven behavior All thresholds, model choices are in Pydantic model Ensures traceability"},{"location":"architecture/#fusion-flow-detailed","title":"Fusion flow (detailed)","text":"<pre><code>sequenceDiagram\n    participant UI\n    participant API\n    participant Vector\n    participant Sparse\n    participant Graph\n    participant Fusion\n    participant Reranker\n    UI-&gt;&gt;API: search(req)\n    API-&gt;&gt;Vector: vector.search(req)\n    API-&gt;&gt;Sparse: sparse.search(req)\n    API-&gt;&gt;Graph: graph.search(req)\n    Vector--&gt;&gt;Fusion: vector_hits\n    Sparse--&gt;&gt;Fusion: sparse_hits\n    Graph--&gt;&gt;Fusion: graph_hits\n    Fusion-&gt;&gt;Reranker: fused_candidates\n    Reranker--&gt;&gt;API: final_ranked\n    API--&gt;&gt;UI: results</code></pre> <ul> <li> Confirm DB connections</li> <li> Verify embeddings table exists</li> <li> Tune fusion weights via config</li> </ul> Collapsible: Design decisions <ul> <li>Corpus-first design isolates data per corpus for multi-tenant safety.</li> <li>No frontend type should be hand-written; generated types are the contract.</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<ul> <li> <p> Pydantic Config Model</p> <p>All tunables live in server/models/tribrid_config_model.py</p> </li> <li> <p> Models List</p> <p>data/models.json is the source of truth for available LLMs and embeddings</p> </li> <li> <p> Environment &amp; Secrets</p> <p>DB URIs, API keys, and container memory are set via .env</p> </li> </ul> <p>Pro Tip</p> <p>Always add a new field to tribrid_config_model.py before adding UI controls. Run the generate script to propagate types.</p> <p>Config Warning</p> <p>Field constraints in Pydantic (Field(..., ge=..., le=...)) are enforced at load time. Invalid config will fail to start.</p> <p>Important</p> <p>The field <code>repo_id</code> remains in APIs for backward compatibility. Treat it as <code>corpus_id</code> in documentation.</p> Collapsible: What belongs in tribrid_config_model.py <ul> <li>All thresholds, weights, and booleans that control runtime behavior</li> <li>Feature flags</li> <li>Model selection defaults</li> </ul>"},{"location":"configuration/#configuration-overview-table","title":"Configuration overview table","text":"Section Example fields Purpose indexing indexing.chunk_size, indexing.bm25_tokenizer Controls how chunking and BM25 are performed retrieval retrieval.vector_k, retrieval.sparse_limit Fine-tunes search budgets and limits fusion fusion.vector_weight, fusion.sparse_weight, fusion.rrf_k_div Weights and fusion algorithm parameters reranker reranker.enabled, reranker.model, reranker.top_k Controls training and runtime reranker behavior graph graph.max_hops, graph.community_min_size Controls graph traversal and community detection"},{"location":"configuration/#example-configuration-snippets","title":"Example configuration snippets","text":"<pre><code>flowchart LR\n    config_file[tribrid_config_model.py] --&gt; gen_ts[generate_types.py]\n    gen_ts --&gt; web_types[web/src/types/generated.ts]\n    web_types --&gt; frontend[UI Stores &amp; Hooks]</code></pre> PythoncurlTypeScript <pre><code>from server.models.tribrid_config_model import TriBridConfig\n\ncfg = TriBridConfig() # (1)\n# (2) Example: read a constrained field\nprint(cfg.retrieval.vector_k)\n</code></pre> <pre><code># Get current server config\ncurl -X GET \"http://localhost:8000/config\"\n</code></pre> <pre><code>// DO NOT write types by hand - import generated\nimport { TriBridConfig } from '../types/generated'\n\nconst cfg = useConfigStore().config as TriBridConfig // (1)\n</code></pre> <ol> <li>Config loads from server/models/tribrid_config_model.py</li> <li>Field constraints prevent invalid values</li> </ol>"},{"location":"configuration/#key-config-tables-selected-fields","title":"Key config tables (selected fields)","text":"Field Type Default Description retrieval.vector_k int 10 Number of vector neighbors returned retrieval.sparse_limit int 50 Max number of sparse results to fetch fusion.vector_weight float 1.0 Weight applied to vector results in fusion fusion.sparse_weight float 1.0 Weight applied to sparse results in fusion graph.max_hops int 2 Max number of hops for graph expansion reranker.enabled bool False Enable cross-encoder reranking"},{"location":"configuration/#models-source-of-truth","title":"Models source of truth","text":"File Purpose Where used data/models.json All LLM/embedding/reranker model definitions UI model pickers, cost calculator server/models/tribrid_config_model.py Runtime defaults for model selection Server config validation"},{"location":"configuration/#code-examples-update-config-via-api","title":"Code examples: update config via API","text":"PythoncurlTypeScript <pre><code># (1) Patch a config section\nimport requests\n\nresp = requests.patch('http://localhost:8000/config/retrieval', json={\"vector_k\": 20}) # (2)\nprint(resp.status_code)\n</code></pre> <pre><code>curl -X PATCH \"http://localhost:8000/config/retrieval\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"vector_k\":20}'\n</code></pre> <pre><code>// (1) Use generated types to form request\nimport { RetrievalConfig } from '../types/generated'\n\nconst payload: Partial&lt;RetrievalConfig&gt; = { vector_k: 20 }\nawait fetch('/api/config/retrieval', { method: 'PATCH', body: JSON.stringify(payload) })\n</code></pre> <ol> <li>Use typed payloads generated from Pydantic</li> <li> <p>Server validates constraints and returns errors for out-of-range values</p> </li> <li> <p> Add new config fields to tribrid_config_model.py</p> </li> <li> Run ++uv run scripts/generate_types.py++</li> <li> Update UI stores/hooks to consume generated types</li> </ol> Collapsible: Advanced topics <ul> <li>You can generate JSON schema from the Pydantic model for external validation.</li> <li>Use Field(..., ge=..., le=...) to lock ranges and default values.</li> </ul>"},{"location":"deploy/","title":"Deployment","text":"<ul> <li> <p> Docker Compose</p> <p>Postgres (pgvector) + Neo4j + TriBridRAG server</p> </li> <li> <p> Environment variables (.env)</p> <p>DB URIs, API keys, container memory</p> </li> <li> <p> Health &amp; Metrics</p> <p>/health and /metrics endpoints for readiness</p> </li> </ul> <p>Pro Tip</p> <p>Persist DB volumes outside the repo; set TRIBRID_DB_DIR to a stable absolute path.</p> <p>Security Warning</p> <p>Change default Neo4j passwords and do not expose DB ports to public networks.</p> <p>Critical</p> <p>Running with default secrets in production is insecure. Rotate keys and use secret stores.</p> Collapsible: Docker Compose summary <p>Example services:</p> <ul> <li>postgres: uses pgvector-enabled image</li> <li>neo4j: community or enterprise depending on env</li> <li>tribrid server: application server</li> </ul>"},{"location":"deploy/#docker-compose-excerpt","title":"Docker compose excerpt","text":"Service Image Ports Notes postgres pgvector/pgvector:pg16 5432 Stores embeddings + FTS neo4j neo4j:5.26.20-community 7474/7687 Graph DB for entity relationships <pre><code>flowchart LR\n    DockerCompose --&gt; Postgres\n    DockerCompose --&gt; Neo4j\n    DockerCompose --&gt; TriBridServer\n    Postgres --&gt; TriBridServer\n    Neo4j --&gt; TriBridServer</code></pre> PythoncurlTypeScript <pre><code># (1) Example health ping\nimport requests\n\nresp = requests.get('http://localhost:8000/health')\nprint(resp.json())\n</code></pre> <pre><code>curl http://localhost:8000/ready\n</code></pre> <pre><code>// (1) UI health check hook\nconst { ready } = useHealth()\n</code></pre> <ol> <li>Health endpoints report readiness and metrics</li> </ol>"},{"location":"deploy/#environment-variables-selected","title":"Environment variables (selected)","text":"Variable Purpose Example POSTGRES_HOST Postgres host localhost POSTGRES_PORT Postgres port 5432 POSTGRES_DB Database name tribrid_rag POSTGRES_USER DB user postgres POSTGRES_PASSWORD DB password NEO4J_URI Neo4j connection URI bolt://localhost:7687 NEO4J_USER Neo4j user neo4j NEO4J_PASSWORD Neo4j password"},{"location":"deploy/#startup-checklist","title":"Startup checklist","text":"<ul> <li> Set .env values</li> <li> Start Docker: ++docker compose up -d++</li> <li> Verify ++/health++ and ++/ready++ endpoints</li> <li> Index at least one corpus</li> </ul> Collapsible: Troubleshooting <ul> <li>If Postgres fails: check volumes and POSTGRES_PASSWORD</li> <li>If Neo4j fails: increase heap via NEO4J_HEAP_MAX and NEO4J_PAGECACHE</li> </ul>"},{"location":"glossary/","title":"Glossary","text":"<ul> <li> <p> Glossary</p> <p>Key terms from data/glossary.json</p> </li> <li> <p> Infrastructure Terms</p> <p>Postgres pgvector URL, Neo4j URI, Table names</p> </li> <li> <p> Retrieval Terms</p> <p>vector_k, fusion weights, chunk_summaries</p> </li> </ul> <p>Information</p> <p>The complete glossary is sourced from data/glossary.json. UI tooltips derive from this file.</p> <p>Pro Tip</p> <p>Use glossary terms in UI via the TooltipIcon component to keep definitions consistent.</p> <p>Note</p> <p>Do not duplicate glossary definitions in UI code\u2014use the source file for single source of truth.</p> Collapsible: Example terms <p>Selected entries from data/glossary.json are shown below.</p> Term Key Definition PostgreSQL pgvector URL POSTGRES_URL Connection URL for PostgreSQL with pgvector extension. Format: postgresql://user:pass@host:port/db Neo4j Connection URI NEO4J_URI Connection URI for Neo4j. Format: bolt://host:7687 or neo4j://host:7687 Active Repository REPO Logical repository name for routing and indexing (repo_id / corpus_id) Table Name TABLE_NAME Optional override for pgvector table name, defaults to code_chunks_{REPO} <pre><code>flowchart LR\n    data_glossary[data/glossary.json] --&gt; UI_Tooltip[TooltipIcon]\n    UI_Tooltip --&gt; Frontend[Help text &amp; Glossary tab]</code></pre> PythoncurlTypeScript <pre><code># (1) Load glossary JSON\nimport json\nwith open('data/glossary.json') as f:\n    g = json.load(f)\nprint(g['terms'][0]['term'])\n</code></pre> <pre><code># (1) Serve glossary via endpoint\ncurl http://localhost:8000/glossary\n</code></pre> <pre><code>import glossary from '../data/glossary.json'\n// (1) Render TooltipIcon with definition\n&lt;TooltipIcon term={glossary.terms[0]} /&gt;\n</code></pre> <ol> <li> <p>The glossary is the authoritative source for tooltips and UI help</p> </li> <li> <p> Use glossary terms in UI components</p> </li> <li> Keep data/glossary.json updated when adding terms</li> </ol> Collapsible: Adding a glossary term <ol> <li>Add the term to data/glossary.json with key and definition</li> <li>Commit and deploy</li> <li>UI will surface term via TooltipIcon automatically</li> </ol>"},{"location":"indexing/","title":"Indexing","text":"<ul> <li> <p> Chunking &amp; Embedding</p> <p>Chunker, Embedder, Summarizer components</p> </li> <li> <p> FileLoader &amp; Patterns</p> <p>FileLoader converts .gitignore patterns to gitwildmatch</p> </li> <li> <p> Graph Builder</p> <p>Extract entities and relationships to Neo4j</p> </li> </ul> <p>Pro Tip</p> <p>Tune chunk_size and overlap in config to suit your LLM context window (see data/models.json for model contexts).</p> <p>Important</p> <p>The Embedder is deterministic by default; provider-backed embedders are supported by configuration and models.json.</p> <p>Data Warning</p> <p>Reindexing can be IO and CPU intensive. Use force_reindex selectively and monitor IndexStatus endpoints.</p> Collapsible: Indexing flow <p>Indexing typically follows: FileLoader -&gt; Chunker -&gt; Embedder -&gt; Postgres storage -&gt; GraphBuilder</p> <pre><code>flowchart TD\n    Files[Files on disk] --&gt; Loader[FileLoader]\n    Loader --&gt; Chunker[Chunker]\n    Chunker --&gt; Embedder[Embedder]\n    Embedder --&gt; Postgres[(Postgres Index)]\n    Chunker --&gt; Summarizer[ChunkSummarizer]\n    Summarizer --&gt; Postgres\n    Postgres --&gt; GraphBuilder[GraphBuilder]\n    GraphBuilder --&gt; Neo4j[(Neo4j Graph)]</code></pre> Step Component Output 1 FileLoader Normalized file list (excludes via patterns) 2 Chunker Chunks with token counts and metadata 3 Embedder Embedding vectors for chunks 4 ChunkSummarizer Short summaries (chunk_summaries) 5 GraphBuilder Entities &amp; relationships stored in Neo4j PythoncurlTypeScript <pre><code>from server.indexing.chunker import Chunker\nfrom server.indexing.embedder import Embedder\n\nchunker = Chunker()\nembedder = Embedder()\n\nchunks = chunker.chunk_file('src/main.py') # (1)\nembeddings = embedder.embed_chunks(chunks) # (2)\n</code></pre> <pre><code>curl -X POST \"http://localhost:8000/index\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"repo_id\":\"my_corpus\",\"repo_path\":\"/path/to/repo\"}'\n</code></pre> <pre><code>import { IndexRequest } from '../types/generated'\n\nconst req: IndexRequest = { repo_id: 'my_corpus', repo_path: '/path' }\nawait fetch('/api/index', { method: 'POST', body: JSON.stringify(req) })\n</code></pre> <ol> <li>Chunker splits file into manageable pieces with start/end lines</li> <li>Embedder creates embeddings that are stored in Postgres</li> </ol>"},{"location":"indexing/#chunk-summaries-ui-term-chunk_summaries","title":"Chunk summaries (UI term: chunk_summaries)","text":"Field Description chunk_id Unique id for chunk summary Short AI-generated text summary token_count Token budget used for embedding <ul> <li> Validate file inclusion patterns</li> <li> Monitor IndexStatus endpoints for progress</li> <li> Periodically rebuild vocabulary preview (VocabPreviewResponse)</li> </ul> Collapsible: Best practices <ul> <li>Use consistent embedding models; changing models requires reindexing</li> <li>Keep chunk sizes aligned with model context limits (see data/models.json)</li> </ul>"},{"location":"assets/images/","title":"Screenshots Guide","text":""},{"location":"assets/images/#how-to-add-screenshots-to-docs","title":"How to Add Screenshots to Docs","text":"<ol> <li>Take screenshots of the TriBridRAG UI at http://localhost:5175/</li> <li>Save them to this directory with descriptive names:</li> <li><code>rag-config-interface.png</code> - RAG tab with fusion weights</li> <li><code>search-results.png</code> - Search interface with results</li> <li><code>graph-visualization.png</code> - Neo4j graph view</li> <li><code>model-selector.png</code> - Model picker interface</li> <li> <p><code>cost-calculator.png</code> - Cost tracking dashboard</p> </li> <li> <p>Add to docs using this format:</p> </li> </ol> <pre><code>![RAG Configuration Interface](./assets/images/rag-config-interface.png)\n*Configure fusion weights, reranking, and search parameters through the intuitive UI*\n</code></pre> <p>Or with lightbox zoom:</p> <pre><code>&lt;figure markdown&gt;\n  ![RAG Configuration](./assets/images/rag-config-interface.png){ loading=lazy }\n  &lt;figcaption&gt;Configure tri-brid fusion weights and reranking options&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre>"},{"location":"assets/images/#recommended-screenshots","title":"Recommended Screenshots","text":""},{"location":"assets/images/#1-rag-configuration-tab","title":"1. RAG Configuration Tab","text":"<ul> <li>Show the sliders for fusion weights (vector/sparse/graph)</li> <li>Reranker dropdown</li> <li>Top-K settings</li> <li>Confidence thresholds</li> </ul>"},{"location":"assets/images/#2-search-interface","title":"2. Search Interface","text":"<ul> <li>Query input</li> <li>Results panel with chunks</li> <li>Relevance scores</li> <li>Citation links</li> </ul>"},{"location":"assets/images/#3-graph-visualization","title":"3. Graph Visualization","text":"<ul> <li>Neo4j entities and relationships</li> <li>Community detection</li> <li>Entity details panel</li> </ul>"},{"location":"assets/images/#4-model-management","title":"4. Model Management","text":"<ul> <li>Model picker dropdown (embedding/generation/reranker)</li> <li>Provider selection</li> <li>Cost calculator</li> <li>Context window info</li> </ul>"},{"location":"assets/images/#5-glossarytooltips","title":"5. Glossary/Tooltips","text":"<ul> <li>Show the tooltip system with definitions</li> <li>Searchable glossary tab</li> </ul>"},{"location":"assets/images/#screenshot-tips","title":"Screenshot Tips","text":"<ul> <li>Use dark mode (matches docs theme)</li> <li>Capture at ~1920x1080 or similar</li> <li>Show real data/results (not empty states)</li> <li>Highlight key features with cursor or annotations</li> <li>Keep UI clean (close unnecessary panels)</li> </ul>"},{"location":"retrieval/overview/","title":"Retrieval","text":"<ul> <li> <p> Vector Search (pgvector)</p> <p>Semantic similarity using stored embeddings</p> </li> <li> <p> Sparse Search (FTS/BM25)</p> <p>Exact matches and identifier lookup via Postgres FTS</p> </li> <li> <p> Graph Search (Neo4j)</p> <p>Entity traversal, community context, and hops-based expansion</p> </li> </ul> <p>Pro Tip</p> <p>Use vector search for conceptual queries and sparse search for code identifiers or exact phrases.</p> <p>Implementation Note</p> <p>TriBridFusion orchestrates parallel calls to VectorRetriever, SparseRetriever, and GraphRetriever.</p> <p>Performance Warning</p> <p>Large corpora may need Postgres and Neo4j tuning. Adjust PG connection pools and Neo4j heap sizes in environment.</p> Collapsible: Retrieval quick facts <ul> <li>Fusion runs the three retrievers in parallel and merges results by configurable weights</li> <li>Reranking is optional and controlled by the reranker configuration</li> </ul>"},{"location":"retrieval/overview/#retriever-responsibilities","title":"Retriever responsibilities","text":"Retriever Purpose Primary file Vector Semantic similarity via pgvector server/retrieval/vector.py Sparse BM25 &amp; FTS for precise matching server/retrieval/sparse.py Graph Context expansion via Neo4j traversal server/retrieval/graph.py <pre><code>flowchart LR\n    Query --&gt; Vector[VectorRetriever]\n    Query --&gt; Sparse[SparseRetriever]\n    Query --&gt; Graph[GraphRetriever]\n    Vector --&gt; Fusion\n    Sparse --&gt; Fusion\n    Graph --&gt; Fusion\n    Fusion --&gt; Results</code></pre> PythoncurlTypeScript <pre><code>def fusion_search(query: str, repo_id: str): # (1)\n    # (2) Run retrievers in parallel\n    vector_task = vector.search(query, repo_id)\n    sparse_task = sparse.search(query, repo_id)\n    graph_task = graph.search(query, repo_id)\n    # (3) fusion merges results\n    fused = fusion.fuse([vector_task, sparse_task, graph_task])\n    return fused\n</code></pre> <pre><code>curl -X POST \"http://localhost:8000/search\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\":\"init db connection\",\"repo_id\":\"my_corpus\"}'\n</code></pre> <pre><code>import { SearchResponse } from '../types/generated' // (1)\n\nasync function fetchSearch(query: string, repoId: string): Promise&lt;SearchResponse&gt; { // (2)\n  const res = await fetch('/api/search', { method: 'POST', body: JSON.stringify({ query, repo_id: repoId }) })\n  return res.json()\n}\n</code></pre> <ol> <li>Function entry types and contract</li> <li>Parallel retrieval and fusion</li> <li>Optional rerank step occurs after fusion</li> </ol>"},{"location":"retrieval/overview/#graph-expansion-patterns","title":"Graph expansion patterns","text":"Strategy Use case Config field Max hops Short context expansion graph.max_hops Community Bring related entities graph.community_min_size Attribute filter Limit by node label graph.allowed_labels"},{"location":"retrieval/overview/#reranker","title":"Reranker","text":"<p>Information</p> <p>The reranker (cross-encoder) is an optional component. Training utilities and triplet mining exist under server/retrieval/learning.py and server/api/reranker.py.</p> <pre><code>sequenceDiagram\n    participant Fusion\n    participant Reranker\n    Fusion-&gt;&gt;Reranker: candidates\n    Reranker--&gt;&gt;Fusion: scored_ranked\n    Fusion--&gt;&gt;Client: final_results</code></pre> <ul> <li> Verify embedding model selection in models.json</li> <li> If using provider embeddings, ensure API keys are set</li> </ul> Collapsible: Troubleshooting <ul> <li>If vector results are poor: re-embed with updated model or increase chunk context.</li> <li>If sparse fails to find identifiers: regenerate FTS tokenizer or stemmer settings in config.</li> </ul>"}]}