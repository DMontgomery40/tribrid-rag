{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#tribridrag-documentation","title":"TriBridRAG Documentation","text":"<ul> <li> <p> Tri-brid Retrieval</p> <p>Parallel Vector (pgvector), Sparse (PostgreSQL FTS/BM25), and Graph (Neo4j) search fused with configurable strategies.</p> </li> <li> <p> Pydantic Is The Law</p> <p>All configuration and API shapes come from <code>server/models/tribrid_config_model.py</code>. TypeScript types are generated \u2014 never hand-written.</p> </li> <li> <p> PostgreSQL Backbone</p> <p>Chunk storage, embeddings, pgvector indexing, and FTS live in one database. No separate vector DB to manage.</p> </li> <li> <p> Knowledge Graph</p> <p>Neo4j stores entities and relationships; graph traversal augments retrieval for cross-file context.</p> </li> <li> <p> API-First</p> <p>FastAPI endpoints for indexing, retrieval, config, models, graph, health, and metrics.</p> </li> <li> <p> Operational Safety</p> <p>Field constraints, health/readiness, Prometheus metrics, and cost-aware models.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Read This First</p> <p>TriBridRAG is strictly Pydantic-first. If a field or feature is not in <code>tribrid_config_model.py</code>, it does not exist. Add it there, regenerate TypeScript types, then build the rest.</p> <p>Implementation Note \u2014 repo_id vs corpus_id</p> <p>The API still uses <code>repo_id</code> for historical reasons. Treat it as the corpus identifier. Many Pydantic models accept both via <code>validation_alias</code>, and serialize as <code>corpus_id</code>.</p> <p>Security Warning \u2014 Secrets and DB Access</p> <p>Ensure <code>.env</code> is not committed. Limit database exposure to trusted networks. Use strong passwords for PostgreSQL and Neo4j. Rotate API keys regularly.</p>"},{"location":"#what-tribridrag-does","title":"What TriBridRAG Does","text":"<p>TriBridRAG executes three independent retrieval methods in parallel and fuses them into a single result list that can optionally be reranked with a cross-encoder. All behavior is controlled by the Pydantic configuration model.</p> Feature Description Status Vector Search Dense similarity via pgvector in PostgreSQL \u2705 Active Sparse Search PostgreSQL FTS/BM25 for exact terms, identifiers \u2705 Active Graph Search Neo4j traversal to follow entities/relations \u2705 Active Fusion Weighted/reciprocal-rank fusion of sources \u2705 Active Reranker Optional cross-encoder reranking \u2705 Active"},{"location":"#end-to-end-retrieval-flow","title":"End-to-End Retrieval Flow","text":"<pre><code>flowchart LR\n    Q[Query] --&gt; V[\"Vector Search\\npgvector\"]\n    Q --&gt; S[\"Sparse Search\\nPostgreSQL FTS/BM25\"]\n    Q --&gt; G[\"Graph Search\\nNeo4j\"]\n    V --&gt; F[Fusion Layer]\n    S --&gt; F\n    G --&gt; F\n    F --&gt; R[Optional Reranker]\n    R --&gt; O[Results]\n    F --&gt; O</code></pre>"},{"location":"#quickstart-run-index-search","title":"Quickstart \u2014 Run, Index, Search","text":"<ul> <li> Configure environment (.env)</li> <li> Launch services with Docker Compose</li> <li> Index a corpus</li> <li> Search via API</li> <li> Tune fusion weights</li> <li> Enable reranking if needed</li> </ul> <p>Use Ctrl+C to stop local uvicorn or Docker Tail sessions.</p> PythoncurlTypeScript <pre><code>import httpx\n\nBASE = \"http://localhost:8000\"\n\n# 1) Trigger indexing of a corpus (1)\nreq = {\n    \"corpus_id\": \"tribrid\",  # repo_id alias is also accepted (2)\n    \"repo_path\": \"/path/to/your/codebase\",\n    \"force_reindex\": False,\n}\nr = httpx.post(f\"{BASE}/index\", json=req)\nr.raise_for_status()\n\n# 2) Poll status\nstatus = httpx.get(f\"{BASE}/index/status\", params={\"corpus_id\": \"tribrid\"}).json()\nprint(status)\n\n# 3) Search (parallel vector/sparse/graph with fusion -&gt; optional rerank) (3)\npayload = {\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"How does the chunker split Python files?\",\n    \"top_k\": 8,\n    \"enable_reranker\": False,\n}\nres = httpx.post(f\"{BASE}/search\", json=payload).json()\nfor m in res[\"results\"]:\n    print(m[\"file_path\"], m[\"score\"])  # fused score\n</code></pre> <pre><code>BASE=http://localhost:8000\n\n# (1) Start indexing\ncurl -sS -X POST \"$BASE/index\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"repo_path\": \"/path/to/your/codebase\",\n    \"force_reindex\": false\n  }'\n\n# (2) Status\ncurl -sS \"$BASE/index/status?corpus_id=tribrid\" | jq .\n\n# (3) Search\ncurl -sS -X POST \"$BASE/search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"How does the chunker split Python files?\",\n    \"top_k\": 8,\n    \"enable_reranker\": false\n  }' | jq '.results[] | {file_path, score}'\n</code></pre> <pre><code>// (1) Use generated types \u2014 do not hand-write interfaces\nimport { IndexRequest } from \"./web/src/types/generated\"; // (2)\n\nasync function search() {\n  const base = \"http://localhost:8000\";\n\n  const indexReq: IndexRequest = {\n    corpus_id: \"tribrid\", // repo_id alias is accepted server-side\n    repo_path: \"/path/to/your/codebase\",\n    force_reindex: false,\n  };\n\n  await fetch(`${base}/index`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(indexReq),\n  });\n\n  const res = await fetch(`${base}/search`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({ corpus_id: \"tribrid\", query: \"chunker\", top_k: 8 }),\n  });\n  const data = await res.json();\n  console.log(data.results.map((m: any) =&gt; [m.file_path, m.score])); // (3)\n}\n</code></pre> <ol> <li>Index start: pushes files through loader \u2192 chunker \u2192 embedder \u2192 graph builder</li> <li>repo_id/corpus_id aliasing is enforced in Pydantic with <code>AliasChoices</code></li> <li>Search runs vector/sparse/graph in parallel \u2192 fusion \u2192 optional reranker</li> </ol> <p>Success \u2014 One Config To Rule Them All</p> <p>Every behavior above is configured by the Pydantic model. Toggle fusion weights, graph hop limits, top_k, and reranker directly in config.</p>"},{"location":"#configuration-and-operational-knobs","title":"Configuration and Operational Knobs","text":"Area Key Examples Description Retrieval <code>retrieval.vector.top_k</code>, <code>retrieval.sparse.top_k</code>, <code>retrieval.graph.max_hops</code> Controls depth and breadth per retriever Fusion <code>fusion.strategy</code>, <code>fusion.weights</code>, <code>fusion.rrf_k_div</code> Controls score fusion behavior Reranker <code>reranker.enabled</code>, <code>reranker.model</code> Optional cross-encoder reranking Indexing <code>indexing.chunker.strategy</code>, <code>indexing.embedder.model</code> Chunking and embeddings <pre><code>flowchart TB\n    CFG[\"Pydantic Config\\nTriBridConfig\"] --&gt; GEN[\"generate_types.py\\nTypescript types\"]\n    GEN --&gt; STO[Zustand Stores]\n    STO --&gt; HOOKS[React Hooks]\n    HOOKS --&gt; UI[Components]\n    CFG --&gt; API[FastAPI Schemas]</code></pre> <p>Critical \u2014 Do Not Hand-Write API Types</p> <p>All frontend types are generated from Pydantic. Run <code>uv run scripts/generate_types.py</code> after any config model changes.</p> <p>Configuration API Retrieval</p> Advanced Topics <ul> <li>Fusion math: supports weighted linear combination and Reciprocal Rank Fusion with configurable <code>rrf_k_div</code>.</li> <li>Retrieval cache: cache keys include <code>corpus_id</code>, <code>query</code>, and relevant config hashes for correctness.</li> <li>Failure isolation: vector, sparse, and graph paths are resilient; a failure in one path degrades gracefully without crashing the whole search.</li> </ul> <ol> <li> <p>Costs are derived from <code>data/models.json</code> and displayed in the UI.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/","title":"API","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<ul> <li> <p> FastAPI Endpoints</p> <p>Clean endpoints for config, indexing, retrieval, graph, models, keywords, reranker, and health.</p> </li> <li> <p> Schema by Pydantic</p> <p>Request/response models are defined in Pydantic. The frontend imports generated TypeScript types.</p> </li> <li> <p> Secrets Check</p> <p>Validate configured API keys and DB connections via <code>/secrets/check</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Inspect Schemas</p> <p>Each endpoint returns Pydantic-driven shapes. Prefer querying <code>/config</code> first to align UI interactions with actual server capabilities.</p> <p>HTTP Conventions</p> <ul> <li>JSON requests/responses</li> <li>Errors via standard HTTP status codes with <code>detail</code></li> <li>Streaming responses for long-running operations use <code>StreamingResponse</code></li> </ul> <p>Rate &amp; Resource Limits</p> <p>Reranking and keyword generation incur model usage and cost. Control with config and model selection.</p>"},{"location":"api/#endpoint-inventory","title":"Endpoint Inventory","text":"Area Route Method Function Config <code>/config</code> GET <code>get_config</code> Config <code>/config/reset</code> POST <code>reset_config</code> Config <code>/config/{section}</code> PATCH Sectional patch, e.g., <code>fusion</code> Secrets <code>/secrets/check</code> GET <code>check_secrets</code> Index <code>/index</code> POST Start indexing Index <code>/index/status</code> GET <code>IndexStatus</code> for corpus Index <code>/index/stats</code> GET <code>IndexStats</code> summary Search <code>/search</code> POST Tri-brid retrieval + fusion (+reranker) Graph <code>/graph/{corpus_id}/entities</code> GET List entities Graph <code>/graph/{corpus_id}/entity/{entity_id}</code> GET Entity details Graph <code>/graph/{corpus_id}/entity/{entity_id}/relationships</code> GET Relationships Graph <code>/graph/{corpus_id}/entity/{entity_id}/neighbors</code> GET 1-hop neighbors Graph <code>/graph/{corpus_id}/community/{community_id}/members</code> GET Members Graph <code>/graph/{corpus_id}/community/{community_id}/subgraph</code> GET Subgraph Models <code>/models/by-type/{component_type}</code> GET List models for component Models <code>/models/providers</code> GET All providers Models <code>/models/providers/{provider}</code> GET Models by provider Chunk Summaries <code>/chunk_summaries</code> GET List summaries Chunk Summaries <code>/chunk_summaries/build</code> POST Build summaries Keywords <code>/keywords/generate</code> POST Generate keywords Reranker <code>/reranker/status</code> GET Status Reranker <code>/reranker/info</code> GET Info Reranker <code>/reranker/mine</code> POST Mine triplets Reranker <code>/reranker/train</code> POST Train Reranker <code>/reranker/evaluate</code> POST Evaluate Reranker <code>/reranker/logs/count</code> GET Logs count Reranker <code>/reranker/triplets/count</code> GET Triplets count Reranker <code>/reranker/costs</code> GET Cost report Health <code>/health</code> GET Liveness Health <code>/ready</code> GET Readiness Health <code>/metrics</code> GET Prometheus Docker <code>/docker/status</code> GET Runtime info Docker <code>/docker/{container}/restart</code> POST Restart container Docker <code>/docker/{container}/logs</code> GET Container logs <pre><code>flowchart TB\n    CLI[Client] --&gt; API[FastAPI]\n    API --&gt; PC[Postgres Client]\n    API --&gt; NC[Neo4j Client]\n    API --&gt; CFG[Pydantic Models]\n    API --&gt; ML[Model Catalog]\n    PC --&gt; DB[(PostgreSQL)]\n    NC --&gt; GDB[(Neo4j)]</code></pre>"},{"location":"api/#example-config-roundtrip","title":"Example: Config Roundtrip","text":"PythoncurlTypeScript <pre><code>import httpx\n\nbase = \"http://localhost:8000\"\ncfg = httpx.get(f\"{base}/config\").json()          # (1)\n\n# Enable reranker\nhttpx.patch(f\"{base}/config/reranker\", json={\"enabled\": True})  # (2)\n\n# Check secrets (API keys, DBs) (3)\nprint(httpx.get(f\"{base}/secrets/check\").json())\n</code></pre> <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/config\" | jq . # (1)\ncurl -sS -X PATCH \"$BASE/config/reranker\" -H 'Content-Type: application/json' -d '{\"enabled\": true}' | jq . # (2)\ncurl -sS \"$BASE/secrets/check\" | jq . # (3)\n</code></pre> <pre><code>import { TriBridConfig } from \"./web/src/types/generated\";\n\nasync function check(): Promise&lt;void&gt; {\n  const cfg: TriBridConfig = await (await fetch(\"/config\")).json(); // (1)\n  await fetch(\"/config/reranker\", { method: \"PATCH\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify({ enabled: true }) }); // (2)\n  const secrets = await (await fetch(\"/secrets/check\")).json(); // (3)\n  console.log(secrets);\n}\n</code></pre> <ol> <li>All shapes defined by Pydantic</li> <li>Patch one section with validation</li> <li>Validate secrets and DB connectivity</li> </ol> <p>Model Catalog Endpoint</p> <p>The UI must populate model selectors from <code>/models/...</code>. No hard-coded lists.</p>"},{"location":"api/#graph-api-example","title":"Graph API Example","text":"PythoncurlTypeScript <pre><code>import httpx\nbase = \"http://localhost:8000\"\n\nentities = httpx.get(f\"{base}/graph/tribrid/entities\").json()\nnode = httpx.get(f\"{base}/graph/tribrid/entity/{entities[0]['id']}\").json()\nrels = httpx.get(f\"{base}/graph/tribrid/entity/{entities[0]['id']}/relationships\").json()\nprint(node, len(rels))\n</code></pre> <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/graph/tribrid/entities\" | jq '.[0]'\n</code></pre> <pre><code>async function firstEntity(corpus: string) {\n  const ents = await (await fetch(`/graph/${corpus}/entities`)).json();\n  const id = ents[0].id;\n  const rels = await (await fetch(`/graph/${corpus}/entity/${id}/relationships`)).json();\n  console.log(id, rels.length);\n}\n</code></pre> <p>Do Not Transform Shapes</p> <p>If the frontend needs different <code>Entity</code> shapes, change the Pydantic models that define these endpoints and regenerate types.</p> Streaming Search <p>Some endpoints may stream responses for long operations. Use backpressure-aware clients when consuming <code>text/event-stream</code> or chunked JSON.</p>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture","title":"Architecture","text":"<ul> <li> <p> Tri-Path Retrieval</p> <p>Vector, Sparse, and Graph retrievers run concurrently for maximum recall.</p> </li> <li> <p> Fusion Layer</p> <p>Weighted fusion or RRF unifies heterogeneous scores into one ranking.</p> </li> <li> <p> Optional Reranker</p> <p>Cross-encoder can refine the fused list by understanding local context.</p> </li> <li> <p> Pydantic-Orchestrated</p> <p>All engine parameters are Pydantic fields with constraints and defaults.</p> </li> <li> <p> FastAPI Surface</p> <p>Clean endpoints for indexing, retrieval, graph queries, and system health.</p> </li> <li> <p> Observability</p> <p>Readiness + Prometheus metrics + PostgreSQL exporter.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Concurrency</p> <p>TriBridRAG parallelizes retrievers using asyncio. Keep DB connection pools sized adequately to avoid I/O starvation under concurrency.</p> <p>Implementation Note \u2014 Failure Modes</p> <p>Each retriever is wrapped so failures degrade that path only. Fusion runs on the subset that succeeded, and <code>metadata.partial</code> flags can indicate a degraded answer.</p> <p>Graph Availability</p> <p>If Neo4j is unavailable, retrieval still works with vector and sparse results. Ensure fallback behavior is tested for your deployment.</p>"},{"location":"architecture/#system-diagram","title":"System Diagram","text":"<pre><code>flowchart LR\n    subgraph Client\n      U[User / UI / API Client]\n    end\n\n    U --&gt;|HTTP| A[FastAPI]\n    A --&gt;|async| V[\"VectorRetriever\\nPostgres+pgvector\"]\n    A --&gt;|async| S[\"SparseRetriever\\nPostgres FTS/BM25\"]\n    A --&gt;|async| G[\"GraphRetriever\\nNeo4j\"]\n\n    V --&gt; F[Fusion]\n    S --&gt; F\n    G --&gt; F\n\n    F --&gt;|optional| R[Cross-Encoder Reranker]\n    F --&gt; O[Results]\n    R --&gt; O\n\n    subgraph Storage\n      P[(PostgreSQL)]\n      N[(Neo4j)]\n    end\n\n    V &lt;--&gt; P\n    S &lt;--&gt; P\n    G &lt;--&gt; N</code></pre>"},{"location":"architecture/#layer-responsibilities","title":"Layer Responsibilities","text":"Layer Module Responsibilities Key Config Vector <code>server/retrieval/vector.py</code> Dense search via pgvector <code>retrieval.vector.*</code> Sparse <code>server/retrieval/sparse.py</code> FTS/BM25 on chunks <code>retrieval.sparse.*</code> Graph <code>server/retrieval/graph.py</code> Entity traversal, context expansion <code>retrieval.graph.*</code> Fusion <code>server/retrieval/fusion.py</code> Merge scores (weighted or RRF) <code>fusion.*</code> Reranker <code>server/retrieval/rerank.py</code> Cross-encoder ranking <code>reranker.*</code>"},{"location":"architecture/#hot-path-example","title":"Hot Path Example","text":"PythoncurlTypeScript <pre><code>from server.retrieval.fusion import TriBridFusion\n\nasync def search(corpus_id: str, query: str, cfg):\n    fusion = TriBridFusion(cfg)                     # (1)\n    results = await fusion.search(corpus_id, query) # (2)\n    if cfg.reranker.enabled:\n        from server.retrieval.rerank import Reranker\n        rr = Reranker(cfg)\n        results = await rr.rerank(query, results)  # (3)\n    return results\n</code></pre> <pre><code># High-level: Fusion + optional reranker is server-controlled by config.\ncurl -sS -X POST http://localhost:8000/search \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"database client architecture\",\n    \"top_k\": 10,\n    \"enable_reranker\": true\n  }' | jq .\n</code></pre> <pre><code>import { SearchRequest, SearchResponse } from \"./web/src/types/generated\";\n\nexport async function triSearch(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const resp = await fetch(\"/search\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(req),\n  });\n  return await resp.json();\n}\n</code></pre> <ol> <li><code>TriBridFusion</code> encapsulates running vector/sparse/graph in parallel</li> <li>Returns fused results, with per-source metadata for auditing</li> <li>Optional reranking pass</li> </ol> <p>Separation of Concerns</p> <p>The fusion layer is agnostic of storage details. Retrievers expose a common interface returning scored matches with provenance.</p>"},{"location":"architecture/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Use HNSW or IVFFlat pgvector indexes depending on corpus size and update frequency.</li> <li>Keep FTS indexes up to date after reindexing.</li> <li>Neo4j memory (heap/pagecache) should be tuned for graph traversal fan-out.</li> <li>Set Postgres and Neo4j connection pool sizes to match concurrency.</li> </ul> <pre><code>flowchart TB\n    subgraph \"Tuning Inputs\"\n      K[top_k]\n      W[weights]\n      RRF[rrf_k_div]\n      H[max_hops]\n    end\n\n    K --&gt; FUSION\n    W --&gt; FUSION\n    RRF --&gt; FUSION\n    H --&gt; GRAPH\n\n    GRAPH[GraphRetriever] --&gt; FUSION[Fusion]</code></pre> Advanced: Caching Strategy <ul> <li>Retrieval cache key: <code>corpus_id + query + retriever config hash</code>.</li> <li>Expiration controlled by config; invalidate on reindex or config change.</li> <li>Cache entries store per-retriever scores and feature vectors for analysis.</li> </ul>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration","title":"Configuration","text":"<ul> <li> <p> Single Source of Truth</p> <p><code>server/models/tribrid_config_model.py</code> defines every tunable parameter with Pydantic <code>Field()</code> constraints.</p> </li> <li> <p> Generated Types</p> <p>Run <code>uv run scripts/generate_types.py</code> to regenerate <code>web/src/types/generated.ts</code>. No hand-written types.</p> </li> <li> <p> Constraints Enforced</p> <p>Min/max ranges, enums, and defaults are enforced at load time with precise error messages.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Change Pydantic First</p> <p>Add fields to <code>tribrid_config_model.py</code>, regenerate TypeScript types, then wire through stores/hooks/components. Do not add UI controls first.</p> <p>Terminology \u2014 Corpus</p> <p>A corpus is any folder you index. The identifier is serialized as <code>corpus_id</code>, but for compatibility <code>repo_id</code> is accepted on input.</p> <p>Validation</p> <p>Invalid config values are rejected at load time. Respect <code>ge</code>, <code>le</code>, and <code>Literal</code> constraints or your server will refuse to start.</p>"},{"location":"configuration/#configuration-surfaces","title":"Configuration Surfaces","text":"<ul> <li><code>server/models/tribrid_config_model.py</code> \u2014 Pydantic models (authoritative)</li> <li><code>data/models.json</code> \u2014 Model catalog (pricing, context window)</li> <li><code>data/glossary.json</code> \u2014 Tooltip terms and categories</li> </ul> <pre><code>flowchart LR\n    P[tribrid_config_model.py] --&gt;|pydantic2ts| T[generated.ts]\n    T --&gt; S[Zustand Stores]\n    S --&gt; H[Hooks]\n    H --&gt; C[Components]\n    P --&gt; A[FastAPI Schemas]\n    A --&gt; UI[API Responses]</code></pre>"},{"location":"configuration/#key-sections-and-representative-fields","title":"Key Sections and Representative Fields","text":"Section Example Fields Description retrieval.vector <code>top_k</code>, <code>distance_metric</code>, <code>min_score</code> Dense search controls retrieval.sparse <code>top_k</code>, <code>use_bm25</code>, <code>tsquery_mode</code> Text search controls retrieval.graph <code>max_hops</code>, <code>edge_types</code>, <code>community_boost</code> Graph traversal fusion <code>strategy</code>, <code>weights</code>, <code>rrf_k_div</code> Fusion parameters reranker <code>enabled</code>, <code>model</code>, <code>batch_size</code> Cross-encoder settings indexing <code>chunker.strategy</code>, <code>embedder.model</code> Index pipeline knobs"},{"location":"configuration/#fusion-configuration","title":"Fusion Configuration","text":"Field Type Constraints Description <code>fusion.strategy</code> Literal[\"weighted\", \"rrf\"] required Fusion algorithm <code>fusion.weights.vector</code> float 0.0\u20132.0 Weight for vector scores <code>fusion.weights.sparse</code> float 0.0\u20132.0 Weight for sparse scores <code>fusion.weights.graph</code> float 0.0\u20132.0 Weight for graph scores <code>fusion.rrf_k_div</code> int 1\u2013200 RRF divisor constant"},{"location":"configuration/#graph-retrieval-configuration","title":"Graph Retrieval Configuration","text":"Field Type Constraints Description <code>retrieval.graph.max_hops</code> int 0\u20135 Traversal depth from seed entities <code>retrieval.graph.edge_types</code> list[str] optional Restrict traversal to specific relationships <code>retrieval.graph.expand_neighbors</code> bool default False Expand 1-hop neighbors for context"},{"location":"configuration/#reranker-configuration","title":"Reranker Configuration","text":"Field Type Constraints Description <code>reranker.enabled</code> bool default False Enable reranking stage <code>reranker.model</code> str must exist in models.json Reranker model id <code>reranker.batch_size</code> int 1\u2013128 Micro-batch size for scoring"},{"location":"configuration/#reading-and-updating-config-via-api","title":"Reading and Updating Config via API","text":"PythoncurlTypeScript <pre><code>import httpx\n\nbase = \"http://localhost:8000\"\n\n# Read full config (1)\ncfg = httpx.get(f\"{base}/config\").json()\n\n# Patch fusion weights (2)\npatch = {\"fusion\": {\"strategy\": \"weighted\", \"weights\": {\"vector\": 1.0, \"sparse\": 0.8, \"graph\": 0.6}}}\nr = httpx.patch(f\"{base}/config/fusion\", json=patch[\"fusion\"]).json()\n\n# Reset to defaults (3)\nhttpx.post(f\"{base}/config/reset\")\n</code></pre> <pre><code>BASE=http://localhost:8000\n\ncurl -sS \"$BASE/config\" | jq . # (1)\n\ncurl -sS -X PATCH \"$BASE/config/fusion\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"strategy\": \"weighted\", \"weights\": {\"vector\": 1.0, \"sparse\": 0.8, \"graph\": 0.6}}' | jq . # (2)\n\ncurl -sS -X POST \"$BASE/config/reset\" # (3)\n</code></pre> <pre><code>import { TriBridConfig } from \"./web/src/types/generated\";\n\nasync function loadConfig(): Promise&lt;TriBridConfig&gt; {\n  const r = await fetch(\"/config\");\n  return await r.json(); // (1)\n}\n\nasync function patchFusion() {\n  await fetch(\"/config/fusion\", {\n    method: \"PATCH\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({ strategy: \"weighted\", weights: { vector: 1.0, sparse: 0.8, graph: 0.6 } }),\n  }); // (2)\n}\n</code></pre> <ol> <li>The API returns the Pydantic-driven shape of the full config</li> <li>Partial patch by section is supported; validation is enforced</li> <li>Reset restores defaults compiled into the Pydantic model</li> </ol> <p>Do Not Write Adapters</p> <p>If the frontend needs a different shape, change the Pydantic model and regenerate types. Adapters are forbidden technical debt.</p> <pre><code>flowchart TB\n    U[User] --&gt; UI[\"Frontend\\n(generated.ts)\"]\n    UI --&gt; API[FastAPI /config]\n    API --&gt; P[Pydantic Models]\n    P --&gt; API\n    API --&gt; UI</code></pre> <ul> <li> Update Pydantic model first</li> <li> Run <code>uv run scripts/generate_types.py</code></li> <li> Update stores and hooks</li> <li> Use generated types in components</li> </ul> Examples of Field Constraints <ul> <li><code>Field(ge=0.0, le=1.0)</code> for progress fractions</li> <li><code>Literal[...]</code> for state enums like <code>\"idle\" | \"indexing\" | \"complete\" | \"error\"</code></li> <li><code>AliasChoices(\"repo_id\", \"corpus_id\")</code> to migrate naming safely</li> </ul>"},{"location":"database/","title":"Database","text":""},{"location":"database/#databases-and-storage","title":"Databases and Storage","text":"<ul> <li> <p> PostgreSQL + pgvector</p> <p>Single store for chunks, embeddings, and FTS/BM25 indexes.</p> </li> <li> <p> Neo4j Graph</p> <p>Entities and relationships power graph traversal and community queries.</p> </li> <li> <p> Operational Controls</p> <p>Connection pools, health checks, and exporters for metrics.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Co-locate Storage</p> <p>Use the provided Docker Compose to run Postgres and Neo4j locally with sane defaults and persistent volumes outside the repository.</p> <p>pgvector Index Choice</p> <p>Choose HNSW for high-recall and read-heavy workloads; IVFFlat for faster build times and stable performance on mid-size corpora.</p> <p>Neo4j Memory</p> <p>Set <code>NEO4J_HEAP_INIT</code>, <code>NEO4J_HEAP_MAX</code>, and <code>NEO4J_PAGECACHE</code> environment variables for large graphs to avoid GC thrash.</p>"},{"location":"database/#docker-compose-services","title":"Docker Compose Services","text":"Service Image Ports Data Volume Postgres <code>pgvector/pgvector:pg16</code> <code>${POSTGRES_PORT:-5432}:5432</code> <code>${TRIBRID_DB_DIR}/postgres:/var/lib/postgresql/data</code> Postgres Exporter <code>prometheuscommunity/postgres-exporter:latest</code> internal n/a Neo4j <code>${NEO4J_IMAGE:-neo4j:5.26.20-community}</code> <code>7687</code>, <code>7474</code> internal volume <pre><code>flowchart LR\n    Client --&gt; API\n    API --&gt; PG[(PostgreSQL + pgvector)]\n    API --&gt; NEO[(Neo4j)]\n    PG --&gt; EXP[Postgres Exporter]\n    EXP --&gt; PROM[Prometheus]</code></pre>"},{"location":"database/#environment-variables","title":"Environment Variables","text":"Key Description <code>POSTGRES_HOST</code> Hostname for PostgreSQL <code>POSTGRES_PORT</code> Port number <code>POSTGRES_DB</code> Database name <code>POSTGRES_USER</code> Username <code>POSTGRES_PASSWORD</code> Password <code>NEO4J_URI</code> <code>bolt://host:7687</code> or <code>neo4j://host:7687</code> <code>NEO4J_USER</code> Neo4j username <code>NEO4J_PASSWORD</code> Neo4j password <code>TRIBRID_DB_DIR</code> Host directory for DB bind-mounts <code>NEO4J_HEAP_INIT</code>, <code>NEO4J_HEAP_MAX</code>, <code>NEO4J_PAGECACHE</code> Neo4j memory tuning"},{"location":"database/#connectivity-checks","title":"Connectivity Checks","text":"PythoncurlTypeScript <pre><code>import httpx\n\nbase = \"http://localhost:8000\"\nprint(httpx.get(f\"{base}/health\").json())  # (1)\nprint(httpx.get(f\"{base}/ready\").json())   # (2)\n</code></pre> <pre><code>curl -sS http://localhost:8000/health | jq .\ncurl -sS http://localhost:8000/ready | jq .\n</code></pre> <pre><code>async function readiness() {\n  const health = await (await fetch(\"/health\")).json(); // (1)\n  const ready = await (await fetch(\"/ready\")).json();   // (2)\n  console.log(health, ready);\n}\n</code></pre> <ol> <li>Liveness: server process up</li> <li>Readiness: DBs connected and ready to accept requests</li> </ol> <p>Index Footprint</p> <p>Use <code>DashboardIndexStatsResponse</code> to view <code>pgvector_index_bytes</code>, <code>bm25_index_bytes</code>, and <code>neo4j_store_bytes</code> per corpus.</p> <ul> <li> Use separate credentials per environment</li> <li> Restrict network access to DB services</li> <li> Enable backups for Postgres and Neo4j stores</li> </ul> Postgres Client <p><code>PostgresClient</code> manages connection pooling and ensures FTS + pgvector indexes exist per corpus table. It exposes <code>connect</code>, <code>disconnect</code>, and <code>close_shared_pools</code> for lifecycle control.</p>"},{"location":"deployment/","title":"Deployment","text":""},{"location":"deployment/#deployment","title":"Deployment","text":"<ul> <li> <p> Docker-First</p> <p>Compose stack for Postgres, Neo4j, exporter, and API.</p> </li> <li> <p> Configurable</p> <p>All behavior via Pydantic config and environment variables.</p> </li> <li> <p> Portable</p> <p>Works on local dev, CI, or container platforms.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Persistent Volumes</p> <p>Keep DB data outside the repo. Default bind-mount path is <code>../tribrid-rag-db/</code>. Override with <code>TRIBRID_DB_DIR</code> to point elsewhere.</p> <p>Environment Template</p> <p>Copy the provided environment configuration to <code>.env</code>, fill in DB credentials and API keys, and export it into your shell for local runs.</p> <p>Production Secrets</p> <p>Use a secret manager for API keys and DB credentials in production. Do not rely on <code>.env</code> files in containerized environments.</p>"},{"location":"deployment/#services-and-ports","title":"Services and Ports","text":"Service Port Purpose API (uvicorn) 8000 REST endpoints PostgreSQL 5432 Chunk + vector + FTS storage Neo4j Bolt 7687 Graph driver Neo4j Browser 7474 Admin UI <pre><code>flowchart LR\n    Dev[Developer] --&gt; Compose[Docker Compose]\n    Compose --&gt; API\n    Compose --&gt; Postgres\n    Compose --&gt; Neo4j\n    Postgres --&gt; Exporter</code></pre>"},{"location":"deployment/#bring-up","title":"Bring-Up","text":"<ul> <li> Create <code>.env</code> with DB creds and API keys</li> <li> <code>docker compose up -d</code></li> <li> <code>uv run scripts/generate_types.py</code></li> <li> Start API service</li> </ul> <p>Use Ctrl+C to stop foreground sessions.</p> PythoncurlTypeScript <pre><code>import subprocess, os\n\n# Generate types from Pydantic (1)\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)\n\n# Start FastAPI via uvicorn (2)\nos.system(\"uvicorn server.main:app --reload --port 8000\")  # (2)\n</code></pre> <pre><code># After containers are up:\ncurl -sS http://localhost:8000/ready | jq .  # (3)\n</code></pre> <pre><code>// Frontend dev typically proxies to :8000\n// Ensure generated.ts is present\nconsole.log(\"Ensure types generated and API ready at /ready\");\n</code></pre> <ol> <li>Generate TS types from Pydantic</li> <li>Run API server</li> <li>Validate readiness</li> </ol> <p>Monitoring</p> <p>Prometheus can scrape <code>/metrics</code> directly and <code>postgres-exporter</code> for DB metrics.</p> <pre><code>flowchart TB\n    Env[.env] --&gt; Compose\n    Pydantic --&gt; Types[generated.ts]\n    Types --&gt; UI\n    Compose --&gt; API\n    API --&gt; READY[\"/ready\"]</code></pre> Container Logs <p>Use <code>/docker/{container}/logs</code> to fetch current logs lines via API for basic troubleshooting when UI access is limited.</p>"},{"location":"frontend/","title":"Frontend","text":""},{"location":"frontend/#frontend-integration-and-types","title":"Frontend Integration and Types","text":"<ul> <li> <p> Generated Types Only</p> <p><code>web/src/types/generated.ts</code> is the only source for API interfaces.</p> </li> <li> <p> Zustand Stores</p> <p>Stores consume generated types; hooks expose typed accessors.</p> </li> <li> <p> Components</p> <p>Props derive from hooks; no custom interfaces without Pydantic ancestry.</p> </li> </ul> <p>Get started Configuration API</p> <p>Generate Early</p> <p>Run <code>uv run scripts/generate_types.py</code> before starting the frontend. Hot reload relies on correct types.</p> <p>Traceability</p> <p>Every UI element (slider, toggle, input) must map to a Pydantic field. Tooltips come from <code>data/glossary.json</code>.</p> <p>No Hand-Written Interfaces</p> <p>Interfaces like <code>interface SearchResponse { ... }</code> are forbidden. Import from <code>generated.ts</code>.</p>"},{"location":"frontend/#store-and-hook-structure","title":"Store and Hook Structure","text":"File Purpose <code>web/src/stores/useConfigStore.ts</code> Holds <code>TriBridConfig</code> and patch helpers <code>web/src/hooks/useConfig.ts</code> Read/update config <code>web/src/hooks/useFusion.ts</code> Fusion-related derived state <code>web/src/hooks/useReranker.ts</code> Reranker configuration and status <pre><code>flowchart TB\n    G[generated.ts] --&gt; S[stores]\n    S --&gt; H[hooks]\n    H --&gt; C[components]</code></pre>"},{"location":"frontend/#example-usage","title":"Example Usage","text":"PythoncurlTypeScript <pre><code># Backend reference: see dev/pydantic.md for generation step (1)\n</code></pre> <pre><code># Frontend consumes API; see api.md for routes (2)\n</code></pre> <pre><code>import { TriBridConfig, SearchResponse } from '../web/src/types/generated';\n\nfunction useConfig() {\n  // typed fetch\n  const [cfg, setCfg] = React.useState&lt;TriBridConfig | null&gt;(null);\n  React.useEffect(() =&gt; { fetch('/config').then(r =&gt; r.json()).then(setCfg); }, []); // (3)\n  return cfg;\n}\n</code></pre> <ol> <li>Types generation step is mandatory</li> <li>API is the contract; no local mocks of shapes</li> <li>Fetch returns the Pydantic-driven shape of config</li> </ol> <p>Tooltip Integration</p> <p><code>data/glossary.json</code> drives hover help via <code>TooltipIcon</code> in the UI. Keep term keys stable.</p> <ul> <li> Use generated types across stores, hooks, and components</li> <li> Remove any legacy custom interfaces</li> <li> Validate prop chains map back to Pydantic fields</li> </ul> <pre><code>flowchart LR\n    Glossary[data/glossary.json] --&gt; Tooltip[TooltipIcon]\n    Tooltip --&gt; UI</code></pre> Component Inventory <ul> <li><code>DockerStatusCard.tsx</code>, <code>HealthStatusCard.tsx</code> show system state</li> <li><code>RepoSelector.tsx</code> binds UI to <code>corpus_id</code></li> <li><code>RAGTab.tsx</code>, <code>GrafanaTab.tsx</code>, <code>AdminTab.tsx</code> orchestrate panels using typed hooks</li> </ul>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#glossary","title":"Glossary","text":"<ul> <li> <p> Centralized Terms</p> <p><code>data/glossary.json</code> drives all tooltips in the UI.</p> </li> <li> <p> Cross-References</p> <p>Each term lists related entries to encourage discovery.</p> </li> <li> <p> Editable</p> <p>Update the JSON file, not components, to change tooltip content.</p> </li> </ul> <p>Get started Configuration API</p> <p>Source of Truth</p> <p><code>data/glossary.json</code> is parsed by the UI. Keep <code>key</code> values stable for long-lived tooltips.</p> <p>Examples</p> <ul> <li>PostgreSQL pgvector URL</li> <li>Neo4j Connection URI</li> <li>Active Repository (Corpus)</li> </ul> <p>Typos</p> <p>Misspelled keys break existing tooltips silently. Validate JSON in CI.</p>"},{"location":"glossary/#representative-entries","title":"Representative Entries","text":"Term Key Definition PostgreSQL pgvector URL POSTGRES_URL Connection URL for pgvector-enabled Postgres Neo4j Connection URI NEO4J_URI Connection URI for Neo4j graph Active Repository REPO Logical corpus name for routing and indexing <pre><code>flowchart LR\n    glossary.json --&gt; TooltipIcon\n    TooltipIcon --&gt; UI</code></pre> Python <pre><code># Tooling note: the UI consumes the JSON directly; backend does not parse this by default.\n</code></pre> curl <pre><code># Validate JSON structure in CI, e.g., with jq\njq . data/glossary.json &gt; /dev/null\n</code></pre> TypeScript <pre><code>// UI side: import terms via a loader and feed into TooltipIcon\n</code></pre> <p>Consistency</p> <p>Use the glossary for all UI textual explanations to avoid drift between screens.</p> <ul> <li> Keep terms unique</li> <li> Provide related links for navigation</li> <li> Update definitions when behavior changes</li> </ul> Localization <p>If localization is needed, consider expanding the schema with <code>translations</code> while keeping <code>key</code> stable.</p>"},{"location":"indexing/","title":"Indexing","text":""},{"location":"indexing/#indexing-pipeline","title":"Indexing Pipeline","text":"<ul> <li> <p> Loader</p> <p>Git-aware discovery honoring <code>.gitignore</code> with root-relative patterns.</p> </li> <li> <p> Chunker</p> <p>Fixed, AST-aware, or semantic chunk strategies with line attribution.</p> </li> <li> <p> Embedder</p> <p>Deterministic local embedder or provider-backed embeddings configured in Pydantic.</p> </li> <li> <p> Chunk Summaries</p> <p>Optional LLM-generated <code>summary</code> per chunk to improve sparse search.</p> </li> <li> <p> Graph Builder</p> <p>Entity/relationship extraction and Neo4j persistence.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Idempotent Indexing</p> <p>Use <code>force_reindex=false</code> for incremental updates. The indexer skips unchanged files using mtime/hash checks where available.</p> <p>Storage Layout</p> <p>Chunks, embeddings, and FTS are in PostgreSQL. Graph artifacts are in Neo4j. Sizes are summarized via dashboard endpoints.</p> <p>Large Corpora</p> <p>Configure Neo4j heap and page cache in Docker env for multi-million edge graphs. Monitor Postgres disk growth for pgvector indexes.</p>"},{"location":"indexing/#pipeline-flow","title":"Pipeline Flow","text":"<pre><code>flowchart LR\n    L[FileLoader] --&gt; C[Chunker]\n    C --&gt; E[Embedder]\n    E --&gt; P[(PostgreSQL)]\n    C --&gt; S[ChunkSummarizer]\n    S --&gt; P\n    C --&gt; GB[GraphBuilder]\n    GB --&gt; N[(Neo4j)]</code></pre>"},{"location":"indexing/#chunking-strategies","title":"Chunking Strategies","text":"Strategy Module Parameters Use Case <code>chunk_fixed</code> <code>server/indexing/chunker.py</code> <code>size</code>, <code>overlap</code> Simple sliding windows <code>chunk_ast</code> <code>server/indexing/chunker.py</code> <code>language</code>, <code>node_types</code> Code-aware boundaries <code>chunk_semantic</code> <code>server/indexing/chunker.py</code> <code>min_tokens</code>, <code>max_tokens</code> Balanced semantic splits"},{"location":"indexing/#index-request-models","title":"Index Request Models","text":"Field Type Description <code>corpus_id</code> str Corpus identifier (alias of <code>repo_id</code>) <code>repo_path</code> str Absolute path on disk <code>force_reindex</code> bool Force full rebuild"},{"location":"indexing/#indexing-via-api","title":"Indexing via API","text":"PythoncurlTypeScript <pre><code>import httpx\n\nbase = \"http://localhost:8000\"\n\nreq = {\n    \"corpus_id\": \"tribrid\",\n    \"repo_path\": \"/work/src/tribrid\",\n    \"force_reindex\": False,\n}\n\n# Start\nhttpx.post(f\"{base}/index\", json=req)  # (1)\n\n# Status\nstatus = httpx.get(f\"{base}/index/status\", params={\"corpus_id\": \"tribrid\"}).json()  # (2)\n\n# Storage stats\nstats = httpx.get(f\"{base}/index/stats\", params={\"corpus_id\": \"tribrid\"}).json()  # (3)\nprint(stats)\n</code></pre> <pre><code>BASE=http://localhost:8000\n\ncurl -sS -X POST \"$BASE/index\" -H 'Content-Type: application/json' -d '{\n  \"corpus_id\":\"tribrid\",\n  \"repo_path\":\"/work/src/tribrid\",\n  \"force_reindex\":false\n}'\n\ncurl -sS \"$BASE/index/status?corpus_id=tribrid\" | jq .\ncurl -sS \"$BASE/index/stats?corpus_id=tribrid\" | jq .\n</code></pre> <pre><code>import { IndexRequest, IndexStats } from \"./web/src/types/generated\";\n\nasync function reindex(path: string) {\n  const req: IndexRequest = { corpus_id: \"tribrid\", repo_path: path, force_reindex: false };\n  await fetch(\"/index\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) }); // (1)\n  const status = await (await fetch(\"/index/status?corpus_id=tribrid\")).json(); // (2)\n  const stats: IndexStats = await (await fetch(\"/index/stats?corpus_id=tribrid\")).json(); // (3)\n  console.log(status, stats.total_chunks);\n}\n</code></pre> <ol> <li>Start indexing</li> <li>Poll progress</li> <li>Inspect aggregated stats</li> </ol>"},{"location":"indexing/#chunk-summaries","title":"Chunk Summaries","text":"Endpoint Method Description <code>/chunk_summaries</code> GET List summaries for a corpus <code>/chunk_summaries/build</code> POST Generate summaries for all chunks <p>Sparse Boost</p> <p>Summaries can improve recall for identifier-heavy queries by adding descriptive context to FTS.</p> <pre><code>flowchart TB\n    Chunks --&gt; Summarizer\n    Summarizer --&gt; Postgres[(FTS Index)]\n    Summarizer --&gt; Costs[Model Costs]\n    Costs --&gt; Models[data/models.json]</code></pre> <ul> <li> Choose chunking strategy in config</li> <li> Enable summaries for sparse boost if budget allows</li> <li> Validate storage growth in dashboard stats</li> </ul> Indexing Failure Modes <ul> <li>File decoding errors: logged and skipped</li> <li>Embedding timeouts: retried with backoff; chunk remains un-embedded if persistent</li> <li>Graph build failures: search still works with vector/sparse; flagged in logs</li> </ul>"},{"location":"models/","title":"Models","text":""},{"location":"models/#model-catalog-datamodelsjson","title":"Model Catalog (data/models.json)","text":"<ul> <li> <p> Cost-Aware</p> <p>Pricing per 1k tokens with provider and family classifications.</p> </li> <li> <p> LLM/Embedding/Reranker</p> <p>Centralized catalog for generation, embeddings, and reranking models.</p> </li> <li> <p> API-Served</p> <p>UI and backend must fetch models from <code>/models/...</code>. No local lists.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Single Source</p> <p><code>data/models.json</code> is the authoritative source for model availability, pricing, and context sizes. Update it to change selectable models.</p> <p>Components</p> <p>The <code>components</code> field indicates usage: <code>GEN</code> for generation, <code>EMB</code> for embeddings, <code>RERANK</code> for cross-encoders.</p> <p>Pricing Staleness</p> <p>Prices may change. Keep <code>last_updated</code> current and reference sources in the file header.</p>"},{"location":"models/#api-endpoints","title":"API Endpoints","text":"Route Description <code>/models/by-type/{component_type}</code> Filter by <code>GEN</code>, <code>EMB</code>, or <code>RERANK</code> <code>/models/providers</code> List providers <code>/models/providers/{provider}</code> Models for a specific provider <pre><code>flowchart LR\n    Catalog[data/models.json] --&gt; API[FastAPI /models]\n    API --&gt; UI[Model Pickers]\n    API --&gt; Server[Embedding/Reranker Selection]</code></pre>"},{"location":"models/#example-queries","title":"Example Queries","text":"PythoncurlTypeScript <pre><code>import httpx\n\nbase = \"http://localhost:8000\"\ngens = httpx.get(f\"{base}/models/by-type/GEN\").json()  # (1)\nproviders = httpx.get(f\"{base}/models/providers\").json()  # (2)\nopenai = httpx.get(f\"{base}/models/providers/openai\").json()  # (3)\nprint(gens[0], providers, len(openai))\n</code></pre> <pre><code>BASE=http://localhost:8000\ncurl -sS \"$BASE/models/by-type/GEN\" | jq '.[0]'\ncurl -sS \"$BASE/models/providers\" | jq .\ncurl -sS \"$BASE/models/providers/openai\" | jq '.[].model'\n</code></pre> <pre><code>type ModelItem = { provider: string; family: string; model: string; components: string[] };\n\nasync function listGen(): Promise&lt;ModelItem[]&gt; {\n  return await (await fetch(\"/models/by-type/GEN\")).json();\n}\n</code></pre> <ol> <li>Generation models</li> <li>Providers</li> <li>Provider-specific listing</li> </ol>"},{"location":"models/#data-columns","title":"Data Columns","text":"Field Meaning <code>provider</code> e.g., <code>openai</code>, <code>cohere</code>, <code>voyage</code> <code>family</code> Logical family for grouping <code>model</code> Provider\u2019s model identifier <code>components</code> <code>[\"GEN\"]</code>, <code>[\"EMB\"]</code>, <code>[\"RERANK\"]</code> <code>input_per_1k</code> / <code>output_per_1k</code> Pricing in USD <code>context</code> Context window tokens <p>UI Contract</p> <p>All selectors in the UI must call these endpoints and use generated types from Pydantic for request/response where applicable.</p> <ul> <li> Update <code>models.json</code></li> <li> <code>uv run scripts/generate_types.py</code> if schema changed</li> <li> Restart API if reloading is not enabled</li> </ul> Model Notes <p>The <code>notes</code> field documents special capabilities or context window exceptions.</p>"},{"location":"operations/","title":"Operations","text":""},{"location":"operations/#operations-health-and-metrics","title":"Operations, Health, and Metrics","text":"<ul> <li> <p> Health</p> <p><code>/health</code> and <code>/ready</code> for liveness and readiness.</p> </li> <li> <p> Metrics</p> <p><code>/metrics</code> for Prometheus. Plus Postgres exporter for DB metrics.</p> </li> <li> <p> Runtime Control</p> <p>Inspect and restart containers via Docker endpoints.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Readiness Gate</p> <p>Deployments should route traffic only after <code>/ready</code> returns success. This ensures Postgres and Neo4j are available.</p> <p>Scopes</p> <p>Health endpoints are cheap. Metrics scraping interval can be 10\u201330s depending on traffic and budget.</p> <p>High-Cardinality Metrics</p> <p>Avoid per-query labels in Prometheus if cardinality explodes. Aggregate at the corpus or retriever level.</p>"},{"location":"operations/#endpoints","title":"Endpoints","text":"Endpoint Description <code>/health</code> Process liveness <code>/ready</code> Readiness including DB checks <code>/metrics</code> Prometheus metrics <code>/docker/status</code> Container status <code>/docker/{container}/restart</code> Restart container <code>/docker/{container}/logs</code> Tail logs <pre><code>flowchart LR\n    Scrape[Prometheus] --&gt; API[/metrics]\n    API --&gt; App[TriBridRAG]\n    App --&gt; PG[(Postgres)]\n    App --&gt; NEO[(Neo4j)]\n    Scrape --&gt; PExp[postgres-exporter]</code></pre>"},{"location":"operations/#example-metrics-scrape","title":"Example: Metrics Scrape","text":"PythoncurlTypeScript <pre><code>import httpx\n\nprint(httpx.get(\"http://localhost:8000/metrics\").text[:500])  # (1)\n</code></pre> <pre><code>curl -sS http://localhost:8000/metrics | head -n 30\n</code></pre> <pre><code>async function scrape() {\n  const text = await (await fetch('/metrics')).text();\n  console.log(text.split('\\n').slice(0, 10).join('\\n'));\n}\n</code></pre> <ol> <li>Prometheus-style exposition format</li> </ol> <p>Dashboards</p> <p>The repository includes Grafana-ready metrics via <code>/metrics</code> and the Postgres exporter.</p> <ul> <li> Gate traffic with <code>/ready</code></li> <li> Alert on high error rates and slow search latencies</li> <li> Track index build durations and graph traversal times</li> </ul> <pre><code>flowchart TB\n    Alert[Alerts] --&gt; OnCall\n    Metrics --&gt; Alert\n    OnCall --&gt; Mitigate</code></pre> Log Access <p>Use <code>/docker/{container}/logs</code> for quick log retrieval. For long-term retention, integrate with a centralized logging solution.</p>"},{"location":"security/","title":"Security","text":""},{"location":"security/#security-and-secrets","title":"Security and Secrets","text":"<ul> <li> <p> Secrets</p> <p>API keys for providers and DB credentials loaded from environment.</p> </li> <li> <p> Validation</p> <p><code>/secrets/check</code> verifies presence and connectivity.</p> </li> <li> <p> Least Privilege</p> <p>Restrict DB users and network access.</p> </li> </ul> <p>Get started Configuration API</p> <p>Separate Environments</p> <p>Use different credentials per environment (dev, staging, prod). Never reuse production secrets locally.</p> <p>.env Hygiene</p> <p><code>.env</code> is for local dev only. In production, use a secret manager and inject env vars securely.</p> <p>Transport Security</p> <p>Terminate TLS in front of the API service. Restrict DB ports to private networks.</p>"},{"location":"security/#secrets-check","title":"Secrets Check","text":"PythoncurlTypeScript <pre><code>import httpx\nprint(httpx.get(\"http://localhost:8000/secrets/check\").json())  # (1)\n</code></pre> <pre><code>curl -sS http://localhost:8000/secrets/check | jq .\n</code></pre> <pre><code>async function secrets() {\n  console.log(await (await fetch('/secrets/check')).json());\n}\n</code></pre> <ol> <li>Returns flags for provider keys, Postgres, and Neo4j connectivity</li> </ol>"},{"location":"security/#environment-fields","title":"Environment Fields","text":"Key Purpose <code>OPENAI_API_KEY</code>, <code>VOYAGE_API_KEY</code>, <code>COHERE_API_KEY</code>, <code>JINA_API_KEY</code> Provider access <code>POSTGRES_*</code> DB connection for pgvector + FTS <code>NEO4J_*</code> Neo4j connection <pre><code>flowchart LR\n    Env[Environment] --&gt; API\n    API --&gt; Check[/secrets/check]\n    Check --&gt; Report[Status]</code></pre> <ul> <li> Rotate keys regularly</li> <li> Use strong DB passwords</li> <li> Restrict inbound network access</li> </ul> <p>Auditing</p> <p>Log access to admin endpoints (<code>/config</code>, <code>/docker/*</code>, <code>/reranker/*</code>). Monitor for unusual patterns.</p> RBAC <p>Consider fronting the API with an authenticating proxy that provides role-based access for administrative routes.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p> Common Failures</p> <p>Timeouts, DB connectivity, schema mismatches.</p> </li> <li> <p> Validation Errors</p> <p>Pydantic constraints fail fast with precise messages.</p> </li> <li> <p> Recovery</p> <p>Clear caches, reindex, restart services.</p> </li> </ul> <p>Get started Configuration API</p> <p>Read the Error</p> <p>Pydantic tells you exactly which field failed validation and why. Fix the config, regenerate types if needed, and retry.</p> <p>Logs</p> <p>Use <code>/docker/{container}/logs</code> and application logs to pinpoint failures. For DB errors, also inspect Postgres and Neo4j logs.</p> <p>Data Loss Risk</p> <p>Avoid deleting DB volumes unless you intend a full reset. Back up before destructive actions.</p>"},{"location":"troubleshooting/#symptom-action","title":"Symptom \u2192 Action","text":"Symptom Likely Cause Action 500 on <code>/search</code> DB unavailable Check <code>/ready</code>, restart DB containers No results from graph Neo4j disconnected or empty Rebuild graph, check credentials Validation error on <code>/config</code> patch Field constraints violated Adjust values to allowed ranges Slow queries High <code>max_hops</code>, large top_k Reduce graph hops, tune indexes <pre><code>flowchart TB\n    Error[Error] --&gt; Check[/ready]\n    Check --&gt;|ok| Investigate[Inspect Logs]\n    Check --&gt;|fail| Restart[Restart Services]\n    Investigate --&gt; Fix[Config Tune]</code></pre>"},{"location":"troubleshooting/#useful-commands","title":"Useful Commands","text":"PythoncurlTypeScript <pre><code>import httpx\nbase = \"http://localhost:8000\"\nprint(httpx.get(f\"{base}/ready\").json())  # readiness\n</code></pre> <pre><code>curl -sS http://localhost:8000/ready | jq .\ncurl -sS http://localhost:8000/docker/status | jq .\n</code></pre> <pre><code>// Programmatic health checks during E2E tests\nawait fetch('/ready').then(r =&gt; r.ok || Promise.reject('Not ready'))\n</code></pre> <ul> <li> Verify readiness</li> <li> Inspect logs</li> <li> Reduce search/fusion parameters</li> <li> Reindex corpus</li> </ul> <p>Fallback Behavior</p> <p>If one retrieval path fails (e.g., graph), the system continues with vector + sparse. This is expected and logged.</p> Cache Issues <p>If you suspect stale cache, clear retrieval caches (if enabled) or include a cache-busting parameter during debugging.</p>"},{"location":"architecture/health-metrics/","title":"Health & metrics","text":""},{"location":"architecture/health-metrics/#health-and-metrics-internals","title":"Health and Metrics Internals","text":"<ul> <li> <p> Liveness/Readiness</p> <p>Handlers return fine-grained status with DB probes.</p> </li> <li> <p> Prometheus</p> <p>Export standard and custom app metrics.</p> </li> <li> <p> DB Exporter</p> <p>PostgreSQL exporter complements app metrics.</p> </li> </ul> <p>Get started Configuration API</p> <p>Scrape Intervals</p> <p>Start with 15s scraping and tighten as necessary to capture spikes while controlling overhead.</p> <p>Metrics Names</p> <p>Use a <code>tribrid_</code> prefix for app metrics. Include <code>corpus_id</code> labels where appropriate.</p> <p>Label Cardinality</p> <p>Avoid per-file labels in hot paths. Aggregate at corpus/module level to keep metrics tractable.</p> <pre><code>flowchart TB\n    App --&gt; METRICS[\"/metrics\"]\n    METRICS[\"/metrics\"] --&gt; Prom[Prometheus]\n    Postgres --&gt; PExp[postgres-exporter]\n    PExp --&gt; Prom</code></pre>"},{"location":"architecture/health-metrics/#access-examples","title":"Access Examples","text":"PythoncurlTypeScript <pre><code>import httpx\nassert httpx.get(\"http://localhost:8000/health\").status_code == 200\nassert httpx.get(\"http://localhost:8000/ready\").status_code == 200\nprint(httpx.get(\"http://localhost:8000/metrics\").text.splitlines()[:5])\n</code></pre> <pre><code>curl -sS http://localhost:8000/health\ncurl -sS http://localhost:8000/ready\ncurl -sS http://localhost:8000/metrics | head -n 20\n</code></pre> <pre><code>await fetch('/health').then(r =&gt; r.ok || Promise.reject('down'))\nawait fetch('/ready').then(r =&gt; r.ok || Promise.reject('not ready'))\nconst sample = await (await fetch('/metrics')).text();\nconsole.log(sample.split('\\n').slice(0, 5));\n</code></pre> <ul> <li> Gate traffic on readiness</li> <li> Alert on 5xx and slow search</li> <li> Monitor DB connection pool saturation</li> </ul> <p>Observability</p> <p>Combine <code>/metrics</code> with logs and tracing (if added) for a complete operational picture.</p> Implementation <p>Handlers are in <code>server/api/health.py</code>. Readiness checks Postgres/Neo4j pings before returning 200.</p>"},{"location":"assets/images/","title":"Screenshots Guide","text":""},{"location":"assets/images/#screenshots-guide","title":"Screenshots Guide","text":""},{"location":"assets/images/#how-to-add-screenshots-to-docs","title":"How to Add Screenshots to Docs","text":"<ol> <li>Take screenshots of the TriBridRAG UI at http://localhost:5175/</li> <li>Save them to this directory with descriptive names:</li> <li><code>rag-config-interface.png</code> - RAG tab with fusion weights</li> <li><code>search-results.png</code> - Search interface with results</li> <li><code>graph-visualization.png</code> - Neo4j graph view</li> <li><code>model-selector.png</code> - Model picker interface</li> <li> <p><code>cost-calculator.png</code> - Cost tracking dashboard</p> </li> <li> <p>Add to docs using this format:</p> </li> </ol> <pre><code>![RAG Configuration Interface](./assets/images/rag-config-interface.png)\n*Configure fusion weights, reranking, and search parameters through the intuitive UI*\n</code></pre> <p>Or with lightbox zoom:</p> <pre><code>&lt;figure markdown&gt;\n  ![RAG Configuration](./assets/images/rag-config-interface.png){ loading=lazy }\n  &lt;figcaption&gt;Configure tri-brid fusion weights and reranking options&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre>"},{"location":"assets/images/#recommended-screenshots","title":"Recommended Screenshots","text":""},{"location":"assets/images/#1-rag-configuration-tab","title":"1. RAG Configuration Tab","text":"<ul> <li>Show the sliders for fusion weights (vector/sparse/graph)</li> <li>Reranker dropdown</li> <li>Top-K settings</li> <li>Confidence thresholds</li> </ul>"},{"location":"assets/images/#2-search-interface","title":"2. Search Interface","text":"<ul> <li>Query input</li> <li>Results panel with chunks</li> <li>Relevance scores</li> <li>Citation links</li> </ul>"},{"location":"assets/images/#3-graph-visualization","title":"3. Graph Visualization","text":"<ul> <li>Neo4j entities and relationships</li> <li>Community detection</li> <li>Entity details panel</li> </ul>"},{"location":"assets/images/#4-model-management","title":"4. Model Management","text":"<ul> <li>Model picker dropdown (embedding/generation/reranker)</li> <li>Provider selection</li> <li>Cost calculator</li> <li>Context window info</li> </ul>"},{"location":"assets/images/#5-glossarytooltips","title":"5. Glossary/Tooltips","text":"<ul> <li>Show the tooltip system with definitions</li> <li>Searchable glossary tab</li> </ul>"},{"location":"assets/images/#screenshot-tips","title":"Screenshot Tips","text":"<ul> <li>Use dark mode (matches docs theme)</li> <li>Capture at ~1920x1080 or similar</li> <li>Show real data/results (not empty states)</li> <li>Highlight key features with cursor or annotations</li> <li>Keep UI clean (close unnecessary panels)</li> </ul>"},{"location":"dev/pydantic/","title":"Pydantic","text":""},{"location":"dev/pydantic/#pydantic-first-development","title":"Pydantic-First Development","text":"<ul> <li> <p> The Law</p> <p>Everything starts in <code>tribrid_config_model.py</code>. If it\u2019s not there, it does not exist.</p> </li> <li> <p> Generate Types</p> <p><code>uv run scripts/generate_types.py</code> produces <code>web/src/types/generated.ts</code>.</p> </li> <li> <p> Derivation Chain</p> <p>Pydantic \u2192 generated.ts \u2192 stores \u2192 hooks \u2192 components.</p> </li> </ul> <p>Get started Configuration API</p> <p>Workflow</p> <p>1) Add/modify fields in Pydantic. 2) Generate TS types. 3) Use types in stores/hooks/components. 4) Update backend logic to honor new fields.</p> <p>Constraints</p> <p>Use <code>Field(ge=..., le=..., description=...)</code> everywhere. Descriptions become tooltips and docs.</p> <p>No Adapters</p> <p>Never write client-side adapters to change response shapes. Fix the Pydantic model instead.</p>"},{"location":"dev/pydantic/#derivation-chain","title":"Derivation Chain","text":"<pre><code>flowchart TB\n    P[\"Pydantic\\ntribrid_config_model.py\"] --&gt; G[\"pydantic2ts\\n(generate_types.py)\"]\n    G --&gt; T[generated.ts]\n    T --&gt; Z[Zustand Stores]\n    Z --&gt; H[Hooks]\n    H --&gt; C[Components]\n    P --&gt; A[FastAPI Schemas]</code></pre>"},{"location":"dev/pydantic/#commands","title":"Commands","text":"PythoncurlTypeScript <pre><code>import subprocess\nsubprocess.check_call([\"uv\", \"run\", \"scripts/generate_types.py\"])  # (1)\n</code></pre> <pre><code># Not applicable \u2014 run locally with uv\necho \"Run: uv run scripts/generate_types.py\" # (1)\n</code></pre> <pre><code>// After generation, import from generated.ts (2)\nimport { TriBridConfig } from '../web/src/types/generated';\n</code></pre> <ol> <li>Generate TypeScript types from Pydantic models</li> <li>Consume generated types exclusively</li> </ol>"},{"location":"dev/pydantic/#source-of-truth-files","title":"Source-of-Truth Files","text":"File Purpose <code>server/models/tribrid_config_model.py</code> All config and domain models <code>data/models.json</code> Model catalog, pricing, context windows <code>data/glossary.json</code> Tooltip terms and categories <p>UI Traceability</p> <p>Every prop in React components must trace back to a Pydantic field through generated types.</p> <ul> <li> Add field in Pydantic first</li> <li> Generate types</li> <li> Update store/hook</li> <li> Use in component</li> </ul> Common Pitfalls <ul> <li>Missing <code>validation_alias</code> when migrating <code>repo_id</code> \u2192 <code>corpus_id</code></li> <li>Forgetting to include <code>description</code> leads to poor auto-docs</li> <li>Unbounded fields without <code>ge/le</code> allow invalid config into production</li> </ul>"},{"location":"guides/corpus/","title":"Corpus","text":""},{"location":"guides/corpus/#corpus-vs-repo_id","title":"Corpus vs repo_id","text":"<ul> <li> <p> Corpus-First</p> <p>A corpus is any folder you index: repo, docs, or subtree.</p> </li> <li> <p> Isolation</p> <p>Each corpus has separate Postgres tables, Neo4j DB, and config.</p> </li> <li> <p> Naming Migration</p> <p>API accepts <code>repo_id</code> but serializes as <code>corpus_id</code>.</p> </li> </ul> <p>Get started Configuration API</p> <p>Best Practice</p> <p>Use stable, lowercase slugs for corpus ids, e.g., <code>tribrid</code>, <code>myapp-docs</code>. Avoid spaces and special characters.</p> <p>AliasChoices</p> <p>Pydantic models specify <code>validation_alias=AliasChoices(\"repo_id\", \"corpus_id\")</code> and <code>serialization_alias=\"corpus_id\"</code> to ensure forward compatibility.</p> <p>Cross-Corpus Leakage</p> <p>Never mix <code>corpus_id</code> across requests. Isolation is enforced, but path filters and boosts are corpus-scoped.</p>"},{"location":"guides/corpus/#models-using-corpus_id","title":"Models Using corpus_id","text":"Model Fields <code>IndexRequest</code> <code>corpus_id</code>, <code>repo_path</code>, <code>force_reindex</code> <code>IndexStatus</code> <code>corpus_id</code>, <code>status</code>, <code>progress</code>, <code>current_file</code> <code>IndexStats</code> <code>corpus_id</code>, <code>total_files</code>, <code>total_chunks</code>, <code>embedding_model</code> <code>DashboardIndexStatusResponse</code> <code>metadata.repo_id</code> (serialized <code>corpus_id</code>) <pre><code>flowchart LR\n    UI --&gt; API\n    API --&gt; Pyd[AliasChoices(repo_id, corpus_id)]\n    Pyd --&gt; Store[Serialized as corpus_id]</code></pre>"},{"location":"guides/corpus/#example-requests","title":"Example Requests","text":"PythoncurlTypeScript <pre><code>import httpx\n\nreq = {\"corpus_id\": \"tribrid\", \"repo_path\": \"/code/tribrid\", \"force_reindex\": False}\nhttpx.post(\"http://localhost:8000/index\", json=req)   # (1)\nhttpx.get(\"http://localhost:8000/index/status\", params={\"corpus_id\": \"tribrid\"})  # (2)\n</code></pre> <pre><code>curl -sS -X POST http://localhost:8000/index -H 'Content-Type: application/json' -d '{\n  \"corpus_id\": \"tribrid\", \"repo_path\": \"/code/tribrid\", \"force_reindex\": false\n}'\n</code></pre> <pre><code>import { IndexRequest } from '../web/src/types/generated';\nconst req: IndexRequest = { corpus_id: 'tribrid', repo_path: '/code/tribrid', force_reindex: false };\n</code></pre> <ol> <li>Create/refresh a specific corpus</li> <li>Poll that same corpus id for status</li> </ol> <p>Multi-Corpus UIs</p> <p>Add a repo switcher bound to <code>corpus_id</code>. All panels (RAG, Graph, Index) should update in lockstep.</p> <ul> <li> Normalize ids to lowercase slugs</li> <li> Persist per-corpus config</li> <li> Scope metrics by <code>corpus_id</code></li> </ul> Storage Isolation <ul> <li>Postgres tables can be suffixed by corpus id</li> <li>Neo4j Enterprise can allocate separate databases per corpus; Community can emulate via labeling and namespacing</li> </ul>"},{"location":"howto/reranker/","title":"Reranker","text":""},{"location":"howto/reranker/#how-to-reranker-training-and-evaluation","title":"How-To: Reranker Training and Evaluation","text":"<ul> <li> <p> Reranker</p> <p>Cross-encoder stage to refine fused retrieval results.</p> </li> <li> <p>:material-mining:{ .lg .middle } Triplet Mining</p> <p>Collect (query, positive, negative) examples from logs or heuristics.</p> </li> <li> <p> Evaluate</p> <p>Benchmark before/after reranking on an eval dataset.</p> </li> </ul> <p>Get started Configuration API</p> <p>Start Small</p> <p>Begin with a small <code>eval_dataset</code> and a few hundred mined triplets. Validate that gains are consistent across corpora.</p> <p>Costs</p> <p>Training and evaluation costs depend on selected <code>RERANK</code> and <code>EMB/GEN</code> models from <code>data/models.json</code>.</p> <p>Config-Governed</p> <p>Enable via <code>reranker.enabled</code>. All training hyperparameters must be present in Pydantic before use.</p>"},{"location":"howto/reranker/#api-surface","title":"API Surface","text":"Route Method Description <code>/reranker/status</code> GET Load status (model, enabled) <code>/reranker/info</code> GET Implementation details <code>/reranker/mine</code> POST Mine triplets <code>/reranker/train</code> POST Train reranker <code>/reranker/evaluate</code> POST Evaluate against dataset <code>/reranker/logs/count</code> GET Available logs <code>/reranker/triplets/count</code> GET Triplets available <code>/reranker/costs</code> GET Estimated costs <pre><code>flowchart TB\n    Logs[Retrieval Logs] --&gt; Mine[Mine Triplets]\n    Mine --&gt; Train[Train Reranker]\n    Train --&gt; Model[Reranker Model]\n    Model --&gt; Eval[Evaluate]\n    Eval --&gt; Report[Metrics]</code></pre>"},{"location":"howto/reranker/#example-workflow","title":"Example Workflow","text":"PythoncurlTypeScript <pre><code>import httpx\n\nbase = \"http://localhost:8000\"\n\n# Mine triplets (1)\nmine_req = {\"corpus_id\": \"tribrid\", \"max_pairs\": 500}\nhttpx.post(f\"{base}/reranker/mine\", json=mine_req)\n\n# Train (2)\ntrain_req = {\"corpus_id\": \"tribrid\", \"epochs\": 2, \"batch_size\": 16}\nhttpx.post(f\"{base}/reranker/train\", json=train_req)\n\n# Evaluate (3)\neval_req = {\"corpus_id\": \"tribrid\"}\nprint(httpx.post(f\"{base}/reranker/evaluate\", json=eval_req).json())\n</code></pre> <pre><code>BASE=http://localhost:8000\ncurl -sS -X POST \"$BASE/reranker/mine\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"max_pairs\":500}'\ncurl -sS -X POST \"$BASE/reranker/train\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\",\"epochs\":2,\"batch_size\":16}'\ncurl -sS -X POST \"$BASE/reranker/evaluate\" -H 'Content-Type: application/json' -d '{\"corpus_id\":\"tribrid\"}' | jq .\n</code></pre> <pre><code>async function trainReranker(corpus_id: string) {\n  await fetch('/reranker/mine', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id, max_pairs: 500 }) }); // (1)\n  await fetch('/reranker/train', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id, epochs: 2, batch_size: 16 }) }); // (2)\n  const report = await (await fetch('/reranker/evaluate', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({ corpus_id }) })).json(); // (3)\n  console.log(report);\n}\n</code></pre> <ol> <li>Mine triplets</li> <li>Train model</li> <li>Evaluate results</li> </ol>"},{"location":"howto/reranker/#reranker-config-fields","title":"Reranker Config Fields","text":"Field Description <code>reranker.enabled</code> Toggle reranker usage in search <code>reranker.model</code> Model id from <code>models.json</code> <code>reranker.batch_size</code> Micro-batch for reranking <p>Evaluation Discipline</p> <p>Use a fixed <code>eval_dataset</code> to avoid overfitting. Track MAP@K and NDCG@K pre/post reranking.</p> <ul> <li> Mine \u2192 Train \u2192 Evaluate</li> <li> Compare metrics vs baseline</li> <li> Monitor cost estimates via <code>/reranker/costs</code></li> </ul> Triplet Mining <ul> <li>Hard negatives from near-miss candidates</li> <li>Positives from clicked/accepted chunks in logs</li> <li>Balance classes to prevent bias</li> </ul>"},{"location":"retrieval/overview/","title":"Overview","text":""},{"location":"retrieval/overview/#retrieval-overview","title":"Retrieval Overview","text":"<ul> <li> <p> Vector Search</p> <p>pgvector similarity over chunk embeddings with configurable distance metrics and indexes.</p> </li> <li> <p> Sparse Search</p> <p>PostgreSQL FTS/BM25 for exact tokens, identifiers, and literals.</p> </li> <li> <p> Graph Search</p> <p>Neo4j traversal to expand entity neighborhoods and follow relationships across files.</p> </li> <li> <p> Fusion</p> <p>Weighted or RRF; per-retriever contributions logged for analysis.</p> </li> <li> <p> Optional Reranker</p> <p>Cross-encoder rescoring of fused candidates for precision.</p> </li> </ul> <p>Get started Configuration API</p> <p>Pro Tip \u2014 Balance Recall and Precision</p> <p>Increase top_k per retriever to maximize recall. Use fusion weights and reranking to regain precision.</p> <p>Isolation by Corpus</p> <p>Each corpus has isolated storage and graph. Queries always require <code>corpus_id</code>.</p> <p>Latency Budget</p> <p>Graph expansion can increase latency with large hop counts. Use <code>max_hops</code> conservatively and cache frequent queries.</p>"},{"location":"retrieval/overview/#control-surface","title":"Control Surface","text":"Retriever Key Fields Defaults Vector <code>retrieval.vector.top_k</code>, <code>distance_metric</code>, <code>min_score</code> Top_k 8\u201320 Sparse <code>retrieval.sparse.top_k</code>, <code>use_bm25</code>, <code>tsquery_mode</code> BM25 enabled Graph <code>retrieval.graph.max_hops</code>, <code>edge_types</code>, <code>expand_neighbors</code> 1\u20132 hops Fusion <code>fusion.strategy</code>, <code>fusion.weights</code>, <code>fusion.rrf_k_div</code> weighted + tuned weights Reranker <code>reranker.enabled</code>, <code>reranker.model</code>, <code>batch_size</code> disabled <pre><code>flowchart LR\n    Q[Query] --&gt; V[Vector]\n    Q --&gt; S[Sparse]\n    Q --&gt; G[Graph]\n\n    V --&gt; F[Fusion]\n    S --&gt; F\n    G --&gt; F\n\n    F --&gt;|optional| R[Reranker]\n    R --&gt; OUT[Results]\n    F --&gt; OUT</code></pre>"},{"location":"retrieval/overview/#programmatic-search","title":"Programmatic Search","text":"PythoncurlTypeScript <pre><code>import httpx\n\nBASE = \"http://localhost:8000\"\nbody = {\n  \"corpus_id\": \"tribrid\",\n  \"query\": \"How are pgvector indexes created?\",\n  \"top_k\": 10,\n  \"enable_reranker\": True,\n  \"filters\": {\"path_prefix\": \"server/db\"}  # optional impl-specific filter\n}\nres = httpx.post(f\"{BASE}/search\", json=body).json() # (1)\nfor r in res[\"results\"]:\n    # includes per-source scores e.g., r[\"sources\"][\"vector\"], r[\"sources\"][\"sparse\"]\n    print(r[\"file_path\"], r[\"score\"]) # (2)\n</code></pre> <pre><code>curl -sS -X POST http://localhost:8000/search \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"corpus_id\": \"tribrid\",\n    \"query\": \"pgvector index\",\n    \"top_k\": 10,\n    \"enable_reranker\": true\n  }' | jq '.results[0]'\n</code></pre> <pre><code>import { SearchRequest, SearchResponse } from \"../web/src/types/generated\";\n\nasync function run(req: SearchRequest): Promise&lt;SearchResponse&gt; {\n  const r = await fetch(\"/search\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify(req) });\n  return await r.json();\n}\n</code></pre> <ol> <li>Search executes all retrievers concurrently</li> <li><code>score</code> is fused; provenance retained per source</li> </ol> <p>Auditable Fusion</p> <p>Each match returns provenance: which retriever(s) contributed and their raw scores. This is essential for debugging.</p>"},{"location":"retrieval/overview/#fusion-strategies","title":"Fusion Strategies","text":"Strategy Math Notes weighted <code>w_v*sv + w_s*ss + w_g*sg</code> Default; interpretable weights rrf <code>1/(k + rank)</code> per source, summed Robust across heterogeneous scores"},{"location":"retrieval/overview/#graph-expansion","title":"Graph Expansion","text":"Field Effect <code>max_hops</code> Traversal depth; controls neighborhood growth <code>edge_types</code> Restrict to safe/meaningful relations <code>expand_neighbors</code> Add 1-hop context chunks to results <pre><code>flowchart TB\n    Seed[Seed Entities] --&gt;|max_hops| Walk[Traversal]\n    Walk --&gt; Neigh[Neighbors]\n    Neigh --&gt; Context[Context Expansion]</code></pre> <ul> <li> Tune per-retriever <code>top_k</code></li> <li> Choose <code>weighted</code> or <code>rrf</code></li> <li> Enable reranking once recall is strong</li> </ul> Caching <p>The retrieval cache stores fused results keyed by <code>corpus_id</code>, <code>query</code>, and a hash of the retrieval config segment. Invalidate on config changes or reindex.</p>"}]}